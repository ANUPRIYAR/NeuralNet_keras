{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "colab_type": "code",
    "id": "2V9a9L4W7bGn",
    "outputId": "8d92bfb8-43f0-44a4-8c61-5ef105ed949e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "kIkzm2u97mtY",
    "outputId": "b66e9256-eddd-4a52-aaf0-d695cba8265f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'My Drive'\n"
     ]
    }
   ],
   "source": [
    "!ls \"/content/drive\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uAXzuLZlC3QM"
   },
   "source": [
    "**SVHN neural network using Keras**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JPD7fT3GC7B-"
   },
   "source": [
    "### Loading the dataset : Lets us load the training and the test data and check the size of the tensors. Lets us also display the first few images from the training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 158
    },
    "colab_type": "code",
    "id": "BThSVwaj7orv",
    "outputId": "931f5a92-098d-47ff-ef1d-40b6e25158b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (42000, 32, 32) (42000,)\n",
      "Test set (18000, 32, 32) (18000,)\n",
      "\n",
      "\n",
      "Training set (42000, 1024) (42000, 10)\n",
      "Test set (18000, 1024) (18000, 10)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "# Open the file as readonly\n",
    "h5f = h5py.File('/content/drive/My Drive/DLCP/Project-1/Data/SVHN_single_grey1.h5', 'r')\n",
    "\n",
    "# Load the training, test and validation set\n",
    "X_train = h5f['X_train'][:]\n",
    "y_train = h5f['y_train'][:]\n",
    "X_val = h5f['X_test'][:]\n",
    "y_val = h5f['y_test'][:]\n",
    "\n",
    "\n",
    "# Close this file\n",
    "\n",
    "h5f.close()\n",
    "\n",
    "### Print the Training and validation set shapes\n",
    "print('Training set', X_train.shape, y_train.shape)\n",
    "print('Test set', X_val.shape, y_val.shape)\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "# Flatten the images for keras model\n",
    "X_train = X_train.reshape(X_train.shape[0],1024)\n",
    "X_val = X_val.reshape(X_val.shape[0],1024)\n",
    "\n",
    "# normalize inputs from 0-255 to 0-1\n",
    "X_train /= 255.0\n",
    "X_val /= 255.0\n",
    "\n",
    "y_train_label = y_train\n",
    "y_test_label = y_val\n",
    "\n",
    "\n",
    "# convert class vectors to binary class matrices for keras\n",
    "num_classes = 10\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_val = tf.keras.utils.to_categorical(y_val, num_classes)\n",
    "\n",
    "# Print the Training and Test Set shapes\n",
    "print('Training set', X_train.shape, y_train.shape)\n",
    "print('Test set', X_val.shape, y_val.shape)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e63Y5OjSNWvQ"
   },
   "source": [
    "When you print the shapes of the training and test sets, they should be as below:\n",
    "\n",
    "('Training set', (42000, 32, 32), (42000,))\n",
    "('Test set', (18000, 32, 32), (18000,))\n",
    "\n",
    "\n",
    "('Training set', (42000, 1024), (42000, 10))\n",
    "('Test set', (18000, 1024), (18000, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1616
    },
    "colab_type": "code",
    "id": "SOgQmL-l7sRj",
    "outputId": "57cbfb79-b194-4822-d8e5-3af2e6f3d1c8"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAI0AAACOCAYAAAAMyosLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n0JgyFhpTxkJjylhoTJnfmpF0qMv7v3YAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label :1\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAI0AAACOCAYAAAAMyosLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMWksNCaNhcaksdCYNBYak8ZCY9L8B850VtG9EmbwAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label :1\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAI0AAACOCAYAAAAMyosLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label :0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAI0AAACOCAYAAAAMyosLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nturU5JD34wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label :2\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAI0AAACOCAYAAAAMyosLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label :9\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAI0AAACOCAYAAAAMyosLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label :0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAI0AAACOCAYAAAAMyosLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAC09JREFUeJztndeLVk8ShsufOY05i2kUnVHBhAqC\n13rhPy0iCOLFiJgx55yz7tX2Pv3udPOVMGdZeJ+r+qbP9AkUXanDrD9//oQxGf75Xz+A+f/DSmPS\nWGlMGiuNSWOlMWmsNCaNlcaksdKYNHOGuMmZM2dKBvGff2o9ff36dZE/fvxYtf3+/Xta+evXryNd\nFxGxZMmSIv/48aPI3759q66bPXt2kefMmdNsmzdvXrTgu2kf+t6ttlmzZk0rR0QwEbtq1aqq7dix\nY0U+depUkScnJ6vrFixYUOTe9x4bG6tvzudtNRjTwkpj0gxink6fPl1kNR80E1NTU1XbvXv3ivzy\n5csia73s06dPRf78+XPVxiGYpmr58uXVdWvXri3y3LlzqzaaGsq/fv2qruMzUtbn6pmq+fPnF3nh\nwoVV28+fP6d9joiIN2/eFJnvrGa49/yj1iE90pg0VhqTxkpj0gzi0xw5cqTZRvv76NGjqu3u3btF\nZristph+ktr6ZcuWFXnPnj1FnpiYqK4bHx8vsvoc7JPh9/v376vr6Mfcv3+/auO7MM2g/Wg6gfC9\n9RvwN/tQn4Yh99/OpfJIY9JYaUyaQczT0qVLm23Pnj0rsoapr169mlbWTCmHXJqZiIjdu3cX+fDh\nw0WmqdI+Pnz4ULUxXOa9afoiIjZt2lTkDRs2VG0rVqwo8rVr15r9M32g5qOXFefv79+/TytH1GZe\nv6P+buGRxqSx0pg0VhqTZhCfhuEgbWpExK1bt4r84MGDqo3hOPtQ28uSwL59+6q248ePT9u2evXq\n6rrnz58X+cWLF81nZJpf/Sf6MVqmYAlDw2WG4PRN9D17Ps2XL1+KTL+IckTEokWLiqw+k6YrWnik\nMWmsNCbNIOaJ4SyH0Yh6mGW2NaIO1dWskTVr1hR5x44dVdu2bduKzKqxZnNpkq5fv161XblyZdpn\n1Go4TR7D74j6G/RMC+V3795FC+2DmV/2oSaoZ+Y1e9zCI41JY6UxaQYxT/T6OZEooh7iR51/OzY2\nVrVt3ry5yNu3b6/aaLrYh86PZZTBSCqiLj7yGZnNjvjvTDLhnN6dO3dWbfw+vLdmjokWVXVy2yj/\n99d9jHSVMcBKY9JYaUyaQXwaVlo15GYorRVZhpz8v/Xr11fXbdy4scga6jIDynCTf1c0Y8t70yfT\nbOvbt2+nlSNqP0yzxcwk812ePHlSXcd76zMyXOY31ZC7V8l2ldvMGFYak2YQ80Q068vfGvLxN8ND\nFv8i6glO2sYhlwU5Ddt5XW9I5zNplpr/xwxwRJ2N1v9jG02XZpxpkvRbMYXASV2aOeYzaoHS657M\njGGlMWmsNCbNID5Nb6sO+iBqY2nTKesaZ7Zp2Mgwnj6BrvnuwT74/JyQpb81Rc9n1HCZ780+1Mdg\nWK0Vab4PUwSaxuC9e2WbHh5pTBorjUkz+BxhHbYZmqp54jBLk6ThJodmrV5zYhSr0GqemG3VSjyf\nn1lqnSRFc9KrIOvzMztNU67hci/twD75XBre98ykpkNaeKQxaaw0Js3gGWGll6FsTQpS88H5vtwR\nKiJi69atRW5lhyPqSEIzsRy2ewVLtvV2u9L3YoTTmwg16gQqmjU1T73nGhWPNCaNlcaksdKYNIP4\nNK2dpCL6YSr/jzZbJ3JxzZJOCmf4ydBWN29mCK4TubiWij7TypUrY1R64Sx9EPpJvWyuZot5bWvb\nkYj2zIEIT8IyM4iVxqQZvGCpoS6HRB0uGQZzmNVMLNcfccPqiNrUUNY5wjRXu3btqtoY0vNeixcv\njhZqjviemunlrhE0r2qGeyE9++T/aWGTZm3UDLDikcaksdKYNFYak2YQn2bUc5B0UhP9AKbDNX3P\nnT/v3LlTtXHSOf0iXXvEKrpWkLmLJ30HvY7vpuFrq1IeUe8A9vTp0yL31ob3ShGUtYyglW3iKreZ\nMaw0Js0g5qm3ixVNUm9IZ7ipYSTNk55JQLPD4Z5mK6LedUs3waY5oXnSObbsozehjM8bEXH79u0i\nP378uMhaze+lJ/i7961IL/3RwyONSWOlMWkGMU/MQqrX39u7trX8RIdcXtfbe5e7MOh5DTQ1aj4Y\nrTHq0qLnunXrpu0voi50atb6xo0b016n9E7SJa3iZURtunrLfnt4pDFprDQmjZXGpBk85NYwsre9\nRWtbD7XnDNt1PdPDhw+LzMlamn2mH6B9MDznZtb0YSLqDLGuv+JxhDdv3qzaWDlvnQehz6whN78P\n+9DsOX0cH7FsBsNKY9IMvixXQ+7eOpyRC2joQ7PP/M2sbC9jq8M0N0/k5tY6l5hmUzPTly5dKjLP\nWoiow+y/3WSxlQVWM8msuM4fdsHSzBhWGpPGSmPSDOLT9GwxfYte1bV38EZvZ87W+Uxqz3lv7Z+h\nNQ/v0COW6T/Qh4mIOHfuXJF1ohj9Kfpn6v/1yggtf0TLCL11VbrDWAuPNCaNlcakGcQ8cbjXkJhD\nsJoFrk1illaHYvbZm/DVO4eBzzE5OVm1HThwoMg8x4DzeSPq85kuXrxYtXEesM795b1pJntHCfbO\nzeJ7ana7931GxSONSWOlMWmsNCbN4GdY6qy73mwx2m3a5l6VW+H9ejMIedblxMRE1cZyAX0CrVaf\nPXu2yJcvX67auB5cD9ug78Y29X1G9d1aRzbr/406kVzxSGPSWGlMmsF3wtKsL02LmoyW6dI+epPT\nW9tz6C5WJ0+eLPLBgwerNk5C54QpNU+caKWmhX1wIldExJYtW4rMdIIescxJZNo/35PpBJ2E1csI\nq9ls4ZHGpLHSmDSDbz6dOS6GwyV3ndI+aHY0OuNwzwhp586d1XWHDh0qMjdm1P57O0+wT50/zOIm\nJ3VF1EVQmmhdf8XJWr2jG3u7hvEUXzVPo+KRxqSx0pg0VhqTZhCfprczE39r6Eyfhn6MhuLMemqI\nyar0+Ph4kffv319dxwnjGo7zfpyopLt77tmzp8hahWZqQTPYrFDTB9FqPr9jbwsRPq+G5sysq0/j\ndU9mxrDSmDSDh9y9/fh1uOcyV2ZDdWhmuKnzdhk+79u3r8hqnsbGxprPzGGbpkTDaobOvfVc+vw0\nZTQnWlDk/6mJbk3QUhPUywj3zpoiHmlMGiuNSWOlMWkG33xat+yiL0GfIKL2GbhliK5P5lYge/fu\nrdqOHj1aZE6uYogdUYe3mhZgW29demuNVUR/2zLCtIOuQ+J37B3Y0Sp7RNTfrndgRw+PNCaNlcak\nGcQ8MVTUIZBZ37Vr11ZtrAZzg2btg5OYTpw4UbXxt+7oSWgyNGNLM8R763PQLGh2lX2oaeG9e6ac\nJqiXcaYJ1WW5zAjrmqhelpl4pDFprDQmzSDm6erVq/+5oRQlOWz3jqrhMg89Modmp7fzASMHHYo5\nvKtZaJ3229u5Qdt6WdrWsUS9Y3d6GeFegZgmaVRzpHikMWmsNCaNlcakGcSnOX/+fJF1UjhDUw0B\nuZUH2zQTS19I1yLRl6DfomEv+9RwuZeJJUwf6BoiPof6Ga2zoHRCWW9ZLn2aXujfy2j7vCczY1hp\nTJpBzNOFCxeKrOaJw7ZmLxk6tpbXRtTzaqempqo2borYCp0j+ktSe6EuYbjPFEFEHcarGaDp5VGI\nuoG1FmpJa0cMDe97ZtJzhM2MYaUxaaw0Js0gPg1tsfoj9C00rU0bS59DSwX0M3RiUcsP6B3sof4O\nf7cq3hH9LVV679kqI6g/wvJJzzfsrdHmvXWdt4b4LTzSmDRWGpNm1qhhljH/xiONSWOlMWmsNCaN\nlcaksdKYNFYak8ZKY9JYaUwaK41JY6Uxaaw0Jo2VxqSx0pg0VhqTxkpj0lhpTBorjUljpTFprDQm\njZXGpLHSmDRWGpPGSmPS/AtgHiwKROLXZQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label :2\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAI0AAACOCAYAAAAMyosLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCWUiNKFMhCaU+Q8sJSL8WXAztQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label :5\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAI0AAACOCAYAAAAMyosLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ntEFooA1CA20QGmjzF4VgffPZ60SEAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label :1\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAI0AAACOCAYAAAAMyosLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWJ0fFAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label :3\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "# Visualizing the first 10 images in the dataset and their labels\n",
    "\n",
    "for i in range(30,40):\n",
    "  plt.figure(figsize=(2,2))\n",
    "  img = X_train[i].reshape(32,32)\n",
    "  plt.imshow(img, cmap='gray')\n",
    "  plt.axis('off')\n",
    "  plt.show()  \n",
    "  print(\"Label :{}\".format(y_train_label[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R4Xt70dRDMJQ"
   },
   "source": [
    "###Build the Neural Network Model in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1O-gJvEC8yIw"
   },
   "outputs": [],
   "source": [
    "# define the train and test loops and return score\n",
    "def train_and_test_loop(iterations, lr, Lambda,verb=True):\n",
    "    ## Define hyperparameters\n",
    "    iterations = iterations\n",
    "    learning_rate = lr\n",
    "    hidden_nodes = 64\n",
    "    output_nodes = 10\n",
    "   \n",
    "    # Build the building blocks : Hidden layers, output layers, activation functions, optimizers\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(hidden_nodes, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(output_nodes, activation='softmax'))\n",
    "    sgd = tf.keras.optimizers.SGD(lr=lr,decay=Lambda, momentum=0.9)\n",
    "      \n",
    "    # Compile the model\n",
    "    model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "  \n",
    "    # Fit the model\n",
    "    model.fit(X_train,y_train, validation_data=(X_val,y_val), epochs=iterations, batch_size=256,verbose=verb)\n",
    "    \n",
    "    return model\n",
    "\n",
    "    \n",
    "def train_and_test_loop1(iterations, lr, Lambda, verb=True):\n",
    "    ## hyperparameters\n",
    "    iterations = iterations\n",
    "    learning_rate = lr\n",
    "    hidden_nodes = 64\n",
    "    output_nodes = 10\n",
    "\n",
    "    #Build the building blocks : Hidden layers, output layers, activation functions, optimizers\n",
    "    model = tf.keras.models.Sequential()    \n",
    "    model.add(tf.keras.layers.Dense(hidden_nodes, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(output_nodes, activation='softmax'))\n",
    "    sgd = tf.keras.optimizers.SGD(lr=lr,decay=Lambda,momentum=0.9)\n",
    "\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(X_train,y_train, validation_data=(X_val,y_val), epochs=iterations, batch_size=256,verbose=verb)\n",
    "    \n",
    "    # Calculate score and return score\n",
    "    score = model.evaluate(X_val,y_val, verbose=0)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PgZ3BaUYDKc1"
   },
   "source": [
    "### Babysitting the learning process. Complete all the steps below to optimize your model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iEGNyNcwDo5z"
   },
   "source": [
    "### Step 1: Double Check that the loss is reasonable : Disable the regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "V9ovvBhe84cN",
    "outputId": "cc6ceac7-9262-4d41-9724-558e5d122c4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples, validate on 18000 samples\n",
      "42000/42000 [==============================] - 1s 23us/sample - loss: 2.3033 - acc: 0.1256 - val_loss: 2.2790 - val_acc: 0.1656\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.2789849965837266, 0.16555555]"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the hyperparameters\n",
    "lr = 0.01\n",
    "Lambda = 0\n",
    "# Call the train and test function\n",
    "train_and_test_loop1(iterations=1, lr=lr,Lambda=Lambda, verb=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L7wfLkUnDm8B"
   },
   "source": [
    "Is the loss range correct?? What about accuracy, does it make sense for an untrained network?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nx6aiJkp99KY"
   },
   "source": [
    "**Observation **: Loss and accuracy makes sense for an untrained network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6IjjvVZOD7dp"
   },
   "source": [
    "### Step 2: Now, lets crank up the Lambda(Regularization)and check what it does to our loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "colab_type": "code",
    "id": "Ym-j6D4s88M4",
    "outputId": "7955757e-be78-4723-ed47-226dc34da325"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples, validate on 18000 samples\n",
      "Epoch 1/10\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 2.3551 - acc: 0.1026 - val_loss: 2.3225 - val_acc: 0.1072\n",
      "Epoch 2/10\n",
      "42000/42000 [==============================] - 1s 20us/sample - loss: 2.3205 - acc: 0.1054 - val_loss: 2.3169 - val_acc: 0.1051\n",
      "Epoch 3/10\n",
      "42000/42000 [==============================] - 1s 20us/sample - loss: 2.3165 - acc: 0.1035 - val_loss: 2.3147 - val_acc: 0.1039\n",
      "Epoch 4/10\n",
      "42000/42000 [==============================] - 1s 20us/sample - loss: 2.3146 - acc: 0.1033 - val_loss: 2.3135 - val_acc: 0.1043\n",
      "Epoch 5/10\n",
      "42000/42000 [==============================] - 1s 20us/sample - loss: 2.3134 - acc: 0.1030 - val_loss: 2.3126 - val_acc: 0.1044\n",
      "Epoch 6/10\n",
      "42000/42000 [==============================] - 1s 20us/sample - loss: 2.3126 - acc: 0.1022 - val_loss: 2.3120 - val_acc: 0.1043\n",
      "Epoch 7/10\n",
      "42000/42000 [==============================] - 1s 20us/sample - loss: 2.3120 - acc: 0.1029 - val_loss: 2.3116 - val_acc: 0.1044\n",
      "Epoch 8/10\n",
      "42000/42000 [==============================] - 1s 20us/sample - loss: 2.3115 - acc: 0.1021 - val_loss: 2.3112 - val_acc: 0.1041\n",
      "Epoch 9/10\n",
      "42000/42000 [==============================] - 1s 20us/sample - loss: 2.3111 - acc: 0.1020 - val_loss: 2.3109 - val_acc: 0.1036\n",
      "Epoch 10/10\n",
      "42000/42000 [==============================] - 1s 20us/sample - loss: 2.3108 - acc: 0.1019 - val_loss: 2.3106 - val_acc: 0.1033\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x7f68ba07ee10>"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the hyperparameters (Crank up the lambda value)\n",
    "lr = 0.01\n",
    "Lambda = 0.9\n",
    "# Call the train and test function\n",
    "train_and_test_loop(iterations=10, lr=lr,Lambda=Lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h98A3an8D6Vj"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x9UI4XDc-Nna"
   },
   "source": [
    " **Observation**: Loss value increased as compared to Loss value of 1st epoch of previous model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WdpcPj8ZEF0Z"
   },
   "source": [
    "### Step 3: Now, lets overfit to a small subset of our dataset, in this case 20 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iPOFCVcf8_VC"
   },
   "outputs": [],
   "source": [
    "X_train_subset = X_train[30:50,]\n",
    "y_train_subset = y_train[30:50,]\n",
    "\n",
    "X_train = X_train_subset\n",
    "y_train = y_train_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "0XeMU5vE9iyk",
    "outputId": "0b9beaf1-4bea-4e3e-849b-5a7bfd6adf70"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 1024)"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the X_train shape\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "BeCfUg-m9mYI",
    "outputId": "40c341da-9bf1-4dd6-d694-d065b2cd66a7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 10)"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the y_train shape\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jyqGMHrdENv8"
   },
   "source": [
    "### Tip: Make sure that you can overfit very small portion of the training data\n",
    "So, set a small learning rate and turn regularization off\n",
    "\n",
    "In the code below:\n",
    "- Take the first 20 examples from SVHN\n",
    "- turn off regularization(reg=0.0)\n",
    "- use simple vanilla 'sgd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 7163
    },
    "colab_type": "code",
    "id": "alVKKexl9pBY",
    "outputId": "24d18efe-1f2b-4523-9d11-71bc9325f4f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20 samples, validate on 18000 samples\n",
      "Epoch 1/200\n",
      "20/20 [==============================] - 1s 29ms/sample - loss: 2.4309 - acc: 0.1000 - val_loss: 2.3865 - val_acc: 0.1057\n",
      "Epoch 2/200\n",
      "20/20 [==============================] - 0s 9ms/sample - loss: 2.2502 - acc: 0.2500 - val_loss: 2.4061 - val_acc: 0.1007\n",
      "Epoch 3/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 2.1026 - acc: 0.2000 - val_loss: 2.4793 - val_acc: 0.1001\n",
      "Epoch 4/200\n",
      "20/20 [==============================] - 0s 9ms/sample - loss: 2.0252 - acc: 0.2000 - val_loss: 2.5614 - val_acc: 0.0989\n",
      "Epoch 5/200\n",
      "20/20 [==============================] - 0s 9ms/sample - loss: 1.9973 - acc: 0.3000 - val_loss: 2.6343 - val_acc: 0.0994\n",
      "Epoch 6/200\n",
      "20/20 [==============================] - 0s 9ms/sample - loss: 1.9696 - acc: 0.3500 - val_loss: 2.6685 - val_acc: 0.0996\n",
      "Epoch 7/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 1.9179 - acc: 0.3000 - val_loss: 2.6485 - val_acc: 0.1006\n",
      "Epoch 8/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 1.8451 - acc: 0.3500 - val_loss: 2.6169 - val_acc: 0.1014\n",
      "Epoch 9/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 1.7940 - acc: 0.4000 - val_loss: 2.6157 - val_acc: 0.1016\n",
      "Epoch 10/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 1.7557 - acc: 0.5000 - val_loss: 2.6353 - val_acc: 0.1020\n",
      "Epoch 11/200\n",
      "20/20 [==============================] - 0s 9ms/sample - loss: 1.7008 - acc: 0.4500 - val_loss: 2.6597 - val_acc: 0.1044\n",
      "Epoch 12/200\n",
      "20/20 [==============================] - 0s 9ms/sample - loss: 1.6407 - acc: 0.5000 - val_loss: 2.6752 - val_acc: 0.1058\n",
      "Epoch 13/200\n",
      "20/20 [==============================] - 0s 9ms/sample - loss: 1.5738 - acc: 0.5000 - val_loss: 2.7084 - val_acc: 0.1065\n",
      "Epoch 14/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 1.5212 - acc: 0.5500 - val_loss: 2.7582 - val_acc: 0.1067\n",
      "Epoch 15/200\n",
      "20/20 [==============================] - 0s 9ms/sample - loss: 1.4680 - acc: 0.5500 - val_loss: 2.8107 - val_acc: 0.1064\n",
      "Epoch 16/200\n",
      "20/20 [==============================] - 0s 9ms/sample - loss: 1.4166 - acc: 0.5500 - val_loss: 2.8396 - val_acc: 0.1068\n",
      "Epoch 17/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 1.3622 - acc: 0.6000 - val_loss: 2.8373 - val_acc: 0.1091\n",
      "Epoch 18/200\n",
      "20/20 [==============================] - 0s 9ms/sample - loss: 1.3027 - acc: 0.6000 - val_loss: 2.8318 - val_acc: 0.1129\n",
      "Epoch 19/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 1.2538 - acc: 0.8000 - val_loss: 2.8503 - val_acc: 0.1104\n",
      "Epoch 20/200\n",
      "20/20 [==============================] - 0s 9ms/sample - loss: 1.2084 - acc: 0.7000 - val_loss: 2.8903 - val_acc: 0.1089\n",
      "Epoch 21/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 1.1625 - acc: 0.6500 - val_loss: 2.9229 - val_acc: 0.1103\n",
      "Epoch 22/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 1.1126 - acc: 0.6000 - val_loss: 2.9517 - val_acc: 0.1122\n",
      "Epoch 23/200\n",
      "20/20 [==============================] - 0s 9ms/sample - loss: 1.0656 - acc: 0.7500 - val_loss: 2.9937 - val_acc: 0.1136\n",
      "Epoch 24/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 1.0245 - acc: 0.8000 - val_loss: 3.0445 - val_acc: 0.1133\n",
      "Epoch 25/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.9824 - acc: 0.8500 - val_loss: 3.0876 - val_acc: 0.1128\n",
      "Epoch 26/200\n",
      "20/20 [==============================] - 0s 9ms/sample - loss: 0.9408 - acc: 0.8000 - val_loss: 3.1075 - val_acc: 0.1139\n",
      "Epoch 27/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.8982 - acc: 0.8500 - val_loss: 3.1303 - val_acc: 0.1148\n",
      "Epoch 28/200\n",
      "20/20 [==============================] - 0s 9ms/sample - loss: 0.8606 - acc: 0.9000 - val_loss: 3.1654 - val_acc: 0.1158\n",
      "Epoch 29/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.8237 - acc: 0.9000 - val_loss: 3.2075 - val_acc: 0.1162\n",
      "Epoch 30/200\n",
      "20/20 [==============================] - 0s 9ms/sample - loss: 0.7868 - acc: 0.9000 - val_loss: 3.2432 - val_acc: 0.1153\n",
      "Epoch 31/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.7518 - acc: 0.9000 - val_loss: 3.2692 - val_acc: 0.1155\n",
      "Epoch 32/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.7185 - acc: 0.9000 - val_loss: 3.3003 - val_acc: 0.1142\n",
      "Epoch 33/200\n",
      "20/20 [==============================] - 0s 9ms/sample - loss: 0.6877 - acc: 0.9000 - val_loss: 3.3421 - val_acc: 0.1147\n",
      "Epoch 34/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.6557 - acc: 0.9500 - val_loss: 3.3917 - val_acc: 0.1159\n",
      "Epoch 35/200\n",
      "20/20 [==============================] - 0s 9ms/sample - loss: 0.6252 - acc: 0.9500 - val_loss: 3.4392 - val_acc: 0.1156\n",
      "Epoch 36/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.5976 - acc: 0.9500 - val_loss: 3.4769 - val_acc: 0.1149\n",
      "Epoch 37/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.5705 - acc: 0.9500 - val_loss: 3.5110 - val_acc: 0.1160\n",
      "Epoch 38/200\n",
      "20/20 [==============================] - 0s 9ms/sample - loss: 0.5446 - acc: 0.9500 - val_loss: 3.5498 - val_acc: 0.1169\n",
      "Epoch 39/200\n",
      "20/20 [==============================] - 0s 11ms/sample - loss: 0.5196 - acc: 0.9500 - val_loss: 3.5964 - val_acc: 0.1164\n",
      "Epoch 40/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.4960 - acc: 0.9500 - val_loss: 3.6458 - val_acc: 0.1167\n",
      "Epoch 41/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.4743 - acc: 0.9500 - val_loss: 3.6880 - val_acc: 0.1162\n",
      "Epoch 42/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.4529 - acc: 1.0000 - val_loss: 3.7229 - val_acc: 0.1166\n",
      "Epoch 43/200\n",
      "20/20 [==============================] - 0s 9ms/sample - loss: 0.4322 - acc: 1.0000 - val_loss: 3.7551 - val_acc: 0.1179\n",
      "Epoch 44/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.4132 - acc: 1.0000 - val_loss: 3.7864 - val_acc: 0.1188\n",
      "Epoch 45/200\n",
      "20/20 [==============================] - 0s 9ms/sample - loss: 0.3950 - acc: 1.0000 - val_loss: 3.8179 - val_acc: 0.1202\n",
      "Epoch 46/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.3774 - acc: 1.0000 - val_loss: 3.8505 - val_acc: 0.1199\n",
      "Epoch 47/200\n",
      "20/20 [==============================] - 0s 9ms/sample - loss: 0.3608 - acc: 1.0000 - val_loss: 3.8845 - val_acc: 0.1201\n",
      "Epoch 48/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.3452 - acc: 1.0000 - val_loss: 3.9200 - val_acc: 0.1201\n",
      "Epoch 49/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.3301 - acc: 1.0000 - val_loss: 3.9580 - val_acc: 0.1200\n",
      "Epoch 50/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.3160 - acc: 1.0000 - val_loss: 3.9960 - val_acc: 0.1209\n",
      "Epoch 51/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.3025 - acc: 1.0000 - val_loss: 4.0307 - val_acc: 0.1205\n",
      "Epoch 52/200\n",
      "20/20 [==============================] - 0s 9ms/sample - loss: 0.2896 - acc: 1.0000 - val_loss: 4.0613 - val_acc: 0.1209\n",
      "Epoch 53/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.2772 - acc: 1.0000 - val_loss: 4.0888 - val_acc: 0.1205\n",
      "Epoch 54/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.2655 - acc: 1.0000 - val_loss: 4.1158 - val_acc: 0.1208\n",
      "Epoch 55/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.2547 - acc: 1.0000 - val_loss: 4.1441 - val_acc: 0.1213\n",
      "Epoch 56/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.2439 - acc: 1.0000 - val_loss: 4.1758 - val_acc: 0.1208\n",
      "Epoch 57/200\n",
      "20/20 [==============================] - 0s 9ms/sample - loss: 0.2339 - acc: 1.0000 - val_loss: 4.2111 - val_acc: 0.1211\n",
      "Epoch 58/200\n",
      "20/20 [==============================] - 0s 9ms/sample - loss: 0.2244 - acc: 1.0000 - val_loss: 4.2486 - val_acc: 0.1218\n",
      "Epoch 59/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.2153 - acc: 1.0000 - val_loss: 4.2857 - val_acc: 0.1218\n",
      "Epoch 60/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.2067 - acc: 1.0000 - val_loss: 4.3199 - val_acc: 0.1219\n",
      "Epoch 61/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.1985 - acc: 1.0000 - val_loss: 4.3501 - val_acc: 0.1223\n",
      "Epoch 62/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.1908 - acc: 1.0000 - val_loss: 4.3758 - val_acc: 0.1228\n",
      "Epoch 63/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.1835 - acc: 1.0000 - val_loss: 4.3974 - val_acc: 0.1231\n",
      "Epoch 64/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.1764 - acc: 1.0000 - val_loss: 4.4185 - val_acc: 0.1233\n",
      "Epoch 65/200\n",
      "20/20 [==============================] - 0s 9ms/sample - loss: 0.1698 - acc: 1.0000 - val_loss: 4.4396 - val_acc: 0.1232\n",
      "Epoch 66/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.1636 - acc: 1.0000 - val_loss: 4.4618 - val_acc: 0.1239\n",
      "Epoch 67/200\n",
      "20/20 [==============================] - 0s 9ms/sample - loss: 0.1576 - acc: 1.0000 - val_loss: 4.4853 - val_acc: 0.1243\n",
      "Epoch 68/200\n",
      "20/20 [==============================] - 0s 9ms/sample - loss: 0.1519 - acc: 1.0000 - val_loss: 4.5098 - val_acc: 0.1246\n",
      "Epoch 69/200\n",
      "20/20 [==============================] - 0s 9ms/sample - loss: 0.1466 - acc: 1.0000 - val_loss: 4.5339 - val_acc: 0.1244\n",
      "Epoch 70/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.1415 - acc: 1.0000 - val_loss: 4.5565 - val_acc: 0.1250\n",
      "Epoch 71/200\n",
      "20/20 [==============================] - 0s 9ms/sample - loss: 0.1366 - acc: 1.0000 - val_loss: 4.5778 - val_acc: 0.1252\n",
      "Epoch 72/200\n",
      "20/20 [==============================] - 0s 9ms/sample - loss: 0.1320 - acc: 1.0000 - val_loss: 4.5984 - val_acc: 0.1253\n",
      "Epoch 73/200\n",
      "20/20 [==============================] - 0s 9ms/sample - loss: 0.1277 - acc: 1.0000 - val_loss: 4.6185 - val_acc: 0.1254\n",
      "Epoch 74/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.1234 - acc: 1.0000 - val_loss: 4.6382 - val_acc: 0.1257\n",
      "Epoch 75/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.1195 - acc: 1.0000 - val_loss: 4.6577 - val_acc: 0.1258\n",
      "Epoch 76/200\n",
      "20/20 [==============================] - 0s 9ms/sample - loss: 0.1157 - acc: 1.0000 - val_loss: 4.6766 - val_acc: 0.1258\n",
      "Epoch 77/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.1121 - acc: 1.0000 - val_loss: 4.6955 - val_acc: 0.1256\n",
      "Epoch 78/200\n",
      "20/20 [==============================] - 0s 9ms/sample - loss: 0.1087 - acc: 1.0000 - val_loss: 4.7148 - val_acc: 0.1257\n",
      "Epoch 79/200\n",
      "20/20 [==============================] - 0s 9ms/sample - loss: 0.1054 - acc: 1.0000 - val_loss: 4.7343 - val_acc: 0.1259\n",
      "Epoch 80/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.1023 - acc: 1.0000 - val_loss: 4.7540 - val_acc: 0.1258\n",
      "Epoch 81/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.0993 - acc: 1.0000 - val_loss: 4.7735 - val_acc: 0.1259\n",
      "Epoch 82/200\n",
      "20/20 [==============================] - 0s 9ms/sample - loss: 0.0965 - acc: 1.0000 - val_loss: 4.7925 - val_acc: 0.1258\n",
      "Epoch 83/200\n",
      "20/20 [==============================] - 0s 9ms/sample - loss: 0.0938 - acc: 1.0000 - val_loss: 4.8107 - val_acc: 0.1257\n",
      "Epoch 84/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.0912 - acc: 1.0000 - val_loss: 4.8284 - val_acc: 0.1260\n",
      "Epoch 85/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.0887 - acc: 1.0000 - val_loss: 4.8459 - val_acc: 0.1261\n",
      "Epoch 86/200\n",
      "20/20 [==============================] - 0s 9ms/sample - loss: 0.0863 - acc: 1.0000 - val_loss: 4.8629 - val_acc: 0.1263\n",
      "Epoch 87/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.0840 - acc: 1.0000 - val_loss: 4.8795 - val_acc: 0.1264\n",
      "Epoch 88/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.0819 - acc: 1.0000 - val_loss: 4.8955 - val_acc: 0.1266\n",
      "Epoch 89/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.0798 - acc: 1.0000 - val_loss: 4.9111 - val_acc: 0.1265\n",
      "Epoch 90/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.0778 - acc: 1.0000 - val_loss: 4.9261 - val_acc: 0.1263\n",
      "Epoch 91/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.0759 - acc: 1.0000 - val_loss: 4.9407 - val_acc: 0.1264\n",
      "Epoch 92/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.0740 - acc: 1.0000 - val_loss: 4.9546 - val_acc: 0.1264\n",
      "Epoch 93/200\n",
      "20/20 [==============================] - 0s 9ms/sample - loss: 0.0723 - acc: 1.0000 - val_loss: 4.9679 - val_acc: 0.1265\n",
      "Epoch 94/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.0706 - acc: 1.0000 - val_loss: 4.9811 - val_acc: 0.1265\n",
      "Epoch 95/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.0689 - acc: 1.0000 - val_loss: 4.9941 - val_acc: 0.1263\n",
      "Epoch 96/200\n",
      "20/20 [==============================] - 0s 9ms/sample - loss: 0.0674 - acc: 1.0000 - val_loss: 5.0073 - val_acc: 0.1265\n",
      "Epoch 97/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.0659 - acc: 1.0000 - val_loss: 5.0205 - val_acc: 0.1267\n",
      "Epoch 98/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.0644 - acc: 1.0000 - val_loss: 5.0336 - val_acc: 0.1267\n",
      "Epoch 99/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.0630 - acc: 1.0000 - val_loss: 5.0463 - val_acc: 0.1269\n",
      "Epoch 100/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.0617 - acc: 1.0000 - val_loss: 5.0582 - val_acc: 0.1272\n",
      "Epoch 101/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.0604 - acc: 1.0000 - val_loss: 5.0689 - val_acc: 0.1272\n",
      "Epoch 102/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.0591 - acc: 1.0000 - val_loss: 5.0792 - val_acc: 0.1272\n",
      "Epoch 103/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.0579 - acc: 1.0000 - val_loss: 5.0893 - val_acc: 0.1272\n",
      "Epoch 104/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.0568 - acc: 1.0000 - val_loss: 5.0995 - val_acc: 0.1276\n",
      "Epoch 105/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.0557 - acc: 1.0000 - val_loss: 5.1103 - val_acc: 0.1274\n",
      "Epoch 106/200\n",
      "20/20 [==============================] - 0s 9ms/sample - loss: 0.0546 - acc: 1.0000 - val_loss: 5.1212 - val_acc: 0.1274\n",
      "Epoch 107/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.0535 - acc: 1.0000 - val_loss: 5.1323 - val_acc: 0.1275\n",
      "Epoch 108/200\n",
      "20/20 [==============================] - 0s 9ms/sample - loss: 0.0525 - acc: 1.0000 - val_loss: 5.1428 - val_acc: 0.1276\n",
      "Epoch 109/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.0515 - acc: 1.0000 - val_loss: 5.1527 - val_acc: 0.1278\n",
      "Epoch 110/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.0506 - acc: 1.0000 - val_loss: 5.1628 - val_acc: 0.1279\n",
      "Epoch 111/200\n",
      "20/20 [==============================] - 0s 9ms/sample - loss: 0.0497 - acc: 1.0000 - val_loss: 5.1729 - val_acc: 0.1282\n",
      "Epoch 112/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.0488 - acc: 1.0000 - val_loss: 5.1829 - val_acc: 0.1282\n",
      "Epoch 113/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.0479 - acc: 1.0000 - val_loss: 5.1929 - val_acc: 0.1282\n",
      "Epoch 114/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.0471 - acc: 1.0000 - val_loss: 5.2028 - val_acc: 0.1284\n",
      "Epoch 115/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.0463 - acc: 1.0000 - val_loss: 5.2125 - val_acc: 0.1286\n",
      "Epoch 116/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.0455 - acc: 1.0000 - val_loss: 5.2221 - val_acc: 0.1289\n",
      "Epoch 117/200\n",
      "20/20 [==============================] - 0s 9ms/sample - loss: 0.0447 - acc: 1.0000 - val_loss: 5.2315 - val_acc: 0.1289\n",
      "Epoch 118/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.0440 - acc: 1.0000 - val_loss: 5.2407 - val_acc: 0.1288\n",
      "Epoch 119/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.0433 - acc: 1.0000 - val_loss: 5.2492 - val_acc: 0.1289\n",
      "Epoch 120/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.0426 - acc: 1.0000 - val_loss: 5.2574 - val_acc: 0.1292\n",
      "Epoch 121/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.0419 - acc: 1.0000 - val_loss: 5.2654 - val_acc: 0.1291\n",
      "Epoch 122/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.0413 - acc: 1.0000 - val_loss: 5.2736 - val_acc: 0.1291\n",
      "Epoch 123/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.0406 - acc: 1.0000 - val_loss: 5.2819 - val_acc: 0.1292\n",
      "Epoch 124/200\n",
      "20/20 [==============================] - 0s 9ms/sample - loss: 0.0400 - acc: 1.0000 - val_loss: 5.2903 - val_acc: 0.1290\n",
      "Epoch 125/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.0394 - acc: 1.0000 - val_loss: 5.2985 - val_acc: 0.1291\n",
      "Epoch 126/200\n",
      "20/20 [==============================] - 0s 11ms/sample - loss: 0.0388 - acc: 1.0000 - val_loss: 5.3067 - val_acc: 0.1289\n",
      "Epoch 127/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.0382 - acc: 1.0000 - val_loss: 5.3149 - val_acc: 0.1289\n",
      "Epoch 128/200\n",
      "20/20 [==============================] - 0s 9ms/sample - loss: 0.0377 - acc: 1.0000 - val_loss: 5.3230 - val_acc: 0.1290\n",
      "Epoch 129/200\n",
      "20/20 [==============================] - 0s 9ms/sample - loss: 0.0371 - acc: 1.0000 - val_loss: 5.3308 - val_acc: 0.1289\n",
      "Epoch 130/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.0366 - acc: 1.0000 - val_loss: 5.3381 - val_acc: 0.1291\n",
      "Epoch 131/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.0361 - acc: 1.0000 - val_loss: 5.3452 - val_acc: 0.1293\n",
      "Epoch 132/200\n",
      "20/20 [==============================] - 0s 9ms/sample - loss: 0.0356 - acc: 1.0000 - val_loss: 5.3523 - val_acc: 0.1294\n",
      "Epoch 133/200\n",
      "20/20 [==============================] - 0s 9ms/sample - loss: 0.0351 - acc: 1.0000 - val_loss: 5.3596 - val_acc: 0.1292\n",
      "Epoch 134/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.0346 - acc: 1.0000 - val_loss: 5.3670 - val_acc: 0.1292\n",
      "Epoch 135/200\n",
      "20/20 [==============================] - 0s 9ms/sample - loss: 0.0342 - acc: 1.0000 - val_loss: 5.3744 - val_acc: 0.1293\n",
      "Epoch 136/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.0337 - acc: 1.0000 - val_loss: 5.3823 - val_acc: 0.1295\n",
      "Epoch 137/200\n",
      "20/20 [==============================] - 0s 9ms/sample - loss: 0.0332 - acc: 1.0000 - val_loss: 5.3899 - val_acc: 0.1296\n",
      "Epoch 138/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.0328 - acc: 1.0000 - val_loss: 5.3974 - val_acc: 0.1297\n",
      "Epoch 139/200\n",
      "20/20 [==============================] - 0s 9ms/sample - loss: 0.0324 - acc: 1.0000 - val_loss: 5.4044 - val_acc: 0.1297\n",
      "Epoch 140/200\n",
      "20/20 [==============================] - 0s 9ms/sample - loss: 0.0320 - acc: 1.0000 - val_loss: 5.4109 - val_acc: 0.1298\n",
      "Epoch 141/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.0316 - acc: 1.0000 - val_loss: 5.4171 - val_acc: 0.1294\n",
      "Epoch 142/200\n",
      "20/20 [==============================] - 0s 9ms/sample - loss: 0.0312 - acc: 1.0000 - val_loss: 5.4234 - val_acc: 0.1294\n",
      "Epoch 143/200\n",
      "20/20 [==============================] - 0s 9ms/sample - loss: 0.0308 - acc: 1.0000 - val_loss: 5.4297 - val_acc: 0.1295\n",
      "Epoch 144/200\n",
      "20/20 [==============================] - 0s 9ms/sample - loss: 0.0304 - acc: 1.0000 - val_loss: 5.4361 - val_acc: 0.1296\n",
      "Epoch 145/200\n",
      "20/20 [==============================] - 0s 9ms/sample - loss: 0.0301 - acc: 1.0000 - val_loss: 5.4425 - val_acc: 0.1296\n",
      "Epoch 146/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.0297 - acc: 1.0000 - val_loss: 5.4488 - val_acc: 0.1297\n",
      "Epoch 147/200\n",
      "20/20 [==============================] - 0s 9ms/sample - loss: 0.0293 - acc: 1.0000 - val_loss: 5.4551 - val_acc: 0.1297\n",
      "Epoch 148/200\n",
      "20/20 [==============================] - 0s 9ms/sample - loss: 0.0290 - acc: 1.0000 - val_loss: 5.4615 - val_acc: 0.1297\n",
      "Epoch 149/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.0287 - acc: 1.0000 - val_loss: 5.4675 - val_acc: 0.1297\n",
      "Epoch 150/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.0283 - acc: 1.0000 - val_loss: 5.4733 - val_acc: 0.1295\n",
      "Epoch 151/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.0280 - acc: 1.0000 - val_loss: 5.4788 - val_acc: 0.1297\n",
      "Epoch 152/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.0277 - acc: 1.0000 - val_loss: 5.4847 - val_acc: 0.1299\n",
      "Epoch 153/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.0274 - acc: 1.0000 - val_loss: 5.4907 - val_acc: 0.1299\n",
      "Epoch 154/200\n",
      "20/20 [==============================] - 0s 9ms/sample - loss: 0.0271 - acc: 1.0000 - val_loss: 5.4968 - val_acc: 0.1300\n",
      "Epoch 155/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.0268 - acc: 1.0000 - val_loss: 5.5030 - val_acc: 0.1301\n",
      "Epoch 156/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.0265 - acc: 1.0000 - val_loss: 5.5091 - val_acc: 0.1298\n",
      "Epoch 157/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.0262 - acc: 1.0000 - val_loss: 5.5152 - val_acc: 0.1298\n",
      "Epoch 158/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.0259 - acc: 1.0000 - val_loss: 5.5211 - val_acc: 0.1298\n",
      "Epoch 159/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.0256 - acc: 1.0000 - val_loss: 5.5267 - val_acc: 0.1298\n",
      "Epoch 160/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.0254 - acc: 1.0000 - val_loss: 5.5318 - val_acc: 0.1299\n",
      "Epoch 161/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.0251 - acc: 1.0000 - val_loss: 5.5367 - val_acc: 0.1298\n",
      "Epoch 162/200\n",
      "20/20 [==============================] - 0s 9ms/sample - loss: 0.0249 - acc: 1.0000 - val_loss: 5.5415 - val_acc: 0.1299\n",
      "Epoch 163/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.0246 - acc: 1.0000 - val_loss: 5.5464 - val_acc: 0.1300\n",
      "Epoch 164/200\n",
      "20/20 [==============================] - 0s 9ms/sample - loss: 0.0244 - acc: 1.0000 - val_loss: 5.5516 - val_acc: 0.1300\n",
      "Epoch 165/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.0241 - acc: 1.0000 - val_loss: 5.5569 - val_acc: 0.1299\n",
      "Epoch 166/200\n",
      "20/20 [==============================] - 0s 11ms/sample - loss: 0.0239 - acc: 1.0000 - val_loss: 5.5625 - val_acc: 0.1299\n",
      "Epoch 167/200\n",
      "20/20 [==============================] - 0s 9ms/sample - loss: 0.0236 - acc: 1.0000 - val_loss: 5.5683 - val_acc: 0.1297\n",
      "Epoch 168/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.0234 - acc: 1.0000 - val_loss: 5.5739 - val_acc: 0.1297\n",
      "Epoch 169/200\n",
      "20/20 [==============================] - 0s 9ms/sample - loss: 0.0232 - acc: 1.0000 - val_loss: 5.5796 - val_acc: 0.1296\n",
      "Epoch 170/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.0229 - acc: 1.0000 - val_loss: 5.5848 - val_acc: 0.1296\n",
      "Epoch 171/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.0227 - acc: 1.0000 - val_loss: 5.5899 - val_acc: 0.1296\n",
      "Epoch 172/200\n",
      "20/20 [==============================] - 0s 9ms/sample - loss: 0.0225 - acc: 1.0000 - val_loss: 5.5947 - val_acc: 0.1294\n",
      "Epoch 173/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.0223 - acc: 1.0000 - val_loss: 5.5996 - val_acc: 0.1294\n",
      "Epoch 174/200\n",
      "20/20 [==============================] - 0s 9ms/sample - loss: 0.0221 - acc: 1.0000 - val_loss: 5.6045 - val_acc: 0.1293\n",
      "Epoch 175/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.0219 - acc: 1.0000 - val_loss: 5.6094 - val_acc: 0.1293\n",
      "Epoch 176/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.0217 - acc: 1.0000 - val_loss: 5.6146 - val_acc: 0.1294\n",
      "Epoch 177/200\n",
      "20/20 [==============================] - 0s 9ms/sample - loss: 0.0215 - acc: 1.0000 - val_loss: 5.6199 - val_acc: 0.1295\n",
      "Epoch 178/200\n",
      "20/20 [==============================] - 0s 9ms/sample - loss: 0.0213 - acc: 1.0000 - val_loss: 5.6251 - val_acc: 0.1296\n",
      "Epoch 179/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.0211 - acc: 1.0000 - val_loss: 5.6303 - val_acc: 0.1296\n",
      "Epoch 180/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.0209 - acc: 1.0000 - val_loss: 5.6352 - val_acc: 0.1294\n",
      "Epoch 181/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.0207 - acc: 1.0000 - val_loss: 5.6400 - val_acc: 0.1296\n",
      "Epoch 182/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.0205 - acc: 1.0000 - val_loss: 5.6447 - val_acc: 0.1296\n",
      "Epoch 183/200\n",
      "20/20 [==============================] - 0s 9ms/sample - loss: 0.0204 - acc: 1.0000 - val_loss: 5.6490 - val_acc: 0.1297\n",
      "Epoch 184/200\n",
      "20/20 [==============================] - 0s 9ms/sample - loss: 0.0202 - acc: 1.0000 - val_loss: 5.6533 - val_acc: 0.1296\n",
      "Epoch 185/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.0200 - acc: 1.0000 - val_loss: 5.6576 - val_acc: 0.1296\n",
      "Epoch 186/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.0198 - acc: 1.0000 - val_loss: 5.6619 - val_acc: 0.1295\n",
      "Epoch 187/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.0197 - acc: 1.0000 - val_loss: 5.6662 - val_acc: 0.1295\n",
      "Epoch 188/200\n",
      "20/20 [==============================] - 0s 9ms/sample - loss: 0.0195 - acc: 1.0000 - val_loss: 5.6706 - val_acc: 0.1296\n",
      "Epoch 189/200\n",
      "20/20 [==============================] - 0s 9ms/sample - loss: 0.0193 - acc: 1.0000 - val_loss: 5.6750 - val_acc: 0.1296\n",
      "Epoch 190/200\n",
      "20/20 [==============================] - 0s 9ms/sample - loss: 0.0192 - acc: 1.0000 - val_loss: 5.6794 - val_acc: 0.1297\n",
      "Epoch 191/200\n",
      "20/20 [==============================] - 0s 9ms/sample - loss: 0.0190 - acc: 1.0000 - val_loss: 5.6838 - val_acc: 0.1297\n",
      "Epoch 192/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.0189 - acc: 1.0000 - val_loss: 5.6880 - val_acc: 0.1298\n",
      "Epoch 193/200\n",
      "20/20 [==============================] - 0s 9ms/sample - loss: 0.0187 - acc: 1.0000 - val_loss: 5.6921 - val_acc: 0.1297\n",
      "Epoch 194/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.0186 - acc: 1.0000 - val_loss: 5.6962 - val_acc: 0.1297\n",
      "Epoch 195/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.0184 - acc: 1.0000 - val_loss: 5.7005 - val_acc: 0.1297\n",
      "Epoch 196/200\n",
      "20/20 [==============================] - 0s 9ms/sample - loss: 0.0183 - acc: 1.0000 - val_loss: 5.7049 - val_acc: 0.1297\n",
      "Epoch 197/200\n",
      "20/20 [==============================] - 0s 10ms/sample - loss: 0.0181 - acc: 1.0000 - val_loss: 5.7095 - val_acc: 0.1297\n",
      "Epoch 198/200\n",
      "20/20 [==============================] - 0s 9ms/sample - loss: 0.0180 - acc: 1.0000 - val_loss: 5.7140 - val_acc: 0.1297\n",
      "Epoch 199/200\n",
      "20/20 [==============================] - 0s 9ms/sample - loss: 0.0178 - acc: 1.0000 - val_loss: 5.7185 - val_acc: 0.1299\n",
      "Epoch 200/200\n",
      "20/20 [==============================] - 0s 9ms/sample - loss: 0.0177 - acc: 1.0000 - val_loss: 5.7233 - val_acc: 0.1299\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x7f68b4c2c748>"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set hyperparameters for Overfitting\n",
    "lr = 0.02\n",
    "Lambda = 0\n",
    "\n",
    "#call the train and test function (run it for sufficient epochs until the accuracy is going to 100%)\n",
    "train_and_test_loop(iterations=200, lr=lr,Lambda=Lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tbJuHVByEXjc"
   },
   "source": [
    "\n",
    "Very small loss,  train accuracy going to 100, nice! We are successful in overfitting. If your accuracy is not 100%, then tweak the hyperparameters and epoch values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mhHQOPICkx5j"
   },
   "source": [
    "**Observation**: Can see that model is overfitting since validation loss is much larger than training loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3t7jkmc1EgPj"
   },
   "source": [
    "### Loading the original dataset again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "zFS7IVbh91-v",
    "outputId": "ea1c673f-7d30-4c55-d1b0-95edd9e4a3c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train (42000, 1024) X_val : (18000, 1024)\n",
      "y_train (42000, 10) y_val : (18000, 10)\n"
     ]
    }
   ],
   "source": [
    "# Loading the original dataset\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "# Open the file as readonly\n",
    "h5f = h5py.File('/content/drive/My Drive/DLCP/Project-1/Data/SVHN_single_grey1.h5', 'r')\n",
    "\n",
    "# Load the training, test and validation set\n",
    "X_train = h5f['X_train'][:]\n",
    "y_train = h5f['y_train'][:]\n",
    "X_val = h5f['X_test'][:]\n",
    "y_val = h5f['y_test'][:]\n",
    "\n",
    "# Close this file(call the close function)\n",
    "h5f.close()\n",
    "\n",
    "#Flatten the images \n",
    "X_train = X_train.reshape(X_train.shape[0],1024)\n",
    "X_val = X_val.reshape(X_val.shape[0],1024)\n",
    "\n",
    "# # normalize inputs from 0-255 to 0-1\n",
    "X_train /= 255.0\n",
    "X_val /= 255.0\n",
    "\n",
    "# convert class vectors to binary class matrices for keras\n",
    "num_classes = 10\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_val = tf.keras.utils.to_categorical(y_val, num_classes)\n",
    "\n",
    "#Print the training and vallidation sets \n",
    "print(\"X_train\",X_train.shape,\"X_val :\",X_val.shape)\n",
    "print(\"y_train\",y_train.shape,\"y_val :\",y_val.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GB3ZyQwTEo-l"
   },
   "source": [
    "###Step 4: Start with small regularization and find learning rate that makes the loss go down.\n",
    "\n",
    "- we start with Lambda(small regularization) = 1e-7\n",
    "- we start with a small learning rate =1e-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1830
    },
    "colab_type": "code",
    "id": "gGTvUESjHJZB",
    "outputId": "f3f7ef90-49a4-4221-c228-18df9f89e460"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples, validate on 18000 samples\n",
      "Epoch 1/50\n",
      "42000/42000 [==============================] - 1s 31us/sample - loss: 2.4769 - acc: 0.1039 - val_loss: 2.4739 - val_acc: 0.1018\n",
      "Epoch 2/50\n",
      "42000/42000 [==============================] - 1s 21us/sample - loss: 2.4754 - acc: 0.1039 - val_loss: 2.4723 - val_acc: 0.1018\n",
      "Epoch 3/50\n",
      "42000/42000 [==============================] - 1s 21us/sample - loss: 2.4739 - acc: 0.1039 - val_loss: 2.4709 - val_acc: 0.1019\n",
      "Epoch 4/50\n",
      "42000/42000 [==============================] - 1s 21us/sample - loss: 2.4724 - acc: 0.1040 - val_loss: 2.4694 - val_acc: 0.1019\n",
      "Epoch 5/50\n",
      "42000/42000 [==============================] - 1s 21us/sample - loss: 2.4709 - acc: 0.1041 - val_loss: 2.4680 - val_acc: 0.1020\n",
      "Epoch 6/50\n",
      "42000/42000 [==============================] - 1s 21us/sample - loss: 2.4695 - acc: 0.1040 - val_loss: 2.4665 - val_acc: 0.1019\n",
      "Epoch 7/50\n",
      "42000/42000 [==============================] - 1s 22us/sample - loss: 2.4681 - acc: 0.1041 - val_loss: 2.4651 - val_acc: 0.1018\n",
      "Epoch 8/50\n",
      "42000/42000 [==============================] - 1s 21us/sample - loss: 2.4667 - acc: 0.1041 - val_loss: 2.4637 - val_acc: 0.1019\n",
      "Epoch 9/50\n",
      "42000/42000 [==============================] - 1s 21us/sample - loss: 2.4653 - acc: 0.1042 - val_loss: 2.4623 - val_acc: 0.1020\n",
      "Epoch 10/50\n",
      "42000/42000 [==============================] - 1s 21us/sample - loss: 2.4639 - acc: 0.1042 - val_loss: 2.4610 - val_acc: 0.1021\n",
      "Epoch 11/50\n",
      "42000/42000 [==============================] - 1s 21us/sample - loss: 2.4625 - acc: 0.1042 - val_loss: 2.4596 - val_acc: 0.1021\n",
      "Epoch 12/50\n",
      "42000/42000 [==============================] - 1s 21us/sample - loss: 2.4612 - acc: 0.1043 - val_loss: 2.4583 - val_acc: 0.1020\n",
      "Epoch 13/50\n",
      "42000/42000 [==============================] - 1s 21us/sample - loss: 2.4599 - acc: 0.1042 - val_loss: 2.4570 - val_acc: 0.1019\n",
      "Epoch 14/50\n",
      "42000/42000 [==============================] - 1s 21us/sample - loss: 2.4585 - acc: 0.1042 - val_loss: 2.4557 - val_acc: 0.1019\n",
      "Epoch 15/50\n",
      "42000/42000 [==============================] - 1s 21us/sample - loss: 2.4572 - acc: 0.1043 - val_loss: 2.4544 - val_acc: 0.1021\n",
      "Epoch 16/50\n",
      "42000/42000 [==============================] - 1s 21us/sample - loss: 2.4560 - acc: 0.1043 - val_loss: 2.4531 - val_acc: 0.1021\n",
      "Epoch 17/50\n",
      "42000/42000 [==============================] - 1s 21us/sample - loss: 2.4547 - acc: 0.1043 - val_loss: 2.4518 - val_acc: 0.1021\n",
      "Epoch 18/50\n",
      "42000/42000 [==============================] - 1s 21us/sample - loss: 2.4534 - acc: 0.1045 - val_loss: 2.4506 - val_acc: 0.1021\n",
      "Epoch 19/50\n",
      "42000/42000 [==============================] - 1s 21us/sample - loss: 2.4522 - acc: 0.1044 - val_loss: 2.4493 - val_acc: 0.1023\n",
      "Epoch 20/50\n",
      "42000/42000 [==============================] - 1s 21us/sample - loss: 2.4509 - acc: 0.1044 - val_loss: 2.4481 - val_acc: 0.1024\n",
      "Epoch 21/50\n",
      "42000/42000 [==============================] - 1s 21us/sample - loss: 2.4497 - acc: 0.1043 - val_loss: 2.4469 - val_acc: 0.1024\n",
      "Epoch 22/50\n",
      "42000/42000 [==============================] - 1s 21us/sample - loss: 2.4485 - acc: 0.1043 - val_loss: 2.4457 - val_acc: 0.1026\n",
      "Epoch 23/50\n",
      "42000/42000 [==============================] - 1s 21us/sample - loss: 2.4473 - acc: 0.1042 - val_loss: 2.4445 - val_acc: 0.1027\n",
      "Epoch 24/50\n",
      "42000/42000 [==============================] - 1s 21us/sample - loss: 2.4461 - acc: 0.1042 - val_loss: 2.4433 - val_acc: 0.1027\n",
      "Epoch 25/50\n",
      "42000/42000 [==============================] - 1s 22us/sample - loss: 2.4450 - acc: 0.1042 - val_loss: 2.4422 - val_acc: 0.1028\n",
      "Epoch 26/50\n",
      "42000/42000 [==============================] - 1s 21us/sample - loss: 2.4438 - acc: 0.1043 - val_loss: 2.4410 - val_acc: 0.1028\n",
      "Epoch 27/50\n",
      "42000/42000 [==============================] - 1s 21us/sample - loss: 2.4427 - acc: 0.1043 - val_loss: 2.4399 - val_acc: 0.1028\n",
      "Epoch 28/50\n",
      "42000/42000 [==============================] - 1s 21us/sample - loss: 2.4416 - acc: 0.1042 - val_loss: 2.4388 - val_acc: 0.1029\n",
      "Epoch 29/50\n",
      "42000/42000 [==============================] - 1s 21us/sample - loss: 2.4404 - acc: 0.1042 - val_loss: 2.4377 - val_acc: 0.1027\n",
      "Epoch 30/50\n",
      "42000/42000 [==============================] - 1s 21us/sample - loss: 2.4393 - acc: 0.1043 - val_loss: 2.4366 - val_acc: 0.1026\n",
      "Epoch 31/50\n",
      "42000/42000 [==============================] - 1s 21us/sample - loss: 2.4382 - acc: 0.1044 - val_loss: 2.4355 - val_acc: 0.1026\n",
      "Epoch 32/50\n",
      "42000/42000 [==============================] - 1s 21us/sample - loss: 2.4372 - acc: 0.1045 - val_loss: 2.4344 - val_acc: 0.1027\n",
      "Epoch 33/50\n",
      "42000/42000 [==============================] - 1s 21us/sample - loss: 2.4361 - acc: 0.1045 - val_loss: 2.4334 - val_acc: 0.1029\n",
      "Epoch 34/50\n",
      "42000/42000 [==============================] - 1s 21us/sample - loss: 2.4350 - acc: 0.1045 - val_loss: 2.4323 - val_acc: 0.1026\n",
      "Epoch 35/50\n",
      "42000/42000 [==============================] - 1s 21us/sample - loss: 2.4340 - acc: 0.1046 - val_loss: 2.4313 - val_acc: 0.1026\n",
      "Epoch 36/50\n",
      "42000/42000 [==============================] - 1s 21us/sample - loss: 2.4329 - acc: 0.1046 - val_loss: 2.4302 - val_acc: 0.1025\n",
      "Epoch 37/50\n",
      "42000/42000 [==============================] - 1s 21us/sample - loss: 2.4319 - acc: 0.1046 - val_loss: 2.4292 - val_acc: 0.1026\n",
      "Epoch 38/50\n",
      "42000/42000 [==============================] - 1s 21us/sample - loss: 2.4309 - acc: 0.1048 - val_loss: 2.4282 - val_acc: 0.1025\n",
      "Epoch 39/50\n",
      "42000/42000 [==============================] - 1s 22us/sample - loss: 2.4299 - acc: 0.1050 - val_loss: 2.4272 - val_acc: 0.1024\n",
      "Epoch 40/50\n",
      "42000/42000 [==============================] - 1s 21us/sample - loss: 2.4289 - acc: 0.1050 - val_loss: 2.4262 - val_acc: 0.1024\n",
      "Epoch 41/50\n",
      "42000/42000 [==============================] - 1s 22us/sample - loss: 2.4279 - acc: 0.1050 - val_loss: 2.4252 - val_acc: 0.1024\n",
      "Epoch 42/50\n",
      "42000/42000 [==============================] - 1s 21us/sample - loss: 2.4269 - acc: 0.1051 - val_loss: 2.4243 - val_acc: 0.1023\n",
      "Epoch 43/50\n",
      "42000/42000 [==============================] - 1s 21us/sample - loss: 2.4259 - acc: 0.1051 - val_loss: 2.4233 - val_acc: 0.1024\n",
      "Epoch 44/50\n",
      "42000/42000 [==============================] - 1s 21us/sample - loss: 2.4250 - acc: 0.1051 - val_loss: 2.4224 - val_acc: 0.1021\n",
      "Epoch 45/50\n",
      "42000/42000 [==============================] - 1s 21us/sample - loss: 2.4240 - acc: 0.1053 - val_loss: 2.4214 - val_acc: 0.1021\n",
      "Epoch 46/50\n",
      "42000/42000 [==============================] - 1s 21us/sample - loss: 2.4231 - acc: 0.1053 - val_loss: 2.4205 - val_acc: 0.1021\n",
      "Epoch 47/50\n",
      "42000/42000 [==============================] - 1s 21us/sample - loss: 2.4222 - acc: 0.1053 - val_loss: 2.4196 - val_acc: 0.1022\n",
      "Epoch 48/50\n",
      "42000/42000 [==============================] - 1s 21us/sample - loss: 2.4212 - acc: 0.1053 - val_loss: 2.4187 - val_acc: 0.1025\n",
      "Epoch 49/50\n",
      "42000/42000 [==============================] - 1s 21us/sample - loss: 2.4203 - acc: 0.1053 - val_loss: 2.4178 - val_acc: 0.1026\n",
      "Epoch 50/50\n",
      "42000/42000 [==============================] - 1s 21us/sample - loss: 2.4194 - acc: 0.1053 - val_loss: 2.4169 - val_acc: 0.1024\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.4168695822821724, 0.10244445]"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set the hyperparameters according to the above instructions\n",
    "lr = 1e-7\n",
    "Lambda = 1e-7\n",
    "iterations = 50\n",
    "#call the train and test function\n",
    "train_and_test_loop1(iterations=iterations, lr=lr,Lambda=Lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ch02LGmOEvEJ"
   },
   "source": [
    "####Please document your findings of the results of the above step\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3asD_eX-HkKS"
   },
   "source": [
    "**Observation** : Loss decreases steadily with every epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Iii6fioAZcNb"
   },
   "source": [
    "### Step 5: Okay now lets try a (larger) learning rate . What could possibly go wrong?\n",
    "\n",
    "- Learning rate lr  \n",
    "- Regularization lambda \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1830
    },
    "colab_type": "code",
    "id": "HnQEYYWtHpwS",
    "outputId": "52f32c84-368b-43ad-ccb6-611487af661e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples, validate on 18000 samples\n",
      "Epoch 1/50\n",
      "42000/42000 [==============================] - 1s 32us/sample - loss: 14.3768 - acc: 0.0996 - val_loss: 14.4955 - val_acc: 0.1007\n",
      "Epoch 2/50\n",
      "42000/42000 [==============================] - 1s 21us/sample - loss: 14.5109 - acc: 0.0997 - val_loss: 14.4955 - val_acc: 0.1007\n",
      "Epoch 3/50\n",
      "42000/42000 [==============================] - 1s 21us/sample - loss: 14.5109 - acc: 0.0997 - val_loss: 14.4955 - val_acc: 0.1007\n",
      "Epoch 4/50\n",
      "42000/42000 [==============================] - 1s 21us/sample - loss: 14.5109 - acc: 0.0997 - val_loss: 14.4955 - val_acc: 0.1007\n",
      "Epoch 5/50\n",
      "42000/42000 [==============================] - 1s 21us/sample - loss: 14.5109 - acc: 0.0997 - val_loss: 14.4955 - val_acc: 0.1007\n",
      "Epoch 6/50\n",
      "42000/42000 [==============================] - 1s 21us/sample - loss: 14.5109 - acc: 0.0997 - val_loss: 14.4955 - val_acc: 0.1007\n",
      "Epoch 7/50\n",
      "42000/42000 [==============================] - 1s 21us/sample - loss: 14.5109 - acc: 0.0997 - val_loss: 14.4955 - val_acc: 0.1007\n",
      "Epoch 8/50\n",
      "42000/42000 [==============================] - 1s 21us/sample - loss: 14.5109 - acc: 0.0997 - val_loss: 14.4955 - val_acc: 0.1007\n",
      "Epoch 9/50\n",
      "42000/42000 [==============================] - 1s 21us/sample - loss: 14.5109 - acc: 0.0997 - val_loss: 14.4955 - val_acc: 0.1007\n",
      "Epoch 10/50\n",
      "42000/42000 [==============================] - 1s 21us/sample - loss: 14.5109 - acc: 0.0997 - val_loss: 14.4955 - val_acc: 0.1007\n",
      "Epoch 11/50\n",
      "42000/42000 [==============================] - 1s 21us/sample - loss: 14.5109 - acc: 0.0997 - val_loss: 14.4955 - val_acc: 0.1007\n",
      "Epoch 12/50\n",
      "42000/42000 [==============================] - 1s 21us/sample - loss: 14.5109 - acc: 0.0997 - val_loss: 14.4955 - val_acc: 0.1007\n",
      "Epoch 13/50\n",
      "42000/42000 [==============================] - 1s 21us/sample - loss: 14.5109 - acc: 0.0997 - val_loss: 14.4955 - val_acc: 0.1007\n",
      "Epoch 14/50\n",
      "42000/42000 [==============================] - 1s 21us/sample - loss: 14.5109 - acc: 0.0997 - val_loss: 14.4955 - val_acc: 0.1007\n",
      "Epoch 15/50\n",
      "42000/42000 [==============================] - 1s 21us/sample - loss: 14.5109 - acc: 0.0997 - val_loss: 14.4955 - val_acc: 0.1007\n",
      "Epoch 16/50\n",
      "42000/42000 [==============================] - 1s 21us/sample - loss: 14.5109 - acc: 0.0997 - val_loss: 14.4955 - val_acc: 0.1007\n",
      "Epoch 17/50\n",
      "42000/42000 [==============================] - 1s 21us/sample - loss: 14.5109 - acc: 0.0997 - val_loss: 14.4955 - val_acc: 0.1007\n",
      "Epoch 18/50\n",
      "42000/42000 [==============================] - 1s 21us/sample - loss: 14.5109 - acc: 0.0997 - val_loss: 14.4955 - val_acc: 0.1007\n",
      "Epoch 19/50\n",
      "42000/42000 [==============================] - 1s 21us/sample - loss: 14.5109 - acc: 0.0997 - val_loss: 14.4955 - val_acc: 0.1007\n",
      "Epoch 20/50\n",
      "42000/42000 [==============================] - 1s 21us/sample - loss: 14.5109 - acc: 0.0997 - val_loss: 14.4955 - val_acc: 0.1007\n",
      "Epoch 21/50\n",
      "42000/42000 [==============================] - 1s 22us/sample - loss: 14.5109 - acc: 0.0997 - val_loss: 14.4955 - val_acc: 0.1007\n",
      "Epoch 22/50\n",
      "42000/42000 [==============================] - 1s 21us/sample - loss: 14.5109 - acc: 0.0997 - val_loss: 14.4955 - val_acc: 0.1007\n",
      "Epoch 23/50\n",
      "42000/42000 [==============================] - 1s 21us/sample - loss: 14.5109 - acc: 0.0997 - val_loss: 14.4955 - val_acc: 0.1007\n",
      "Epoch 24/50\n",
      "42000/42000 [==============================] - 1s 21us/sample - loss: 14.5109 - acc: 0.0997 - val_loss: 14.4955 - val_acc: 0.1007\n",
      "Epoch 25/50\n",
      "42000/42000 [==============================] - 1s 21us/sample - loss: 14.5109 - acc: 0.0997 - val_loss: 14.4955 - val_acc: 0.1007\n",
      "Epoch 26/50\n",
      "42000/42000 [==============================] - 1s 21us/sample - loss: 14.5109 - acc: 0.0997 - val_loss: 14.4955 - val_acc: 0.1007\n",
      "Epoch 27/50\n",
      "42000/42000 [==============================] - 1s 21us/sample - loss: 14.5109 - acc: 0.0997 - val_loss: 14.4955 - val_acc: 0.1007\n",
      "Epoch 28/50\n",
      "42000/42000 [==============================] - 1s 21us/sample - loss: 14.5109 - acc: 0.0997 - val_loss: 14.4955 - val_acc: 0.1007\n",
      "Epoch 29/50\n",
      "42000/42000 [==============================] - 1s 22us/sample - loss: 14.5109 - acc: 0.0997 - val_loss: 14.4955 - val_acc: 0.1007\n",
      "Epoch 30/50\n",
      "42000/42000 [==============================] - 1s 21us/sample - loss: 14.5109 - acc: 0.0997 - val_loss: 14.4955 - val_acc: 0.1007\n",
      "Epoch 31/50\n",
      "42000/42000 [==============================] - 1s 21us/sample - loss: 14.5109 - acc: 0.0997 - val_loss: 14.4955 - val_acc: 0.1007\n",
      "Epoch 32/50\n",
      "42000/42000 [==============================] - 1s 21us/sample - loss: 14.5109 - acc: 0.0997 - val_loss: 14.4955 - val_acc: 0.1007\n",
      "Epoch 33/50\n",
      "42000/42000 [==============================] - 1s 21us/sample - loss: 14.5109 - acc: 0.0997 - val_loss: 14.4955 - val_acc: 0.1007\n",
      "Epoch 34/50\n",
      "42000/42000 [==============================] - 1s 21us/sample - loss: 14.5109 - acc: 0.0997 - val_loss: 14.4955 - val_acc: 0.1007\n",
      "Epoch 35/50\n",
      "42000/42000 [==============================] - 1s 21us/sample - loss: 14.5109 - acc: 0.0997 - val_loss: 14.4955 - val_acc: 0.1007\n",
      "Epoch 36/50\n",
      "42000/42000 [==============================] - 1s 21us/sample - loss: 14.5109 - acc: 0.0997 - val_loss: 14.4955 - val_acc: 0.1007\n",
      "Epoch 37/50\n",
      "42000/42000 [==============================] - 1s 21us/sample - loss: 14.5109 - acc: 0.0997 - val_loss: 14.4955 - val_acc: 0.1007\n",
      "Epoch 38/50\n",
      "42000/42000 [==============================] - 1s 21us/sample - loss: 14.5109 - acc: 0.0997 - val_loss: 14.4955 - val_acc: 0.1007\n",
      "Epoch 39/50\n",
      "42000/42000 [==============================] - 1s 21us/sample - loss: 14.5109 - acc: 0.0997 - val_loss: 14.4955 - val_acc: 0.1007\n",
      "Epoch 40/50\n",
      "42000/42000 [==============================] - 1s 21us/sample - loss: 14.5109 - acc: 0.0997 - val_loss: 14.4955 - val_acc: 0.1007\n",
      "Epoch 41/50\n",
      "42000/42000 [==============================] - 1s 21us/sample - loss: 14.5109 - acc: 0.0997 - val_loss: 14.4955 - val_acc: 0.1007\n",
      "Epoch 42/50\n",
      "42000/42000 [==============================] - 1s 21us/sample - loss: 14.5109 - acc: 0.0997 - val_loss: 14.4955 - val_acc: 0.1007\n",
      "Epoch 43/50\n",
      "42000/42000 [==============================] - 1s 21us/sample - loss: 14.5109 - acc: 0.0997 - val_loss: 14.4955 - val_acc: 0.1007\n",
      "Epoch 44/50\n",
      "42000/42000 [==============================] - 1s 21us/sample - loss: 14.5109 - acc: 0.0997 - val_loss: 14.4955 - val_acc: 0.1007\n",
      "Epoch 45/50\n",
      "42000/42000 [==============================] - 1s 21us/sample - loss: 14.5109 - acc: 0.0997 - val_loss: 14.4955 - val_acc: 0.1007\n",
      "Epoch 46/50\n",
      "42000/42000 [==============================] - 1s 21us/sample - loss: 14.5109 - acc: 0.0997 - val_loss: 14.4955 - val_acc: 0.1007\n",
      "Epoch 47/50\n",
      "42000/42000 [==============================] - 1s 21us/sample - loss: 14.5109 - acc: 0.0997 - val_loss: 14.4955 - val_acc: 0.1007\n",
      "Epoch 48/50\n",
      "42000/42000 [==============================] - 1s 21us/sample - loss: 14.5109 - acc: 0.0997 - val_loss: 14.4955 - val_acc: 0.1007\n",
      "Epoch 49/50\n",
      "42000/42000 [==============================] - 1s 21us/sample - loss: 14.5109 - acc: 0.0997 - val_loss: 14.4955 - val_acc: 0.1007\n",
      "Epoch 50/50\n",
      "42000/42000 [==============================] - 1s 21us/sample - loss: 14.5109 - acc: 0.0997 - val_loss: 14.4955 - val_acc: 0.1007\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[14.495540306939018, 0.100666665]"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set Hyperparameters( High value for lr and low values for lambda)\n",
    "lr = 1\n",
    "Lambda = 0\n",
    "iterations = 50\n",
    "# Call the train and test function\n",
    "train_and_test_loop1(iterations=iterations, lr=lr,Lambda=Lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nHIXx1hvE-KE"
   },
   "source": [
    "####Please document your findings of the results of the above step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oG354M8YKglU"
   },
   "source": [
    "**Observations:**\n",
    "The loss went quite high at once and then remains constant. Thus very poor accuracy as well.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XRGWq8UmZcNg"
   },
   "source": [
    "### Step 6: Train the model for different learning rates (In a range) based on the learning from above steps\n",
    "\n",
    "- learning rate =\n",
    "- regularization remains the small, lambda "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "colab_type": "code",
    "id": "QcuOAA4RK1I5",
    "outputId": "1eacbfb7-f25d-4db0-ec8a-a52e4af0c2d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples, validate on 18000 samples\n",
      "Epoch 1/10\n",
      "42000/42000 [==============================] - 1s 33us/sample - loss: 2.3002 - acc: 0.1156 - val_loss: 2.2916 - val_acc: 0.1252\n",
      "Epoch 2/10\n",
      "42000/42000 [==============================] - 1s 22us/sample - loss: 2.2894 - acc: 0.1310 - val_loss: 2.2872 - val_acc: 0.1376\n",
      "Epoch 3/10\n",
      "42000/42000 [==============================] - 1s 22us/sample - loss: 2.2866 - acc: 0.1367 - val_loss: 2.2850 - val_acc: 0.1420\n",
      "Epoch 4/10\n",
      "42000/42000 [==============================] - 1s 22us/sample - loss: 2.2849 - acc: 0.1423 - val_loss: 2.2834 - val_acc: 0.1461\n",
      "Epoch 5/10\n",
      "42000/42000 [==============================] - 1s 22us/sample - loss: 2.2835 - acc: 0.1461 - val_loss: 2.2822 - val_acc: 0.1492\n",
      "Epoch 6/10\n",
      "42000/42000 [==============================] - 1s 22us/sample - loss: 2.2824 - acc: 0.1491 - val_loss: 2.2811 - val_acc: 0.1525\n",
      "Epoch 7/10\n",
      "42000/42000 [==============================] - 1s 22us/sample - loss: 2.2814 - acc: 0.1507 - val_loss: 2.2803 - val_acc: 0.1541\n",
      "Epoch 8/10\n",
      "42000/42000 [==============================] - 1s 22us/sample - loss: 2.2806 - acc: 0.1525 - val_loss: 2.2795 - val_acc: 0.1576\n",
      "Epoch 9/10\n",
      "42000/42000 [==============================] - 1s 22us/sample - loss: 2.2799 - acc: 0.1545 - val_loss: 2.2788 - val_acc: 0.1578\n",
      "Epoch 10/10\n",
      "42000/42000 [==============================] - 1s 22us/sample - loss: 2.2792 - acc: 0.1550 - val_loss: 2.2782 - val_acc: 0.1592\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x7f68b56e0f60>"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.01\n",
    "Lambda = 0.09\n",
    "train_and_test_loop(iterations=10, lr=lr,Lambda=Lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2RlCsuiWFHB-"
   },
   "source": [
    "#### Document the findings of the above step here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qdyHXpP7LU0A"
   },
   "source": [
    "**Observation:** Loss value decreases steadily with each epoch "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x-A9KC8sZcNk"
   },
   "source": [
    "### Hyperparameter Optimization\n",
    "\n",
    "### Cross validation Strategy\n",
    "\n",
    "\n",
    "- Do coarse -> fine cross-validation in stages\n",
    "\n",
    "- First stage: only a few epochs to get rough idea of what params work\n",
    "- Second stage: longer running time, finer search\n",
    "- … (repeat as necessary)\n",
    "\n",
    "### Tip for detecting explosions in the solver: \n",
    "- If the cost is ever > 3 * original cost, break out early\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h4cPbsGvZcNl"
   },
   "source": [
    "### For example: Run coarse search for 10 times with different lr and Lambda values each with 100 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3572
    },
    "colab_type": "code",
    "id": "bIUjpRzMLsJF",
    "outputId": "f2a8972b-7a16-4066-83c4-f42f32666a05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Try 1/100: Best_val_acc: [2.3504764711591934, 0.09988889], lr: 6.26064345493644e-07, Lambda: 0.0001173982461032458\n",
      "\n",
      "Try 2/100: Best_val_acc: [2.438791547139486, 0.09466667], lr: 1.5630889480893977e-05, Lambda: 41465.0754490548\n",
      "\n",
      "Try 3/100: Best_val_acc: [2.307356251186795, 0.105444446], lr: 1.3968393804216391e-05, Lambda: 7.332681822779288e-05\n",
      "\n",
      "Try 4/100: Best_val_acc: [2.3068348443773057, 0.10744444], lr: 0.017395640772399867, Lambda: 3.833879204000732\n",
      "\n",
      "Try 5/100: Best_val_acc: [2.327018688201904, 0.097555555], lr: 0.0004441412599233238, Lambda: 0.5369746545192623\n",
      "\n",
      "Try 6/100: Best_val_acc: [14.48121312544081, 0.101555556], lr: 485.3515104056453, Lambda: 1.0834253954136592\n",
      "\n",
      "Try 7/100: Best_val_acc: [2.382926646762424, 0.09544444], lr: 3.5665930938998705e-07, Lambda: 2.1823874395519594e-05\n",
      "\n",
      "Try 8/100: Best_val_acc: [14.49374937608507, 0.100777775], lr: 138.7276897140009, Lambda: 10082.129276201553\n",
      "\n",
      "Try 9/100: Best_val_acc: [0.9164918349054124, 0.7298889], lr: 0.01316066623707063, Lambda: 0.0007307102224816126\n",
      "\n",
      "Try 10/100: Best_val_acc: [14.503599334716798, 0.10016666], lr: 7.194032059541488, Lambda: 50112.113783163746\n",
      "\n",
      "Try 11/100: Best_val_acc: [2.4324106182522245, 0.09922222], lr: 1.173140136955538e-06, Lambda: 0.005611784360752654\n",
      "\n",
      "Try 12/100: Best_val_acc: [2.3774818085564506, 0.094333336], lr: 0.0001272768536982941, Lambda: 32.03123208419965\n",
      "\n",
      "Try 13/100: Best_val_acc: [14.503599334716798, 0.10016666], lr: 124.05092967483145, Lambda: 0.14857456121631732\n",
      "\n",
      "Try 14/100: Best_val_acc: [2.479666266123454, 0.101], lr: 1.802546182834173e-05, Lambda: 0.6797085682178972\n",
      "\n",
      "Try 15/100: Best_val_acc: [2.270610853407118, 0.17883334], lr: 0.00011150803520234233, Lambda: 0.00014338197481295512\n",
      "\n",
      "Try 16/100: Best_val_acc: [7.250878142038981, 0.09816667], lr: 0.13899682062906227, Lambda: 5239.382579005072\n",
      "\n",
      "Try 17/100: Best_val_acc: [2.3716204397413465, 0.09777778], lr: 5.198572568716743e-06, Lambda: 0.014437625261220974\n",
      "\n",
      "Try 18/100: Best_val_acc: [14.502703857421874, 0.10022222], lr: 3.0842788223674753, Lambda: 0.0009873182732963567\n",
      "\n",
      "Try 19/100: Best_val_acc: [2.7703918721940783, 0.08766667], lr: 0.053425437125516645, Lambda: 116.06448485520839\n",
      "\n",
      "Try 20/100: Best_val_acc: [2.360635698530409, 0.0975], lr: 1.2264643477264032e-06, Lambda: 48.63070655621911\n",
      "\n",
      "Try 21/100: Best_val_acc: [2.4066991890801326, 0.09472222], lr: 9.76882577122807e-06, Lambda: 0.036743651488342514\n",
      "\n",
      "Try 22/100: Best_val_acc: [2.3798161682552763, 0.10244445], lr: 1.43307078886042e-07, Lambda: 0.005995081203929409\n",
      "\n",
      "Try 23/100: Best_val_acc: [2.2287029982672797, 0.25483334], lr: 0.015238199924558517, Lambda: 0.06751203097440593\n",
      "\n",
      "Try 24/100: Best_val_acc: [2.387532328075833, 0.10355555], lr: 4.539179211023647e-06, Lambda: 7.180372882585214\n",
      "\n",
      "Try 25/100: Best_val_acc: [13.584793344285753, 0.0955], lr: 0.8970221881606825, Lambda: 78024.54150876682\n",
      "\n",
      "Try 26/100: Best_val_acc: [14.477631252712674, 0.10177778], lr: 151.96099896138108, Lambda: 0.00481814359651834\n",
      "\n",
      "Try 27/100: Best_val_acc: [14.48121312544081, 0.101555556], lr: 1646.7266638773988, Lambda: 3.486357020625721e-05\n",
      "\n",
      "Try 28/100: Best_val_acc: [14.578817110697429, 0.0955], lr: 1.1225288958087465, Lambda: 0.0005212175802099084\n",
      "\n",
      "Try 29/100: Best_val_acc: [14.534940065171984, 0.098222226], lr: 0.7587048677826634, Lambda: 0.14244341185006681\n",
      "\n",
      "Try 30/100: Best_val_acc: [2.437253898832533, 0.093611114], lr: 8.62366478378249e-05, Lambda: 1134.441997866049\n",
      "\n",
      "Try 31/100: Best_val_acc: [14.477631252712674, 0.10177778], lr: 40.0210300522008, Lambda: 220.01347524342833\n",
      "\n",
      "Try 32/100: Best_val_acc: [2.310854627609253, 0.10461111], lr: 5.580889395730834e-05, Lambda: 0.01637785743224646\n",
      "\n",
      "Try 33/100: Best_val_acc: [14.495540306939018, 0.100666665], lr: 372.6883566510737, Lambda: 9.230929330901415e-05\n",
      "\n",
      "Try 34/100: Best_val_acc: [2.3032091664208307, 0.10044444], lr: 0.4361324478666823, Lambda: 0.0003117148226337737\n",
      "\n",
      "Try 35/100: Best_val_acc: [2.3869900478786894, 0.10205556], lr: 8.121451825430583e-05, Lambda: 0.35503591162768494\n",
      "\n",
      "Try 36/100: Best_val_acc: [14.502703857421874, 0.10022222], lr: 751.0288132185824, Lambda: 0.9423037518391622\n",
      "\n",
      "Try 37/100: Best_val_acc: [14.495540304395888, 0.100666665], lr: 34.08447428325563, Lambda: 17.19350506910824\n",
      "\n",
      "Try 38/100: Best_val_acc: [2.399362562391493, 0.10177778], lr: 2.316219182872256e-05, Lambda: 1.066774126169524\n",
      "\n",
      "Try 39/100: Best_val_acc: [2.3421776084899903, 0.097055554], lr: 5.240918381357541e-07, Lambda: 1.9377068004944694e-05\n",
      "\n",
      "Try 40/100: Best_val_acc: [14.502703857421874, 0.10022222], lr: 0.7310605299060936, Lambda: 0.037553801042569446\n",
      "\n",
      "Try 41/100: Best_val_acc: [2.302389238357544, 0.11027778], lr: 0.001848070643515904, Lambda: 0.11746515128550471\n",
      "\n",
      "Try 42/100: Best_val_acc: [14.495540304395888, 0.100666665], lr: 1104.7301009987546, Lambda: 0.08507132407326556\n",
      "\n",
      "Try 43/100: Best_val_acc: [2.34881383895874, 0.09905556], lr: 0.0046428991786060065, Lambda: 59.69983742645468\n",
      "\n",
      "Try 44/100: Best_val_acc: [2.135661490122477, 0.35777777], lr: 0.0010548383719145413, Lambda: 0.0011242168000864011\n",
      "\n",
      "Try 45/100: Best_val_acc: [14.502703857421874, 0.10022222], lr: 3.2179316768574644, Lambda: 0.0013797564063200464\n",
      "\n",
      "Try 46/100: Best_val_acc: [2.5189265433417427, 0.100944445], lr: 1.7364837972411848e-07, Lambda: 0.06300367501090112\n",
      "\n",
      "Try 47/100: Best_val_acc: [2.4250604326460095, 0.101555556], lr: 3.525960224254467e-06, Lambda: 34.71644186841548\n",
      "\n",
      "Try 48/100: Best_val_acc: [2.321114269044664, 0.10527778], lr: 9.501412326654365e-06, Lambda: 0.001412384421091354\n",
      "\n",
      "Try 49/100: Best_val_acc: [2.496939334233602, 0.09427778], lr: 1.816909540817177e-06, Lambda: 5928.848226347405\n",
      "\n",
      "Try 50/100: Best_val_acc: [2.3085524529351127, 0.11261111], lr: 1.2599949363030374e-05, Lambda: 0.0012483766573182582\n",
      "\n",
      "Try 51/100: Best_val_acc: [2.307622357686361, 0.10888889], lr: 9.116303983796558e-05, Lambda: 0.002387883267236992\n",
      "\n",
      "Try 52/100: Best_val_acc: [2.3605592138502334, 0.098], lr: 8.053916528904392e-07, Lambda: 0.0002089573400215386\n",
      "\n",
      "Try 53/100: Best_val_acc: [10.31206234910753, 0.10233333], lr: 0.7219139741974022, Lambda: 41286.65542594739\n",
      "\n",
      "Try 54/100: Best_val_acc: [2.305682582643297, 0.111944444], lr: 4.7822971781765325e-05, Lambda: 0.0037469475128522212\n",
      "\n",
      "Try 55/100: Best_val_acc: [2.3205488137139216, 0.093722224], lr: 0.0022803625163467494, Lambda: 8.79921510961204\n",
      "\n",
      "Try 56/100: Best_val_acc: [1.2812383145226374, 0.6436667], lr: 0.007950120088822024, Lambda: 0.0024915399984632787\n",
      "\n",
      "Try 57/100: Best_val_acc: [14.495540304395888, 0.100666665], lr: 3.314168922302304, Lambda: 0.0025361674789878244\n",
      "\n",
      "Try 58/100: Best_val_acc: [2.1953385704888237, 0.15238889], lr: 0.4829459404429788, Lambda: 0.5374705370067349\n",
      "\n",
      "Try 59/100: Best_val_acc: [14.495540304395888, 0.100666665], lr: 38.283447925847724, Lambda: 26722.80715131027\n",
      "\n",
      "Try 60/100: Best_val_acc: [2.17874752913581, 0.2885], lr: 0.00830015613166111, Lambda: 0.020482709642955253\n",
      "\n",
      "Try 61/100: Best_val_acc: [2.5979794409010144, 0.105111115], lr: 3.1295542293229046e-06, Lambda: 223.54367505096744\n",
      "\n",
      "Try 62/100: Best_val_acc: [2.4565997657775878, 0.098], lr: 0.0003391036611956102, Lambda: 2299.3027198077184\n",
      "\n",
      "Try 63/100: Best_val_acc: [2.3234681256612144, 0.08461111], lr: 0.018706123626722148, Lambda: 3.5673334704092317\n",
      "\n",
      "Try 64/100: Best_val_acc: [2.300515996721056, 0.10955556], lr: 0.13910395057169328, Lambda: 0.8527305405521298\n",
      "\n",
      "Try 65/100: Best_val_acc: [14.495540304395888, 0.100666665], lr: 104.05706655815476, Lambda: 0.18222624931406542\n",
      "\n",
      "Try 66/100: Best_val_acc: [2.2266862322489422, 0.13372222], lr: 0.45522179791174894, Lambda: 0.0031402789931367575\n",
      "\n",
      "Try 67/100: Best_val_acc: [2.2264126625061036, 0.24327777], lr: 0.00013579725411842983, Lambda: 1.1479439082495473e-05\n",
      "\n",
      "Try 68/100: Best_val_acc: [2.299386270311144, 0.10788889], lr: 0.059352563194339264, Lambda: 1.9006697438713538\n",
      "\n",
      "Try 69/100: Best_val_acc: [2.403497636159261, 0.09961111], lr: 0.0004108907932941378, Lambda: 303.57274180556203\n",
      "\n",
      "Try 70/100: Best_val_acc: [14.49374937608507, 0.100777775], lr: 38.164581787009375, Lambda: 0.04372528271658209\n",
      "\n",
      "Try 71/100: Best_val_acc: [1.226083343029022, 0.63255554], lr: 0.034867874202522374, Lambda: 3.70805755687879e-05\n",
      "\n",
      "Try 72/100: Best_val_acc: [2.280065539042155, 0.15533334], lr: 0.00012244005154642585, Lambda: 0.00025313593020962356\n",
      "\n",
      "Try 73/100: Best_val_acc: [5.543189466264513, 0.10022222], lr: 0.13280315790830885, Lambda: 45630.24801071936\n",
      "\n",
      "Try 74/100: Best_val_acc: [2.302119117948744, 0.10966667], lr: 0.19304062987678006, Lambda: 7.231578294641905\n",
      "\n",
      "Try 75/100: Best_val_acc: [2.5901061295403376, 0.09644444], lr: 4.571501908981527e-05, Lambda: 1.2317107046398208\n",
      "\n",
      "Try 76/100: Best_val_acc: [14.48121312544081, 0.101555556], lr: 3867.749129802206, Lambda: 0.16132884466027286\n",
      "\n",
      "Try 77/100: Best_val_acc: [2.383455898920695, 0.10338889], lr: 3.928422851264658e-06, Lambda: 0.01508807546159711\n",
      "\n",
      "Try 78/100: Best_val_acc: [2.301642402648926, 0.11661111], lr: 0.022533851430955276, Lambda: 1.6690962569969034\n",
      "\n",
      "Try 79/100: Best_val_acc: [14.495540304395888, 0.100666665], lr: 4.828108358938488, Lambda: 35320.42086614916\n",
      "\n",
      "Try 80/100: Best_val_acc: [1.354048510869344, 0.63566667], lr: 0.0024952266715698402, Lambda: 0.0005776704791374289\n",
      "\n",
      "Try 81/100: Best_val_acc: [14.503599334716798, 0.10016666], lr: 30.46031101338351, Lambda: 31632.243044588824\n",
      "\n",
      "Try 82/100: Best_val_acc: [2.4197649417453344, 0.09911111], lr: 0.001753563536324773, Lambda: 35750.9682869299\n",
      "\n",
      "Try 83/100: Best_val_acc: [14.495540306939018, 0.100666665], lr: 460.0968545587839, Lambda: 0.002790699327896723\n",
      "\n",
      "Try 84/100: Best_val_acc: [14.48121312544081, 0.101555556], lr: 1840.1192681945436, Lambda: 62901.712204681484\n",
      "\n",
      "Try 85/100: Best_val_acc: [2.5151909679836697, 0.09883333], lr: 7.442987000727031e-07, Lambda: 0.24141779426264687\n",
      "\n",
      "Try 86/100: Best_val_acc: [14.503283448961046, 0.10016666], lr: 7.44157810271662, Lambda: 84.31139717941704\n",
      "\n",
      "Try 87/100: Best_val_acc: [14.534940065171984, 0.098222226], lr: 164.46130352934517, Lambda: 4.470058929398976e-05\n",
      "\n",
      "Try 88/100: Best_val_acc: [2.37712289513482, 0.105], lr: 2.615186827202145e-07, Lambda: 0.3193234815539118\n",
      "\n",
      "Try 89/100: Best_val_acc: [2.4236271913316516, 0.094], lr: 7.723854978648329e-07, Lambda: 0.011296114283913788\n",
      "\n",
      "Try 90/100: Best_val_acc: [5.499354117923312, 0.100666665], lr: 0.10967414679067766, Lambda: 70815.04254449248\n",
      "\n",
      "Try 91/100: Best_val_acc: [14.534940065171984, 0.098222226], lr: 241.5259116419012, Lambda: 9.707418980475771e-05\n",
      "\n",
      "Try 92/100: Best_val_acc: [14.499122085571289, 0.10044444], lr: 429.61767568821693, Lambda: 1.1434939374342777e-05\n",
      "\n",
      "Try 93/100: Best_val_acc: [14.503599334716798, 0.10016666], lr: 17.124914453009115, Lambda: 28006.942264910413\n",
      "\n",
      "Try 94/100: Best_val_acc: [14.503599334716798, 0.10016666], lr: 0.8795857672996228, Lambda: 0.000289496977655415\n",
      "\n",
      "Try 95/100: Best_val_acc: [2.3143777364095053, 0.09527778], lr: 0.0003270173636751417, Lambda: 0.17258328984166016\n",
      "\n",
      "Try 96/100: Best_val_acc: [1.166582336054908, 0.66727775], lr: 0.0023485438822703894, Lambda: 0.00019212415857069583\n",
      "\n",
      "Try 97/100: Best_val_acc: [2.48391950141059, 0.09427778], lr: 1.8447440535510731e-07, Lambda: 0.006975983861897691\n",
      "\n",
      "Try 98/100: Best_val_acc: [2.3476215968661838, 0.10716667], lr: 1.0296526333347644e-05, Lambda: 0.00848825458345948\n",
      "\n",
      "Try 99/100: Best_val_acc: [14.49374937608507, 0.100777775], lr: 14.036816077274286, Lambda: 6324.719194050243\n",
      "\n",
      "CPU times: user 1h 53min 9s, sys: 11min 33s, total: 2h 4min 42s\n",
      "Wall time: 1h 33min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Run coarse search for a coarse range of lr and lambda values and print the results of the \n",
    "#first 10 epochs and figure out the range of lr and lambda for finer search\n",
    "import math\n",
    "import numpy as np\n",
    "for k in range(1,100):\n",
    "    lr = math.pow(10, np.random.uniform(-7.0, 4.0))\n",
    "    Lambda = math.pow(10, np.random.uniform(-5,5))\n",
    "    best_acc = train_and_test_loop1(50, lr, Lambda, False)\n",
    "    print(\"Try {0}/{1}: Best_val_acc: {2}, lr: {3}, Lambda: {4}\\n\".format(k, 100, best_acc, lr, Lambda))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OGBseWjCeCnQ"
   },
   "source": [
    "#### Document the findings of the above step here:\n",
    "\n",
    "Lr and Lambda values of lower value of losses \n",
    "\n",
    "\n",
    "*  Try 9/100: Best_val_acc: [0.9164918349054124, 0.7298889], lr: 0.01316066623707063, Lambda: 0.0007307102224816126\n",
    "*  Try 71/100: Best_val_acc: [1.226083343029022, 0.63255554], lr: 0.034867874202522374, Lambda: 3.70805755687879e-05\n",
    "*  Try 80/100: Best_val_acc: [1.354048510869344, 0.63566667], lr: 0.0024952266715698402, Lambda: 0.0005776704791374289\n",
    "*   Try 97/100: Best_val_acc: [2.48391950141059, 0.09427778], lr: 1.8447440535510731e-07, Lambda: 0.006975983861897691\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hGvFvZ1xdg6t"
   },
   "source": [
    "### Now run finer search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 727
    },
    "colab_type": "code",
    "id": "ejjhemqbdilB",
    "outputId": "671acce3-46b8-4c7e-dedf-096a6856eb5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Try 1/10: Best_val_acc: [2.2950189656151667, 0.11727778], lr: 0.002822577899961329, Lambda: 0.060372754203027505\n",
      "\n",
      "Try 2/10: Best_val_acc: [2.2959940656026205, 0.119055554], lr: 0.0010201289357660945, Lambda: 0.02220768040229958\n",
      "\n",
      "Try 3/10: Best_val_acc: [2.299281034257677, 0.119722225], lr: 0.004332381369473413, Lambda: 0.20465657688084754\n",
      "\n",
      "Try 4/10: Best_val_acc: [2.286019015206231, 0.14422221], lr: 0.0047699584588865975, Lambda: 0.07068064800428157\n",
      "\n",
      "Try 5/10: Best_val_acc: [2.3265166318681505, 0.10783333], lr: 0.0003069292602075098, Lambda: 0.19885768485344102\n",
      "\n",
      "Try 6/10: Best_val_acc: [2.2994270464579265, 0.11027778], lr: 0.0006067317531516788, Lambda: 0.016402861798493068\n",
      "\n",
      "Try 7/10: Best_val_acc: [2.408142639160156, 0.09811111], lr: 0.000622998331084552, Lambda: 62.81732078898682\n",
      "\n",
      "Try 8/10: Best_val_acc: [2.3046938179863825, 0.1015], lr: 0.0013107111035187094, Lambda: 0.21748147027231413\n",
      "\n",
      "Try 9/10: Best_val_acc: [2.3022810433705647, 0.119], lr: 0.005846415604923866, Lambda: 0.721008573058277\n",
      "\n",
      "Try 10/10: Best_val_acc: [2.0363178855048285, 0.41166666], lr: 0.00034298769320160473, Lambda: 2.609567281093282e-05\n",
      "\n",
      "Try 11/10: Best_val_acc: [2.3071629248725043, 0.10027778], lr: 0.0009225459132652588, Lambda: 0.32352924851526516\n",
      "\n",
      "Try 12/10: Best_val_acc: [2.328694550620185, 0.09616667], lr: 0.0010103153880247201, Lambda: 2.946410548665063\n",
      "\n",
      "Try 13/10: Best_val_acc: [2.271622627682156, 0.17338888], lr: 0.004664729243303902, Lambda: 0.05321537371483748\n",
      "\n",
      "Try 14/10: Best_val_acc: [1.3608835085762871, 0.62905556], lr: 0.0035783917560449252, Lambda: 0.0009451414897428412\n",
      "\n",
      "Try 15/10: Best_val_acc: [2.26673347430759, 0.18733333], lr: 0.00021001538537952918, Lambda: 0.000545133191387186\n",
      "\n",
      "Try 16/10: Best_val_acc: [2.315106157938639, 0.09472222], lr: 0.0012433225427436968, Lambda: 0.45030555501883884\n",
      "\n",
      "Try 17/10: Best_val_acc: [2.2940478591918945, 0.12272222], lr: 0.004156530490114983, Lambda: 0.1801312668198907\n",
      "\n",
      "Try 18/10: Best_val_acc: [1.2011000037723116, 0.66283333], lr: 0.0013141042411601146, Lambda: 1.4401944388135805e-05\n",
      "\n",
      "Try 19/10: Best_val_acc: [1.1031953185929193, 0.68516666], lr: 0.004616889426377866, Lambda: 0.0005352990844022703\n",
      "\n",
      "Try 20/10: Best_val_acc: [2.3319749312930638, 0.09961111], lr: 0.008328145502158513, Lambda: 40.754080715928005\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Set a finer range of hyperparameters and figure out even finer range\n",
    "import math\n",
    "import numpy as np\n",
    "for k in range(1,21):\n",
    "    lr = math.pow(10, np.random.uniform(-4.0, -2.0))\n",
    "    Lambda = math.pow(10, np.random.uniform(-5,2))\n",
    "    best_acc = train_and_test_loop1(50, lr, Lambda, False)\n",
    "    print(\"Try {0}/{1}: Best_val_acc: {2}, lr: {3}, Lambda: {4}\\n\".format(k, 10, best_acc, lr, Lambda))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZYeT6jekFfhU"
   },
   "source": [
    "#### Document the findings of the above step here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TYhct_cU15hD"
   },
   "source": [
    "\n",
    "\n",
    "1.   Try 14/10: Best_val_acc: [1.3608835085762871, 0.62905556], lr: 0.0035783917560449252, Lambda: 0.0009451414897428412\n",
    "2.   Try 18/10: Best_val_acc: [1.2011000037723116, 0.66283333], lr: 0.0013141042411601146, Lambda: 1.4401944388135805e-05\n",
    "\n",
    "3.  Try 19/10: Best_val_acc: [1.1031953185929193, 0.68516666], lr: 0.004616889426377866, Lambda: 0.0005352990844022703\n",
    "*   Try 9/100: Best_val_acc: [0.9164918349054124, 0.7298889], lr: 0.01316066623707063, Lambda: 0.0007307102224816126\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wAv5mEK1drVw"
   },
   "source": [
    "### Running deep with the best possible lr and lambda and report the accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71127
    },
    "colab_type": "code",
    "id": "vLTp0UzhdtoS",
    "outputId": "bdfd342f-1159-4dc5-ab1d-9242ec5af1c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples, validate on 18000 samples\n",
      "Epoch 1/2000\n",
      "42000/42000 [==============================] - 3s 70us/sample - loss: 2.2959 - acc: 0.1291 - val_loss: 2.2711 - val_acc: 0.1784\n",
      "Epoch 2/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 2.2304 - acc: 0.2150 - val_loss: 2.1633 - val_acc: 0.2856\n",
      "Epoch 3/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 2.0833 - acc: 0.3164 - val_loss: 1.9879 - val_acc: 0.3377\n",
      "Epoch 4/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 1.8949 - acc: 0.4002 - val_loss: 1.7872 - val_acc: 0.4572\n",
      "Epoch 5/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 1.7084 - acc: 0.4885 - val_loss: 1.6271 - val_acc: 0.5227\n",
      "Epoch 6/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 1.5533 - acc: 0.5499 - val_loss: 1.4710 - val_acc: 0.5863\n",
      "Epoch 7/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 1.4397 - acc: 0.5865 - val_loss: 1.3726 - val_acc: 0.6048\n",
      "Epoch 8/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 1.3481 - acc: 0.6137 - val_loss: 1.3269 - val_acc: 0.6087\n",
      "Epoch 9/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 1.2835 - acc: 0.6319 - val_loss: 1.2755 - val_acc: 0.6131\n",
      "Epoch 10/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 1.2335 - acc: 0.6448 - val_loss: 1.2063 - val_acc: 0.6476\n",
      "Epoch 11/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 1.1972 - acc: 0.6515 - val_loss: 1.2188 - val_acc: 0.6301\n",
      "Epoch 12/2000\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 1.1649 - acc: 0.6631 - val_loss: 1.1674 - val_acc: 0.6518\n",
      "Epoch 13/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 1.1340 - acc: 0.6715 - val_loss: 1.1494 - val_acc: 0.6554\n",
      "Epoch 14/2000\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 1.1151 - acc: 0.6750 - val_loss: 1.1289 - val_acc: 0.6647\n",
      "Epoch 15/2000\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 1.0933 - acc: 0.6806 - val_loss: 1.1037 - val_acc: 0.6747\n",
      "Epoch 16/2000\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 1.0794 - acc: 0.6842 - val_loss: 1.0985 - val_acc: 0.6758\n",
      "Epoch 17/2000\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 1.0639 - acc: 0.6879 - val_loss: 1.0702 - val_acc: 0.6885\n",
      "Epoch 18/2000\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 1.0506 - acc: 0.6911 - val_loss: 1.0519 - val_acc: 0.6903\n",
      "Epoch 19/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 1.0400 - acc: 0.6936 - val_loss: 1.0466 - val_acc: 0.6922\n",
      "Epoch 20/2000\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 1.0268 - acc: 0.6976 - val_loss: 1.0498 - val_acc: 0.6874\n",
      "Epoch 21/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 1.0151 - acc: 0.7026 - val_loss: 1.0468 - val_acc: 0.6832\n",
      "Epoch 22/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 1.0080 - acc: 0.7028 - val_loss: 1.0231 - val_acc: 0.6962\n",
      "Epoch 23/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.9991 - acc: 0.7061 - val_loss: 1.0293 - val_acc: 0.6917\n",
      "Epoch 24/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.9894 - acc: 0.7081 - val_loss: 1.0048 - val_acc: 0.7082\n",
      "Epoch 25/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.9818 - acc: 0.7097 - val_loss: 0.9972 - val_acc: 0.7057\n",
      "Epoch 26/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.9731 - acc: 0.7113 - val_loss: 0.9890 - val_acc: 0.7079\n",
      "Epoch 27/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.9635 - acc: 0.7165 - val_loss: 0.9859 - val_acc: 0.7076\n",
      "Epoch 28/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.9546 - acc: 0.7184 - val_loss: 0.9822 - val_acc: 0.7119\n",
      "Epoch 29/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.9467 - acc: 0.7212 - val_loss: 0.9822 - val_acc: 0.7031\n",
      "Epoch 30/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.9425 - acc: 0.7220 - val_loss: 0.9624 - val_acc: 0.7187\n",
      "Epoch 31/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.9368 - acc: 0.7221 - val_loss: 0.9573 - val_acc: 0.7171\n",
      "Epoch 32/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.9307 - acc: 0.7257 - val_loss: 0.9521 - val_acc: 0.7206\n",
      "Epoch 33/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.9276 - acc: 0.7256 - val_loss: 0.9648 - val_acc: 0.7139\n",
      "Epoch 34/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.9194 - acc: 0.7291 - val_loss: 0.9379 - val_acc: 0.7225\n",
      "Epoch 35/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.9102 - acc: 0.7311 - val_loss: 0.9360 - val_acc: 0.7266\n",
      "Epoch 36/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.9047 - acc: 0.7336 - val_loss: 0.9394 - val_acc: 0.7245\n",
      "Epoch 37/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.9008 - acc: 0.7344 - val_loss: 0.9289 - val_acc: 0.7259\n",
      "Epoch 38/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.8961 - acc: 0.7357 - val_loss: 0.9248 - val_acc: 0.7324\n",
      "Epoch 39/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.8903 - acc: 0.7385 - val_loss: 0.9472 - val_acc: 0.7197\n",
      "Epoch 40/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.8886 - acc: 0.7374 - val_loss: 0.9186 - val_acc: 0.7345\n",
      "Epoch 41/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.8783 - acc: 0.7426 - val_loss: 0.9192 - val_acc: 0.7310\n",
      "Epoch 42/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.8821 - acc: 0.7400 - val_loss: 0.9100 - val_acc: 0.7345\n",
      "Epoch 43/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.8712 - acc: 0.7441 - val_loss: 0.9080 - val_acc: 0.7351\n",
      "Epoch 44/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.8669 - acc: 0.7453 - val_loss: 0.9115 - val_acc: 0.7329\n",
      "Epoch 45/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.8606 - acc: 0.7476 - val_loss: 0.9141 - val_acc: 0.7353\n",
      "Epoch 46/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.8572 - acc: 0.7474 - val_loss: 0.8978 - val_acc: 0.7401\n",
      "Epoch 47/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.8556 - acc: 0.7481 - val_loss: 0.9031 - val_acc: 0.7351\n",
      "Epoch 48/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.8509 - acc: 0.7498 - val_loss: 0.8897 - val_acc: 0.7414\n",
      "Epoch 49/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.8453 - acc: 0.7506 - val_loss: 0.9122 - val_acc: 0.7340\n",
      "Epoch 50/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.8454 - acc: 0.7521 - val_loss: 0.8978 - val_acc: 0.7333\n",
      "Epoch 51/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.8418 - acc: 0.7522 - val_loss: 0.8806 - val_acc: 0.7447\n",
      "Epoch 52/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.8358 - acc: 0.7550 - val_loss: 0.8880 - val_acc: 0.7392\n",
      "Epoch 53/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.8306 - acc: 0.7565 - val_loss: 0.8737 - val_acc: 0.7483\n",
      "Epoch 54/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.8274 - acc: 0.7589 - val_loss: 0.8765 - val_acc: 0.7458\n",
      "Epoch 55/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.8244 - acc: 0.7594 - val_loss: 0.8715 - val_acc: 0.7487\n",
      "Epoch 56/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.8222 - acc: 0.7592 - val_loss: 0.8659 - val_acc: 0.7482\n",
      "Epoch 57/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.8165 - acc: 0.7617 - val_loss: 0.8677 - val_acc: 0.7508\n",
      "Epoch 58/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.8143 - acc: 0.7610 - val_loss: 0.8689 - val_acc: 0.7502\n",
      "Epoch 59/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.8154 - acc: 0.7630 - val_loss: 0.8646 - val_acc: 0.7491\n",
      "Epoch 60/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.8092 - acc: 0.7630 - val_loss: 0.8616 - val_acc: 0.7520\n",
      "Epoch 61/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.8075 - acc: 0.7642 - val_loss: 0.8664 - val_acc: 0.7489\n",
      "Epoch 62/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.8050 - acc: 0.7644 - val_loss: 0.8691 - val_acc: 0.7462\n",
      "Epoch 63/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.8011 - acc: 0.7677 - val_loss: 0.8551 - val_acc: 0.7549\n",
      "Epoch 64/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.7986 - acc: 0.7662 - val_loss: 0.8524 - val_acc: 0.7552\n",
      "Epoch 65/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.7952 - acc: 0.7680 - val_loss: 0.8533 - val_acc: 0.7546\n",
      "Epoch 66/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.7942 - acc: 0.7683 - val_loss: 0.8502 - val_acc: 0.7539\n",
      "Epoch 67/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.7896 - acc: 0.7703 - val_loss: 0.8540 - val_acc: 0.7516\n",
      "Epoch 68/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.7893 - acc: 0.7689 - val_loss: 0.8624 - val_acc: 0.7468\n",
      "Epoch 69/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.7867 - acc: 0.7700 - val_loss: 0.8612 - val_acc: 0.7496\n",
      "Epoch 70/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.7830 - acc: 0.7718 - val_loss: 0.8522 - val_acc: 0.7549\n",
      "Epoch 71/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.7828 - acc: 0.7726 - val_loss: 0.8364 - val_acc: 0.7569\n",
      "Epoch 72/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.7817 - acc: 0.7719 - val_loss: 0.8407 - val_acc: 0.7577\n",
      "Epoch 73/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.7771 - acc: 0.7742 - val_loss: 0.8316 - val_acc: 0.7590\n",
      "Epoch 74/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.7759 - acc: 0.7755 - val_loss: 0.8387 - val_acc: 0.7571\n",
      "Epoch 75/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.7738 - acc: 0.7745 - val_loss: 0.8320 - val_acc: 0.7604\n",
      "Epoch 76/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.7707 - acc: 0.7761 - val_loss: 0.8378 - val_acc: 0.7594\n",
      "Epoch 77/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.7695 - acc: 0.7768 - val_loss: 0.8345 - val_acc: 0.7597\n",
      "Epoch 78/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.7672 - acc: 0.7771 - val_loss: 0.8400 - val_acc: 0.7568\n",
      "Epoch 79/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.7671 - acc: 0.7769 - val_loss: 0.8284 - val_acc: 0.7618\n",
      "Epoch 80/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.7614 - acc: 0.7785 - val_loss: 0.8287 - val_acc: 0.7650\n",
      "Epoch 81/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.7596 - acc: 0.7791 - val_loss: 0.8203 - val_acc: 0.7638\n",
      "Epoch 82/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.7586 - acc: 0.7802 - val_loss: 0.8230 - val_acc: 0.7643\n",
      "Epoch 83/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.7569 - acc: 0.7789 - val_loss: 0.8195 - val_acc: 0.7657\n",
      "Epoch 84/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.7576 - acc: 0.7795 - val_loss: 0.8187 - val_acc: 0.7658\n",
      "Epoch 85/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.7575 - acc: 0.7793 - val_loss: 0.8201 - val_acc: 0.7653\n",
      "Epoch 86/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.7521 - acc: 0.7820 - val_loss: 0.8237 - val_acc: 0.7651\n",
      "Epoch 87/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.7512 - acc: 0.7811 - val_loss: 0.8217 - val_acc: 0.7649\n",
      "Epoch 88/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.7490 - acc: 0.7827 - val_loss: 0.8128 - val_acc: 0.7651\n",
      "Epoch 89/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.7479 - acc: 0.7835 - val_loss: 0.8250 - val_acc: 0.7629\n",
      "Epoch 90/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.7479 - acc: 0.7827 - val_loss: 0.8097 - val_acc: 0.7669\n",
      "Epoch 91/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.7454 - acc: 0.7836 - val_loss: 0.8197 - val_acc: 0.7636\n",
      "Epoch 92/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.7428 - acc: 0.7851 - val_loss: 0.8117 - val_acc: 0.7694\n",
      "Epoch 93/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.7446 - acc: 0.7833 - val_loss: 0.8210 - val_acc: 0.7637\n",
      "Epoch 94/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.7386 - acc: 0.7860 - val_loss: 0.8037 - val_acc: 0.7716\n",
      "Epoch 95/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.7363 - acc: 0.7857 - val_loss: 0.8122 - val_acc: 0.7676\n",
      "Epoch 96/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.7370 - acc: 0.7867 - val_loss: 0.8054 - val_acc: 0.7720\n",
      "Epoch 97/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.7335 - acc: 0.7883 - val_loss: 0.8036 - val_acc: 0.7718\n",
      "Epoch 98/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.7346 - acc: 0.7871 - val_loss: 0.8139 - val_acc: 0.7706\n",
      "Epoch 99/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.7343 - acc: 0.7872 - val_loss: 0.8174 - val_acc: 0.7648\n",
      "Epoch 100/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.7324 - acc: 0.7862 - val_loss: 0.8046 - val_acc: 0.7692\n",
      "Epoch 101/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.7291 - acc: 0.7878 - val_loss: 0.8029 - val_acc: 0.7697\n",
      "Epoch 102/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.7267 - acc: 0.7884 - val_loss: 0.8086 - val_acc: 0.7713\n",
      "Epoch 103/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.7262 - acc: 0.7894 - val_loss: 0.8101 - val_acc: 0.7651\n",
      "Epoch 104/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.7268 - acc: 0.7900 - val_loss: 0.8032 - val_acc: 0.7709\n",
      "Epoch 105/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.7245 - acc: 0.7899 - val_loss: 0.8037 - val_acc: 0.7715\n",
      "Epoch 106/2000\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.7241 - acc: 0.7902 - val_loss: 0.7949 - val_acc: 0.7741\n",
      "Epoch 107/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.7210 - acc: 0.7913 - val_loss: 0.7954 - val_acc: 0.7743\n",
      "Epoch 108/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.7210 - acc: 0.7920 - val_loss: 0.7910 - val_acc: 0.7754\n",
      "Epoch 109/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.7183 - acc: 0.7934 - val_loss: 0.7925 - val_acc: 0.7735\n",
      "Epoch 110/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.7191 - acc: 0.7921 - val_loss: 0.7939 - val_acc: 0.7737\n",
      "Epoch 111/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.7188 - acc: 0.7915 - val_loss: 0.7956 - val_acc: 0.7758\n",
      "Epoch 112/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.7154 - acc: 0.7928 - val_loss: 0.7890 - val_acc: 0.7757\n",
      "Epoch 113/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.7140 - acc: 0.7935 - val_loss: 0.7952 - val_acc: 0.7733\n",
      "Epoch 114/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.7141 - acc: 0.7929 - val_loss: 0.7940 - val_acc: 0.7749\n",
      "Epoch 115/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.7141 - acc: 0.7931 - val_loss: 0.7943 - val_acc: 0.7709\n",
      "Epoch 116/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.7124 - acc: 0.7935 - val_loss: 0.7992 - val_acc: 0.7752\n",
      "Epoch 117/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.7120 - acc: 0.7938 - val_loss: 0.7872 - val_acc: 0.7757\n",
      "Epoch 118/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.7097 - acc: 0.7944 - val_loss: 0.7940 - val_acc: 0.7752\n",
      "Epoch 119/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.7105 - acc: 0.7948 - val_loss: 0.7951 - val_acc: 0.7753\n",
      "Epoch 120/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.7107 - acc: 0.7945 - val_loss: 0.7853 - val_acc: 0.7781\n",
      "Epoch 121/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.7051 - acc: 0.7979 - val_loss: 0.7845 - val_acc: 0.7772\n",
      "Epoch 122/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.7047 - acc: 0.7960 - val_loss: 0.7935 - val_acc: 0.7736\n",
      "Epoch 123/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.7061 - acc: 0.7961 - val_loss: 0.7871 - val_acc: 0.7755\n",
      "Epoch 124/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.7029 - acc: 0.7959 - val_loss: 0.7864 - val_acc: 0.7767\n",
      "Epoch 125/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.7041 - acc: 0.7964 - val_loss: 0.7831 - val_acc: 0.7768\n",
      "Epoch 126/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.7014 - acc: 0.7967 - val_loss: 0.7858 - val_acc: 0.7770\n",
      "Epoch 127/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.7004 - acc: 0.7972 - val_loss: 0.7829 - val_acc: 0.7784\n",
      "Epoch 128/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6990 - acc: 0.7981 - val_loss: 0.7830 - val_acc: 0.7782\n",
      "Epoch 129/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6998 - acc: 0.7965 - val_loss: 0.7794 - val_acc: 0.7794\n",
      "Epoch 130/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6977 - acc: 0.7976 - val_loss: 0.7817 - val_acc: 0.7785\n",
      "Epoch 131/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6985 - acc: 0.7970 - val_loss: 0.7904 - val_acc: 0.7738\n",
      "Epoch 132/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6994 - acc: 0.7975 - val_loss: 0.7833 - val_acc: 0.7763\n",
      "Epoch 133/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6959 - acc: 0.7976 - val_loss: 0.7846 - val_acc: 0.7767\n",
      "Epoch 134/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6979 - acc: 0.7977 - val_loss: 0.7793 - val_acc: 0.7783\n",
      "Epoch 135/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6946 - acc: 0.7991 - val_loss: 0.7747 - val_acc: 0.7808\n",
      "Epoch 136/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6933 - acc: 0.7987 - val_loss: 0.7802 - val_acc: 0.7765\n",
      "Epoch 137/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6922 - acc: 0.7987 - val_loss: 0.7769 - val_acc: 0.7799\n",
      "Epoch 138/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6911 - acc: 0.8002 - val_loss: 0.7746 - val_acc: 0.7809\n",
      "Epoch 139/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6892 - acc: 0.8009 - val_loss: 0.7752 - val_acc: 0.7808\n",
      "Epoch 140/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6907 - acc: 0.7991 - val_loss: 0.7751 - val_acc: 0.7802\n",
      "Epoch 141/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6890 - acc: 0.8004 - val_loss: 0.7817 - val_acc: 0.7781\n",
      "Epoch 142/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6893 - acc: 0.8003 - val_loss: 0.7777 - val_acc: 0.7790\n",
      "Epoch 143/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6877 - acc: 0.8016 - val_loss: 0.7730 - val_acc: 0.7814\n",
      "Epoch 144/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6867 - acc: 0.8014 - val_loss: 0.7734 - val_acc: 0.7795\n",
      "Epoch 145/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6859 - acc: 0.8009 - val_loss: 0.7715 - val_acc: 0.7817\n",
      "Epoch 146/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6859 - acc: 0.8019 - val_loss: 0.7763 - val_acc: 0.7812\n",
      "Epoch 147/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6850 - acc: 0.8021 - val_loss: 0.7711 - val_acc: 0.7814\n",
      "Epoch 148/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6831 - acc: 0.8033 - val_loss: 0.7729 - val_acc: 0.7799\n",
      "Epoch 149/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6822 - acc: 0.8023 - val_loss: 0.7693 - val_acc: 0.7832\n",
      "Epoch 150/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6821 - acc: 0.8037 - val_loss: 0.7699 - val_acc: 0.7828\n",
      "Epoch 151/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6827 - acc: 0.8032 - val_loss: 0.7678 - val_acc: 0.7831\n",
      "Epoch 152/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6801 - acc: 0.8033 - val_loss: 0.7694 - val_acc: 0.7825\n",
      "Epoch 153/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6810 - acc: 0.8032 - val_loss: 0.7742 - val_acc: 0.7807\n",
      "Epoch 154/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6787 - acc: 0.8043 - val_loss: 0.7700 - val_acc: 0.7832\n",
      "Epoch 155/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6803 - acc: 0.8024 - val_loss: 0.7670 - val_acc: 0.7843\n",
      "Epoch 156/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6793 - acc: 0.8026 - val_loss: 0.7645 - val_acc: 0.7855\n",
      "Epoch 157/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6779 - acc: 0.8037 - val_loss: 0.7699 - val_acc: 0.7804\n",
      "Epoch 158/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6782 - acc: 0.8037 - val_loss: 0.7688 - val_acc: 0.7820\n",
      "Epoch 159/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6773 - acc: 0.8031 - val_loss: 0.7706 - val_acc: 0.7813\n",
      "Epoch 160/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6760 - acc: 0.8038 - val_loss: 0.7673 - val_acc: 0.7823\n",
      "Epoch 161/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6756 - acc: 0.8037 - val_loss: 0.7702 - val_acc: 0.7833\n",
      "Epoch 162/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6752 - acc: 0.8050 - val_loss: 0.7667 - val_acc: 0.7837\n",
      "Epoch 163/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6746 - acc: 0.8044 - val_loss: 0.7638 - val_acc: 0.7831\n",
      "Epoch 164/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6734 - acc: 0.8048 - val_loss: 0.7636 - val_acc: 0.7849\n",
      "Epoch 165/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6733 - acc: 0.8051 - val_loss: 0.7757 - val_acc: 0.7798\n",
      "Epoch 166/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6729 - acc: 0.8062 - val_loss: 0.7637 - val_acc: 0.7857\n",
      "Epoch 167/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6734 - acc: 0.8060 - val_loss: 0.7623 - val_acc: 0.7840\n",
      "Epoch 168/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6723 - acc: 0.8054 - val_loss: 0.7642 - val_acc: 0.7832\n",
      "Epoch 169/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6701 - acc: 0.8055 - val_loss: 0.7669 - val_acc: 0.7826\n",
      "Epoch 170/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6704 - acc: 0.8065 - val_loss: 0.7657 - val_acc: 0.7828\n",
      "Epoch 171/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6715 - acc: 0.8056 - val_loss: 0.7669 - val_acc: 0.7815\n",
      "Epoch 172/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6687 - acc: 0.8060 - val_loss: 0.7645 - val_acc: 0.7830\n",
      "Epoch 173/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6700 - acc: 0.8057 - val_loss: 0.7600 - val_acc: 0.7849\n",
      "Epoch 174/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6678 - acc: 0.8075 - val_loss: 0.7679 - val_acc: 0.7824\n",
      "Epoch 175/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6674 - acc: 0.8067 - val_loss: 0.7640 - val_acc: 0.7852\n",
      "Epoch 176/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6675 - acc: 0.8067 - val_loss: 0.7649 - val_acc: 0.7833\n",
      "Epoch 177/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6655 - acc: 0.8076 - val_loss: 0.7587 - val_acc: 0.7861\n",
      "Epoch 178/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6652 - acc: 0.8071 - val_loss: 0.7637 - val_acc: 0.7858\n",
      "Epoch 179/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6668 - acc: 0.8068 - val_loss: 0.7631 - val_acc: 0.7834\n",
      "Epoch 180/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6641 - acc: 0.8078 - val_loss: 0.7569 - val_acc: 0.7875\n",
      "Epoch 181/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6638 - acc: 0.8069 - val_loss: 0.7588 - val_acc: 0.7869\n",
      "Epoch 182/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6633 - acc: 0.8082 - val_loss: 0.7626 - val_acc: 0.7856\n",
      "Epoch 183/2000\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.6641 - acc: 0.8076 - val_loss: 0.7583 - val_acc: 0.7854\n",
      "Epoch 184/2000\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.6619 - acc: 0.8095 - val_loss: 0.7579 - val_acc: 0.7845\n",
      "Epoch 185/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6632 - acc: 0.8081 - val_loss: 0.7593 - val_acc: 0.7844\n",
      "Epoch 186/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6621 - acc: 0.8085 - val_loss: 0.7589 - val_acc: 0.7878\n",
      "Epoch 187/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6617 - acc: 0.8080 - val_loss: 0.7684 - val_acc: 0.7847\n",
      "Epoch 188/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6605 - acc: 0.8076 - val_loss: 0.7557 - val_acc: 0.7874\n",
      "Epoch 189/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6600 - acc: 0.8086 - val_loss: 0.7546 - val_acc: 0.7881\n",
      "Epoch 190/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6601 - acc: 0.8083 - val_loss: 0.7565 - val_acc: 0.7854\n",
      "Epoch 191/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6611 - acc: 0.8082 - val_loss: 0.7555 - val_acc: 0.7866\n",
      "Epoch 192/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6583 - acc: 0.8085 - val_loss: 0.7548 - val_acc: 0.7868\n",
      "Epoch 193/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6599 - acc: 0.8087 - val_loss: 0.7563 - val_acc: 0.7858\n",
      "Epoch 194/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6593 - acc: 0.8086 - val_loss: 0.7574 - val_acc: 0.7869\n",
      "Epoch 195/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6580 - acc: 0.8090 - val_loss: 0.7555 - val_acc: 0.7882\n",
      "Epoch 196/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6574 - acc: 0.8095 - val_loss: 0.7548 - val_acc: 0.7863\n",
      "Epoch 197/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6559 - acc: 0.8098 - val_loss: 0.7542 - val_acc: 0.7878\n",
      "Epoch 198/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6565 - acc: 0.8099 - val_loss: 0.7603 - val_acc: 0.7838\n",
      "Epoch 199/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6556 - acc: 0.8098 - val_loss: 0.7583 - val_acc: 0.7873\n",
      "Epoch 200/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6555 - acc: 0.8098 - val_loss: 0.7626 - val_acc: 0.7832\n",
      "Epoch 201/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6558 - acc: 0.8105 - val_loss: 0.7537 - val_acc: 0.7893\n",
      "Epoch 202/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6538 - acc: 0.8106 - val_loss: 0.7545 - val_acc: 0.7890\n",
      "Epoch 203/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6539 - acc: 0.8111 - val_loss: 0.7529 - val_acc: 0.7884\n",
      "Epoch 204/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6531 - acc: 0.8113 - val_loss: 0.7530 - val_acc: 0.7896\n",
      "Epoch 205/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6531 - acc: 0.8097 - val_loss: 0.7549 - val_acc: 0.7872\n",
      "Epoch 206/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6518 - acc: 0.8117 - val_loss: 0.7523 - val_acc: 0.7885\n",
      "Epoch 207/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6519 - acc: 0.8124 - val_loss: 0.7538 - val_acc: 0.7874\n",
      "Epoch 208/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6518 - acc: 0.8107 - val_loss: 0.7510 - val_acc: 0.7881\n",
      "Epoch 209/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6513 - acc: 0.8111 - val_loss: 0.7550 - val_acc: 0.7892\n",
      "Epoch 210/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6521 - acc: 0.8110 - val_loss: 0.7505 - val_acc: 0.7908\n",
      "Epoch 211/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6503 - acc: 0.8109 - val_loss: 0.7537 - val_acc: 0.7904\n",
      "Epoch 212/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6507 - acc: 0.8119 - val_loss: 0.7533 - val_acc: 0.7904\n",
      "Epoch 213/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6498 - acc: 0.8112 - val_loss: 0.7528 - val_acc: 0.7879\n",
      "Epoch 214/2000\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.6489 - acc: 0.8120 - val_loss: 0.7520 - val_acc: 0.7907\n",
      "Epoch 215/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6493 - acc: 0.8108 - val_loss: 0.7508 - val_acc: 0.7907\n",
      "Epoch 216/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6483 - acc: 0.8125 - val_loss: 0.7497 - val_acc: 0.7887\n",
      "Epoch 217/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6486 - acc: 0.8130 - val_loss: 0.7501 - val_acc: 0.7887\n",
      "Epoch 218/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6476 - acc: 0.8129 - val_loss: 0.7470 - val_acc: 0.7922\n",
      "Epoch 219/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6470 - acc: 0.8128 - val_loss: 0.7494 - val_acc: 0.7888\n",
      "Epoch 220/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6460 - acc: 0.8129 - val_loss: 0.7483 - val_acc: 0.7914\n",
      "Epoch 221/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6471 - acc: 0.8126 - val_loss: 0.7469 - val_acc: 0.7902\n",
      "Epoch 222/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6457 - acc: 0.8127 - val_loss: 0.7512 - val_acc: 0.7882\n",
      "Epoch 223/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6452 - acc: 0.8136 - val_loss: 0.7528 - val_acc: 0.7878\n",
      "Epoch 224/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6449 - acc: 0.8123 - val_loss: 0.7513 - val_acc: 0.7918\n",
      "Epoch 225/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6455 - acc: 0.8129 - val_loss: 0.7512 - val_acc: 0.7902\n",
      "Epoch 226/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6460 - acc: 0.8122 - val_loss: 0.7476 - val_acc: 0.7912\n",
      "Epoch 227/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6434 - acc: 0.8137 - val_loss: 0.7487 - val_acc: 0.7898\n",
      "Epoch 228/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6438 - acc: 0.8130 - val_loss: 0.7466 - val_acc: 0.7922\n",
      "Epoch 229/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6432 - acc: 0.8133 - val_loss: 0.7465 - val_acc: 0.7910\n",
      "Epoch 230/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6443 - acc: 0.8130 - val_loss: 0.7462 - val_acc: 0.7918\n",
      "Epoch 231/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6426 - acc: 0.8146 - val_loss: 0.7461 - val_acc: 0.7925\n",
      "Epoch 232/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6433 - acc: 0.8125 - val_loss: 0.7466 - val_acc: 0.7916\n",
      "Epoch 233/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6434 - acc: 0.8137 - val_loss: 0.7468 - val_acc: 0.7906\n",
      "Epoch 234/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6419 - acc: 0.8137 - val_loss: 0.7472 - val_acc: 0.7900\n",
      "Epoch 235/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6424 - acc: 0.8137 - val_loss: 0.7453 - val_acc: 0.7921\n",
      "Epoch 236/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6410 - acc: 0.8146 - val_loss: 0.7448 - val_acc: 0.7917\n",
      "Epoch 237/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6409 - acc: 0.8133 - val_loss: 0.7447 - val_acc: 0.7926\n",
      "Epoch 238/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6401 - acc: 0.8145 - val_loss: 0.7494 - val_acc: 0.7895\n",
      "Epoch 239/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6407 - acc: 0.8137 - val_loss: 0.7473 - val_acc: 0.7909\n",
      "Epoch 240/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6391 - acc: 0.8140 - val_loss: 0.7498 - val_acc: 0.7904\n",
      "Epoch 241/2000\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.6399 - acc: 0.8148 - val_loss: 0.7468 - val_acc: 0.7907\n",
      "Epoch 242/2000\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.6391 - acc: 0.8146 - val_loss: 0.7459 - val_acc: 0.7911\n",
      "Epoch 243/2000\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.6387 - acc: 0.8148 - val_loss: 0.7458 - val_acc: 0.7909\n",
      "Epoch 244/2000\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.6390 - acc: 0.8139 - val_loss: 0.7440 - val_acc: 0.7917\n",
      "Epoch 245/2000\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.6393 - acc: 0.8136 - val_loss: 0.7483 - val_acc: 0.7910\n",
      "Epoch 246/2000\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.6381 - acc: 0.8148 - val_loss: 0.7449 - val_acc: 0.7902\n",
      "Epoch 247/2000\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.6389 - acc: 0.8147 - val_loss: 0.7435 - val_acc: 0.7928\n",
      "Epoch 248/2000\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.6367 - acc: 0.8155 - val_loss: 0.7448 - val_acc: 0.7898\n",
      "Epoch 249/2000\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.6376 - acc: 0.8149 - val_loss: 0.7441 - val_acc: 0.7924\n",
      "Epoch 250/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6361 - acc: 0.8150 - val_loss: 0.7426 - val_acc: 0.7927\n",
      "Epoch 251/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6363 - acc: 0.8154 - val_loss: 0.7413 - val_acc: 0.7927\n",
      "Epoch 252/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6361 - acc: 0.8155 - val_loss: 0.7435 - val_acc: 0.7929\n",
      "Epoch 253/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6369 - acc: 0.8154 - val_loss: 0.7423 - val_acc: 0.7926\n",
      "Epoch 254/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6352 - acc: 0.8158 - val_loss: 0.7427 - val_acc: 0.7932\n",
      "Epoch 255/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6342 - acc: 0.8151 - val_loss: 0.7457 - val_acc: 0.7910\n",
      "Epoch 256/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6362 - acc: 0.8151 - val_loss: 0.7457 - val_acc: 0.7920\n",
      "Epoch 257/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6348 - acc: 0.8155 - val_loss: 0.7406 - val_acc: 0.7937\n",
      "Epoch 258/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6337 - acc: 0.8164 - val_loss: 0.7400 - val_acc: 0.7947\n",
      "Epoch 259/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6358 - acc: 0.8156 - val_loss: 0.7409 - val_acc: 0.7921\n",
      "Epoch 260/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6340 - acc: 0.8166 - val_loss: 0.7437 - val_acc: 0.7919\n",
      "Epoch 261/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6334 - acc: 0.8166 - val_loss: 0.7439 - val_acc: 0.7912\n",
      "Epoch 262/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6324 - acc: 0.8168 - val_loss: 0.7384 - val_acc: 0.7943\n",
      "Epoch 263/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6315 - acc: 0.8168 - val_loss: 0.7386 - val_acc: 0.7935\n",
      "Epoch 264/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6321 - acc: 0.8167 - val_loss: 0.7400 - val_acc: 0.7933\n",
      "Epoch 265/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6322 - acc: 0.8161 - val_loss: 0.7431 - val_acc: 0.7933\n",
      "Epoch 266/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6308 - acc: 0.8169 - val_loss: 0.7441 - val_acc: 0.7917\n",
      "Epoch 267/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6321 - acc: 0.8163 - val_loss: 0.7424 - val_acc: 0.7927\n",
      "Epoch 268/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6316 - acc: 0.8162 - val_loss: 0.7436 - val_acc: 0.7922\n",
      "Epoch 269/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6310 - acc: 0.8177 - val_loss: 0.7395 - val_acc: 0.7947\n",
      "Epoch 270/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6311 - acc: 0.8156 - val_loss: 0.7454 - val_acc: 0.7914\n",
      "Epoch 271/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6308 - acc: 0.8176 - val_loss: 0.7414 - val_acc: 0.7933\n",
      "Epoch 272/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6295 - acc: 0.8174 - val_loss: 0.7371 - val_acc: 0.7947\n",
      "Epoch 273/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6299 - acc: 0.8171 - val_loss: 0.7390 - val_acc: 0.7938\n",
      "Epoch 274/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6294 - acc: 0.8167 - val_loss: 0.7408 - val_acc: 0.7931\n",
      "Epoch 275/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6305 - acc: 0.8175 - val_loss: 0.7398 - val_acc: 0.7928\n",
      "Epoch 276/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6286 - acc: 0.8182 - val_loss: 0.7428 - val_acc: 0.7931\n",
      "Epoch 277/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6280 - acc: 0.8175 - val_loss: 0.7393 - val_acc: 0.7958\n",
      "Epoch 278/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6291 - acc: 0.8178 - val_loss: 0.7405 - val_acc: 0.7933\n",
      "Epoch 279/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6284 - acc: 0.8172 - val_loss: 0.7373 - val_acc: 0.7947\n",
      "Epoch 280/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6282 - acc: 0.8176 - val_loss: 0.7373 - val_acc: 0.7937\n",
      "Epoch 281/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6276 - acc: 0.8170 - val_loss: 0.7403 - val_acc: 0.7953\n",
      "Epoch 282/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6287 - acc: 0.8175 - val_loss: 0.7369 - val_acc: 0.7961\n",
      "Epoch 283/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6275 - acc: 0.8176 - val_loss: 0.7398 - val_acc: 0.7936\n",
      "Epoch 284/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6270 - acc: 0.8191 - val_loss: 0.7384 - val_acc: 0.7943\n",
      "Epoch 285/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6265 - acc: 0.8174 - val_loss: 0.7383 - val_acc: 0.7954\n",
      "Epoch 286/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6263 - acc: 0.8180 - val_loss: 0.7373 - val_acc: 0.7947\n",
      "Epoch 287/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6262 - acc: 0.8175 - val_loss: 0.7373 - val_acc: 0.7941\n",
      "Epoch 288/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6261 - acc: 0.8178 - val_loss: 0.7356 - val_acc: 0.7956\n",
      "Epoch 289/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6251 - acc: 0.8182 - val_loss: 0.7364 - val_acc: 0.7964\n",
      "Epoch 290/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6266 - acc: 0.8185 - val_loss: 0.7417 - val_acc: 0.7919\n",
      "Epoch 291/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6250 - acc: 0.8182 - val_loss: 0.7374 - val_acc: 0.7944\n",
      "Epoch 292/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6248 - acc: 0.8192 - val_loss: 0.7366 - val_acc: 0.7945\n",
      "Epoch 293/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6258 - acc: 0.8187 - val_loss: 0.7362 - val_acc: 0.7951\n",
      "Epoch 294/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6242 - acc: 0.8186 - val_loss: 0.7355 - val_acc: 0.7947\n",
      "Epoch 295/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6247 - acc: 0.8189 - val_loss: 0.7370 - val_acc: 0.7958\n",
      "Epoch 296/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6233 - acc: 0.8191 - val_loss: 0.7366 - val_acc: 0.7954\n",
      "Epoch 297/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6237 - acc: 0.8190 - val_loss: 0.7371 - val_acc: 0.7947\n",
      "Epoch 298/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6239 - acc: 0.8186 - val_loss: 0.7380 - val_acc: 0.7936\n",
      "Epoch 299/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6226 - acc: 0.8189 - val_loss: 0.7360 - val_acc: 0.7962\n",
      "Epoch 300/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6224 - acc: 0.8195 - val_loss: 0.7375 - val_acc: 0.7944\n",
      "Epoch 301/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6229 - acc: 0.8183 - val_loss: 0.7366 - val_acc: 0.7949\n",
      "Epoch 302/2000\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.6224 - acc: 0.8201 - val_loss: 0.7370 - val_acc: 0.7945\n",
      "Epoch 303/2000\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.6227 - acc: 0.8178 - val_loss: 0.7374 - val_acc: 0.7958\n",
      "Epoch 304/2000\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.6219 - acc: 0.8199 - val_loss: 0.7343 - val_acc: 0.7958\n",
      "Epoch 305/2000\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.6217 - acc: 0.8195 - val_loss: 0.7350 - val_acc: 0.7964\n",
      "Epoch 306/2000\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.6220 - acc: 0.8200 - val_loss: 0.7358 - val_acc: 0.7946\n",
      "Epoch 307/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6213 - acc: 0.8190 - val_loss: 0.7330 - val_acc: 0.7965\n",
      "Epoch 308/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6207 - acc: 0.8200 - val_loss: 0.7351 - val_acc: 0.7951\n",
      "Epoch 309/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6214 - acc: 0.8197 - val_loss: 0.7341 - val_acc: 0.7955\n",
      "Epoch 310/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6203 - acc: 0.8196 - val_loss: 0.7351 - val_acc: 0.7959\n",
      "Epoch 311/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6199 - acc: 0.8195 - val_loss: 0.7349 - val_acc: 0.7958\n",
      "Epoch 312/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6188 - acc: 0.8204 - val_loss: 0.7330 - val_acc: 0.7960\n",
      "Epoch 313/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6191 - acc: 0.8202 - val_loss: 0.7324 - val_acc: 0.7972\n",
      "Epoch 314/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6199 - acc: 0.8203 - val_loss: 0.7349 - val_acc: 0.7959\n",
      "Epoch 315/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6191 - acc: 0.8207 - val_loss: 0.7342 - val_acc: 0.7962\n",
      "Epoch 316/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6191 - acc: 0.8201 - val_loss: 0.7340 - val_acc: 0.7962\n",
      "Epoch 317/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6193 - acc: 0.8209 - val_loss: 0.7320 - val_acc: 0.7972\n",
      "Epoch 318/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6184 - acc: 0.8207 - val_loss: 0.7348 - val_acc: 0.7963\n",
      "Epoch 319/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6182 - acc: 0.8214 - val_loss: 0.7350 - val_acc: 0.7969\n",
      "Epoch 320/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6182 - acc: 0.8217 - val_loss: 0.7333 - val_acc: 0.7968\n",
      "Epoch 321/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6180 - acc: 0.8208 - val_loss: 0.7335 - val_acc: 0.7965\n",
      "Epoch 322/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6176 - acc: 0.8204 - val_loss: 0.7334 - val_acc: 0.7974\n",
      "Epoch 323/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6177 - acc: 0.8201 - val_loss: 0.7324 - val_acc: 0.7971\n",
      "Epoch 324/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6169 - acc: 0.8212 - val_loss: 0.7352 - val_acc: 0.7946\n",
      "Epoch 325/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6174 - acc: 0.8204 - val_loss: 0.7322 - val_acc: 0.7956\n",
      "Epoch 326/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6167 - acc: 0.8204 - val_loss: 0.7342 - val_acc: 0.7946\n",
      "Epoch 327/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6172 - acc: 0.8215 - val_loss: 0.7303 - val_acc: 0.7976\n",
      "Epoch 328/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6166 - acc: 0.8199 - val_loss: 0.7330 - val_acc: 0.7964\n",
      "Epoch 329/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6162 - acc: 0.8214 - val_loss: 0.7304 - val_acc: 0.7976\n",
      "Epoch 330/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6163 - acc: 0.8199 - val_loss: 0.7310 - val_acc: 0.7990\n",
      "Epoch 331/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6155 - acc: 0.8212 - val_loss: 0.7314 - val_acc: 0.7955\n",
      "Epoch 332/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6156 - acc: 0.8208 - val_loss: 0.7316 - val_acc: 0.7972\n",
      "Epoch 333/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6155 - acc: 0.8210 - val_loss: 0.7338 - val_acc: 0.7963\n",
      "Epoch 334/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6157 - acc: 0.8215 - val_loss: 0.7327 - val_acc: 0.7958\n",
      "Epoch 335/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6147 - acc: 0.8210 - val_loss: 0.7321 - val_acc: 0.7957\n",
      "Epoch 336/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6154 - acc: 0.8213 - val_loss: 0.7305 - val_acc: 0.7974\n",
      "Epoch 337/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6147 - acc: 0.8209 - val_loss: 0.7319 - val_acc: 0.7947\n",
      "Epoch 338/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6149 - acc: 0.8209 - val_loss: 0.7306 - val_acc: 0.7977\n",
      "Epoch 339/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6143 - acc: 0.8224 - val_loss: 0.7306 - val_acc: 0.7967\n",
      "Epoch 340/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6138 - acc: 0.8217 - val_loss: 0.7305 - val_acc: 0.7976\n",
      "Epoch 341/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6143 - acc: 0.8211 - val_loss: 0.7320 - val_acc: 0.7966\n",
      "Epoch 342/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6142 - acc: 0.8210 - val_loss: 0.7351 - val_acc: 0.7953\n",
      "Epoch 343/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6143 - acc: 0.8226 - val_loss: 0.7323 - val_acc: 0.7961\n",
      "Epoch 344/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6132 - acc: 0.8228 - val_loss: 0.7302 - val_acc: 0.7972\n",
      "Epoch 345/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6128 - acc: 0.8217 - val_loss: 0.7300 - val_acc: 0.7952\n",
      "Epoch 346/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6127 - acc: 0.8225 - val_loss: 0.7322 - val_acc: 0.7961\n",
      "Epoch 347/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6124 - acc: 0.8215 - val_loss: 0.7305 - val_acc: 0.7964\n",
      "Epoch 348/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6118 - acc: 0.8226 - val_loss: 0.7299 - val_acc: 0.7974\n",
      "Epoch 349/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6130 - acc: 0.8221 - val_loss: 0.7302 - val_acc: 0.7968\n",
      "Epoch 350/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6122 - acc: 0.8221 - val_loss: 0.7339 - val_acc: 0.7962\n",
      "Epoch 351/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6114 - acc: 0.8228 - val_loss: 0.7296 - val_acc: 0.7978\n",
      "Epoch 352/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6118 - acc: 0.8225 - val_loss: 0.7297 - val_acc: 0.7977\n",
      "Epoch 353/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6115 - acc: 0.8220 - val_loss: 0.7301 - val_acc: 0.7966\n",
      "Epoch 354/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6114 - acc: 0.8222 - val_loss: 0.7305 - val_acc: 0.7958\n",
      "Epoch 355/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6112 - acc: 0.8223 - val_loss: 0.7305 - val_acc: 0.7966\n",
      "Epoch 356/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6112 - acc: 0.8229 - val_loss: 0.7295 - val_acc: 0.7972\n",
      "Epoch 357/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6124 - acc: 0.8220 - val_loss: 0.7298 - val_acc: 0.7976\n",
      "Epoch 358/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6107 - acc: 0.8231 - val_loss: 0.7289 - val_acc: 0.7980\n",
      "Epoch 359/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6102 - acc: 0.8220 - val_loss: 0.7277 - val_acc: 0.7990\n",
      "Epoch 360/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6099 - acc: 0.8224 - val_loss: 0.7281 - val_acc: 0.7978\n",
      "Epoch 361/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6102 - acc: 0.8229 - val_loss: 0.7280 - val_acc: 0.7972\n",
      "Epoch 362/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6096 - acc: 0.8230 - val_loss: 0.7295 - val_acc: 0.7992\n",
      "Epoch 363/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6098 - acc: 0.8230 - val_loss: 0.7294 - val_acc: 0.7971\n",
      "Epoch 364/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6101 - acc: 0.8223 - val_loss: 0.7273 - val_acc: 0.7988\n",
      "Epoch 365/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6091 - acc: 0.8227 - val_loss: 0.7290 - val_acc: 0.7971\n",
      "Epoch 366/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6087 - acc: 0.8227 - val_loss: 0.7273 - val_acc: 0.7969\n",
      "Epoch 367/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6093 - acc: 0.8227 - val_loss: 0.7304 - val_acc: 0.7974\n",
      "Epoch 368/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6089 - acc: 0.8225 - val_loss: 0.7271 - val_acc: 0.7974\n",
      "Epoch 369/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6088 - acc: 0.8223 - val_loss: 0.7354 - val_acc: 0.7964\n",
      "Epoch 370/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6085 - acc: 0.8242 - val_loss: 0.7291 - val_acc: 0.7967\n",
      "Epoch 371/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6084 - acc: 0.8225 - val_loss: 0.7300 - val_acc: 0.7969\n",
      "Epoch 372/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6079 - acc: 0.8243 - val_loss: 0.7305 - val_acc: 0.7962\n",
      "Epoch 373/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6077 - acc: 0.8233 - val_loss: 0.7300 - val_acc: 0.7989\n",
      "Epoch 374/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6068 - acc: 0.8239 - val_loss: 0.7257 - val_acc: 0.7984\n",
      "Epoch 375/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6075 - acc: 0.8235 - val_loss: 0.7269 - val_acc: 0.7973\n",
      "Epoch 376/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6079 - acc: 0.8232 - val_loss: 0.7289 - val_acc: 0.7963\n",
      "Epoch 377/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6069 - acc: 0.8233 - val_loss: 0.7274 - val_acc: 0.7975\n",
      "Epoch 378/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6069 - acc: 0.8240 - val_loss: 0.7284 - val_acc: 0.7978\n",
      "Epoch 379/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6079 - acc: 0.8231 - val_loss: 0.7272 - val_acc: 0.7986\n",
      "Epoch 380/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6072 - acc: 0.8243 - val_loss: 0.7281 - val_acc: 0.7987\n",
      "Epoch 381/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6061 - acc: 0.8236 - val_loss: 0.7270 - val_acc: 0.7992\n",
      "Epoch 382/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6062 - acc: 0.8239 - val_loss: 0.7294 - val_acc: 0.7978\n",
      "Epoch 383/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6067 - acc: 0.8235 - val_loss: 0.7276 - val_acc: 0.7992\n",
      "Epoch 384/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6057 - acc: 0.8243 - val_loss: 0.7254 - val_acc: 0.7987\n",
      "Epoch 385/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6055 - acc: 0.8240 - val_loss: 0.7277 - val_acc: 0.7972\n",
      "Epoch 386/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6051 - acc: 0.8253 - val_loss: 0.7270 - val_acc: 0.7979\n",
      "Epoch 387/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6052 - acc: 0.8235 - val_loss: 0.7249 - val_acc: 0.7992\n",
      "Epoch 388/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6056 - acc: 0.8240 - val_loss: 0.7269 - val_acc: 0.7992\n",
      "Epoch 389/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6051 - acc: 0.8239 - val_loss: 0.7270 - val_acc: 0.7988\n",
      "Epoch 390/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6047 - acc: 0.8243 - val_loss: 0.7249 - val_acc: 0.7993\n",
      "Epoch 391/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6053 - acc: 0.8240 - val_loss: 0.7266 - val_acc: 0.7983\n",
      "Epoch 392/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6053 - acc: 0.8244 - val_loss: 0.7277 - val_acc: 0.7988\n",
      "Epoch 393/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6043 - acc: 0.8248 - val_loss: 0.7279 - val_acc: 0.7973\n",
      "Epoch 394/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6045 - acc: 0.8236 - val_loss: 0.7250 - val_acc: 0.7996\n",
      "Epoch 395/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6036 - acc: 0.8247 - val_loss: 0.7250 - val_acc: 0.7984\n",
      "Epoch 396/2000\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.6037 - acc: 0.8250 - val_loss: 0.7245 - val_acc: 0.7987\n",
      "Epoch 397/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6029 - acc: 0.8253 - val_loss: 0.7256 - val_acc: 0.7980\n",
      "Epoch 398/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6036 - acc: 0.8238 - val_loss: 0.7267 - val_acc: 0.7997\n",
      "Epoch 399/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6030 - acc: 0.8251 - val_loss: 0.7272 - val_acc: 0.7982\n",
      "Epoch 400/2000\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 0.6034 - acc: 0.8243 - val_loss: 0.7247 - val_acc: 0.7992\n",
      "Epoch 401/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6028 - acc: 0.8246 - val_loss: 0.7243 - val_acc: 0.7976\n",
      "Epoch 402/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6028 - acc: 0.8250 - val_loss: 0.7292 - val_acc: 0.7963\n",
      "Epoch 403/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6023 - acc: 0.8252 - val_loss: 0.7242 - val_acc: 0.7986\n",
      "Epoch 404/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6030 - acc: 0.8250 - val_loss: 0.7255 - val_acc: 0.8001\n",
      "Epoch 405/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6022 - acc: 0.8251 - val_loss: 0.7255 - val_acc: 0.7983\n",
      "Epoch 406/2000\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.6026 - acc: 0.8247 - val_loss: 0.7269 - val_acc: 0.7979\n",
      "Epoch 407/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6018 - acc: 0.8255 - val_loss: 0.7281 - val_acc: 0.7975\n",
      "Epoch 408/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6020 - acc: 0.8248 - val_loss: 0.7249 - val_acc: 0.7986\n",
      "Epoch 409/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6020 - acc: 0.8250 - val_loss: 0.7240 - val_acc: 0.7998\n",
      "Epoch 410/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6015 - acc: 0.8259 - val_loss: 0.7259 - val_acc: 0.7989\n",
      "Epoch 411/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6015 - acc: 0.8258 - val_loss: 0.7246 - val_acc: 0.7988\n",
      "Epoch 412/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6024 - acc: 0.8256 - val_loss: 0.7237 - val_acc: 0.7987\n",
      "Epoch 413/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6007 - acc: 0.8252 - val_loss: 0.7272 - val_acc: 0.7981\n",
      "Epoch 414/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6005 - acc: 0.8253 - val_loss: 0.7257 - val_acc: 0.7976\n",
      "Epoch 415/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6013 - acc: 0.8254 - val_loss: 0.7248 - val_acc: 0.7992\n",
      "Epoch 416/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6007 - acc: 0.8255 - val_loss: 0.7245 - val_acc: 0.7991\n",
      "Epoch 417/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6010 - acc: 0.8254 - val_loss: 0.7242 - val_acc: 0.7986\n",
      "Epoch 418/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6002 - acc: 0.8260 - val_loss: 0.7244 - val_acc: 0.7985\n",
      "Epoch 419/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6002 - acc: 0.8255 - val_loss: 0.7264 - val_acc: 0.8003\n",
      "Epoch 420/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5998 - acc: 0.8253 - val_loss: 0.7238 - val_acc: 0.7987\n",
      "Epoch 421/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.6002 - acc: 0.8260 - val_loss: 0.7232 - val_acc: 0.7987\n",
      "Epoch 422/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5993 - acc: 0.8251 - val_loss: 0.7252 - val_acc: 0.7989\n",
      "Epoch 423/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5999 - acc: 0.8260 - val_loss: 0.7245 - val_acc: 0.7998\n",
      "Epoch 424/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5994 - acc: 0.8252 - val_loss: 0.7274 - val_acc: 0.7979\n",
      "Epoch 425/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5989 - acc: 0.8261 - val_loss: 0.7252 - val_acc: 0.7991\n",
      "Epoch 426/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5987 - acc: 0.8270 - val_loss: 0.7263 - val_acc: 0.7984\n",
      "Epoch 427/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5987 - acc: 0.8254 - val_loss: 0.7252 - val_acc: 0.7987\n",
      "Epoch 428/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5990 - acc: 0.8259 - val_loss: 0.7265 - val_acc: 0.7992\n",
      "Epoch 429/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5990 - acc: 0.8263 - val_loss: 0.7238 - val_acc: 0.8006\n",
      "Epoch 430/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5986 - acc: 0.8262 - val_loss: 0.7225 - val_acc: 0.7997\n",
      "Epoch 431/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5981 - acc: 0.8257 - val_loss: 0.7223 - val_acc: 0.7998\n",
      "Epoch 432/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5985 - acc: 0.8261 - val_loss: 0.7238 - val_acc: 0.8003\n",
      "Epoch 433/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5983 - acc: 0.8263 - val_loss: 0.7232 - val_acc: 0.7994\n",
      "Epoch 434/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5978 - acc: 0.8264 - val_loss: 0.7226 - val_acc: 0.8003\n",
      "Epoch 435/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5978 - acc: 0.8257 - val_loss: 0.7219 - val_acc: 0.7998\n",
      "Epoch 436/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5974 - acc: 0.8259 - val_loss: 0.7247 - val_acc: 0.7986\n",
      "Epoch 437/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5978 - acc: 0.8253 - val_loss: 0.7232 - val_acc: 0.7996\n",
      "Epoch 438/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5980 - acc: 0.8260 - val_loss: 0.7219 - val_acc: 0.8006\n",
      "Epoch 439/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5973 - acc: 0.8266 - val_loss: 0.7231 - val_acc: 0.7997\n",
      "Epoch 440/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5973 - acc: 0.8265 - val_loss: 0.7231 - val_acc: 0.7991\n",
      "Epoch 441/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5964 - acc: 0.8274 - val_loss: 0.7223 - val_acc: 0.7982\n",
      "Epoch 442/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5966 - acc: 0.8267 - val_loss: 0.7238 - val_acc: 0.7988\n",
      "Epoch 443/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5979 - acc: 0.8261 - val_loss: 0.7211 - val_acc: 0.8003\n",
      "Epoch 444/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5967 - acc: 0.8269 - val_loss: 0.7218 - val_acc: 0.8001\n",
      "Epoch 445/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5965 - acc: 0.8270 - val_loss: 0.7245 - val_acc: 0.7979\n",
      "Epoch 446/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5965 - acc: 0.8264 - val_loss: 0.7208 - val_acc: 0.8005\n",
      "Epoch 447/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5962 - acc: 0.8271 - val_loss: 0.7226 - val_acc: 0.7996\n",
      "Epoch 448/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5961 - acc: 0.8267 - val_loss: 0.7228 - val_acc: 0.7986\n",
      "Epoch 449/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5959 - acc: 0.8265 - val_loss: 0.7219 - val_acc: 0.7987\n",
      "Epoch 450/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5962 - acc: 0.8277 - val_loss: 0.7219 - val_acc: 0.8002\n",
      "Epoch 451/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5961 - acc: 0.8272 - val_loss: 0.7215 - val_acc: 0.7996\n",
      "Epoch 452/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5953 - acc: 0.8270 - val_loss: 0.7211 - val_acc: 0.8008\n",
      "Epoch 453/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5952 - acc: 0.8276 - val_loss: 0.7218 - val_acc: 0.8002\n",
      "Epoch 454/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5950 - acc: 0.8270 - val_loss: 0.7217 - val_acc: 0.7999\n",
      "Epoch 455/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5952 - acc: 0.8264 - val_loss: 0.7218 - val_acc: 0.8004\n",
      "Epoch 456/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5952 - acc: 0.8282 - val_loss: 0.7201 - val_acc: 0.8007\n",
      "Epoch 457/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5946 - acc: 0.8269 - val_loss: 0.7222 - val_acc: 0.8005\n",
      "Epoch 458/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5947 - acc: 0.8271 - val_loss: 0.7212 - val_acc: 0.8011\n",
      "Epoch 459/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5942 - acc: 0.8277 - val_loss: 0.7213 - val_acc: 0.8005\n",
      "Epoch 460/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5948 - acc: 0.8269 - val_loss: 0.7231 - val_acc: 0.7989\n",
      "Epoch 461/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5951 - acc: 0.8282 - val_loss: 0.7207 - val_acc: 0.8004\n",
      "Epoch 462/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5949 - acc: 0.8269 - val_loss: 0.7226 - val_acc: 0.7993\n",
      "Epoch 463/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5938 - acc: 0.8277 - val_loss: 0.7202 - val_acc: 0.8013\n",
      "Epoch 464/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5937 - acc: 0.8280 - val_loss: 0.7216 - val_acc: 0.8008\n",
      "Epoch 465/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5939 - acc: 0.8274 - val_loss: 0.7209 - val_acc: 0.8016\n",
      "Epoch 466/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5932 - acc: 0.8283 - val_loss: 0.7210 - val_acc: 0.7993\n",
      "Epoch 467/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5937 - acc: 0.8283 - val_loss: 0.7195 - val_acc: 0.8014\n",
      "Epoch 468/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5937 - acc: 0.8282 - val_loss: 0.7203 - val_acc: 0.8014\n",
      "Epoch 469/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5936 - acc: 0.8275 - val_loss: 0.7215 - val_acc: 0.7996\n",
      "Epoch 470/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5932 - acc: 0.8280 - val_loss: 0.7213 - val_acc: 0.7999\n",
      "Epoch 471/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5930 - acc: 0.8279 - val_loss: 0.7224 - val_acc: 0.7997\n",
      "Epoch 472/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5928 - acc: 0.8277 - val_loss: 0.7191 - val_acc: 0.8012\n",
      "Epoch 473/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5923 - acc: 0.8281 - val_loss: 0.7190 - val_acc: 0.8001\n",
      "Epoch 474/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5924 - acc: 0.8274 - val_loss: 0.7197 - val_acc: 0.8007\n",
      "Epoch 475/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5920 - acc: 0.8288 - val_loss: 0.7200 - val_acc: 0.8012\n",
      "Epoch 476/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5923 - acc: 0.8279 - val_loss: 0.7199 - val_acc: 0.8007\n",
      "Epoch 477/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5927 - acc: 0.8281 - val_loss: 0.7222 - val_acc: 0.8010\n",
      "Epoch 478/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5922 - acc: 0.8276 - val_loss: 0.7197 - val_acc: 0.8014\n",
      "Epoch 479/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5931 - acc: 0.8276 - val_loss: 0.7202 - val_acc: 0.8018\n",
      "Epoch 480/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5917 - acc: 0.8289 - val_loss: 0.7205 - val_acc: 0.8012\n",
      "Epoch 481/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5921 - acc: 0.8281 - val_loss: 0.7208 - val_acc: 0.8006\n",
      "Epoch 482/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5923 - acc: 0.8284 - val_loss: 0.7227 - val_acc: 0.8007\n",
      "Epoch 483/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5920 - acc: 0.8272 - val_loss: 0.7193 - val_acc: 0.8015\n",
      "Epoch 484/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5911 - acc: 0.8288 - val_loss: 0.7196 - val_acc: 0.8001\n",
      "Epoch 485/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5915 - acc: 0.8285 - val_loss: 0.7197 - val_acc: 0.8021\n",
      "Epoch 486/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5914 - acc: 0.8283 - val_loss: 0.7198 - val_acc: 0.8009\n",
      "Epoch 487/2000\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 0.5906 - acc: 0.8289 - val_loss: 0.7196 - val_acc: 0.8013\n",
      "Epoch 488/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5905 - acc: 0.8279 - val_loss: 0.7206 - val_acc: 0.8008\n",
      "Epoch 489/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5910 - acc: 0.8283 - val_loss: 0.7202 - val_acc: 0.8026\n",
      "Epoch 490/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5908 - acc: 0.8276 - val_loss: 0.7192 - val_acc: 0.8005\n",
      "Epoch 491/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5904 - acc: 0.8281 - val_loss: 0.7205 - val_acc: 0.8008\n",
      "Epoch 492/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5904 - acc: 0.8286 - val_loss: 0.7212 - val_acc: 0.8009\n",
      "Epoch 493/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5902 - acc: 0.8290 - val_loss: 0.7214 - val_acc: 0.7997\n",
      "Epoch 494/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5913 - acc: 0.8277 - val_loss: 0.7206 - val_acc: 0.7999\n",
      "Epoch 495/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5903 - acc: 0.8288 - val_loss: 0.7192 - val_acc: 0.8009\n",
      "Epoch 496/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5902 - acc: 0.8281 - val_loss: 0.7206 - val_acc: 0.8013\n",
      "Epoch 497/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5903 - acc: 0.8280 - val_loss: 0.7189 - val_acc: 0.8015\n",
      "Epoch 498/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5898 - acc: 0.8290 - val_loss: 0.7215 - val_acc: 0.8000\n",
      "Epoch 499/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5894 - acc: 0.8287 - val_loss: 0.7200 - val_acc: 0.7999\n",
      "Epoch 500/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5897 - acc: 0.8295 - val_loss: 0.7191 - val_acc: 0.8019\n",
      "Epoch 501/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5899 - acc: 0.8290 - val_loss: 0.7188 - val_acc: 0.8007\n",
      "Epoch 502/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5897 - acc: 0.8289 - val_loss: 0.7188 - val_acc: 0.8014\n",
      "Epoch 503/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5897 - acc: 0.8287 - val_loss: 0.7180 - val_acc: 0.8009\n",
      "Epoch 504/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5887 - acc: 0.8280 - val_loss: 0.7189 - val_acc: 0.8012\n",
      "Epoch 505/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5894 - acc: 0.8289 - val_loss: 0.7189 - val_acc: 0.8007\n",
      "Epoch 506/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5887 - acc: 0.8300 - val_loss: 0.7185 - val_acc: 0.8008\n",
      "Epoch 507/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5888 - acc: 0.8284 - val_loss: 0.7182 - val_acc: 0.8016\n",
      "Epoch 508/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5884 - acc: 0.8290 - val_loss: 0.7211 - val_acc: 0.8000\n",
      "Epoch 509/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5892 - acc: 0.8290 - val_loss: 0.7180 - val_acc: 0.8019\n",
      "Epoch 510/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5887 - acc: 0.8284 - val_loss: 0.7188 - val_acc: 0.8013\n",
      "Epoch 511/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5880 - acc: 0.8290 - val_loss: 0.7170 - val_acc: 0.8015\n",
      "Epoch 512/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5879 - acc: 0.8291 - val_loss: 0.7182 - val_acc: 0.8014\n",
      "Epoch 513/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5885 - acc: 0.8294 - val_loss: 0.7187 - val_acc: 0.8008\n",
      "Epoch 514/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5875 - acc: 0.8289 - val_loss: 0.7178 - val_acc: 0.8014\n",
      "Epoch 515/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5878 - acc: 0.8292 - val_loss: 0.7201 - val_acc: 0.8011\n",
      "Epoch 516/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5879 - acc: 0.8292 - val_loss: 0.7203 - val_acc: 0.8002\n",
      "Epoch 517/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5876 - acc: 0.8296 - val_loss: 0.7206 - val_acc: 0.8006\n",
      "Epoch 518/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5871 - acc: 0.8290 - val_loss: 0.7183 - val_acc: 0.8013\n",
      "Epoch 519/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5875 - acc: 0.8295 - val_loss: 0.7181 - val_acc: 0.8026\n",
      "Epoch 520/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5879 - acc: 0.8290 - val_loss: 0.7180 - val_acc: 0.8018\n",
      "Epoch 521/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5869 - acc: 0.8302 - val_loss: 0.7188 - val_acc: 0.8019\n",
      "Epoch 522/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5875 - acc: 0.8290 - val_loss: 0.7175 - val_acc: 0.8013\n",
      "Epoch 523/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5876 - acc: 0.8297 - val_loss: 0.7199 - val_acc: 0.8024\n",
      "Epoch 524/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5863 - acc: 0.8299 - val_loss: 0.7187 - val_acc: 0.8012\n",
      "Epoch 525/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5873 - acc: 0.8296 - val_loss: 0.7177 - val_acc: 0.8011\n",
      "Epoch 526/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5864 - acc: 0.8300 - val_loss: 0.7175 - val_acc: 0.8016\n",
      "Epoch 527/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5865 - acc: 0.8294 - val_loss: 0.7179 - val_acc: 0.8019\n",
      "Epoch 528/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5864 - acc: 0.8298 - val_loss: 0.7166 - val_acc: 0.8024\n",
      "Epoch 529/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5867 - acc: 0.8288 - val_loss: 0.7169 - val_acc: 0.8019\n",
      "Epoch 530/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5860 - acc: 0.8295 - val_loss: 0.7194 - val_acc: 0.8027\n",
      "Epoch 531/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5863 - acc: 0.8299 - val_loss: 0.7183 - val_acc: 0.8013\n",
      "Epoch 532/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5860 - acc: 0.8295 - val_loss: 0.7173 - val_acc: 0.8013\n",
      "Epoch 533/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5863 - acc: 0.8299 - val_loss: 0.7171 - val_acc: 0.8021\n",
      "Epoch 534/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5856 - acc: 0.8302 - val_loss: 0.7176 - val_acc: 0.8017\n",
      "Epoch 535/2000\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.5853 - acc: 0.8298 - val_loss: 0.7164 - val_acc: 0.8026\n",
      "Epoch 536/2000\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.5856 - acc: 0.8300 - val_loss: 0.7185 - val_acc: 0.8010\n",
      "Epoch 537/2000\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.5859 - acc: 0.8300 - val_loss: 0.7176 - val_acc: 0.8029\n",
      "Epoch 538/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5854 - acc: 0.8306 - val_loss: 0.7169 - val_acc: 0.8023\n",
      "Epoch 539/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5855 - acc: 0.8301 - val_loss: 0.7165 - val_acc: 0.8025\n",
      "Epoch 540/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5850 - acc: 0.8301 - val_loss: 0.7176 - val_acc: 0.8014\n",
      "Epoch 541/2000\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.5854 - acc: 0.8307 - val_loss: 0.7166 - val_acc: 0.8022\n",
      "Epoch 542/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5847 - acc: 0.8297 - val_loss: 0.7181 - val_acc: 0.8029\n",
      "Epoch 543/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5847 - acc: 0.8301 - val_loss: 0.7160 - val_acc: 0.8028\n",
      "Epoch 544/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5855 - acc: 0.8303 - val_loss: 0.7166 - val_acc: 0.8013\n",
      "Epoch 545/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5846 - acc: 0.8302 - val_loss: 0.7158 - val_acc: 0.8030\n",
      "Epoch 546/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5844 - acc: 0.8306 - val_loss: 0.7156 - val_acc: 0.8028\n",
      "Epoch 547/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5841 - acc: 0.8299 - val_loss: 0.7157 - val_acc: 0.8032\n",
      "Epoch 548/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5846 - acc: 0.8296 - val_loss: 0.7169 - val_acc: 0.8013\n",
      "Epoch 549/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5845 - acc: 0.8302 - val_loss: 0.7165 - val_acc: 0.8029\n",
      "Epoch 550/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5844 - acc: 0.8306 - val_loss: 0.7163 - val_acc: 0.8026\n",
      "Epoch 551/2000\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.5839 - acc: 0.8303 - val_loss: 0.7165 - val_acc: 0.8033\n",
      "Epoch 552/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5842 - acc: 0.8303 - val_loss: 0.7165 - val_acc: 0.8025\n",
      "Epoch 553/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5844 - acc: 0.8303 - val_loss: 0.7155 - val_acc: 0.8028\n",
      "Epoch 554/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5843 - acc: 0.8294 - val_loss: 0.7147 - val_acc: 0.8037\n",
      "Epoch 555/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5840 - acc: 0.8297 - val_loss: 0.7157 - val_acc: 0.8019\n",
      "Epoch 556/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5840 - acc: 0.8300 - val_loss: 0.7160 - val_acc: 0.8019\n",
      "Epoch 557/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5837 - acc: 0.8305 - val_loss: 0.7154 - val_acc: 0.8024\n",
      "Epoch 558/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5839 - acc: 0.8294 - val_loss: 0.7154 - val_acc: 0.8031\n",
      "Epoch 559/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5835 - acc: 0.8297 - val_loss: 0.7179 - val_acc: 0.8028\n",
      "Epoch 560/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5830 - acc: 0.8303 - val_loss: 0.7155 - val_acc: 0.8034\n",
      "Epoch 561/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5833 - acc: 0.8302 - val_loss: 0.7153 - val_acc: 0.8023\n",
      "Epoch 562/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5832 - acc: 0.8308 - val_loss: 0.7163 - val_acc: 0.8019\n",
      "Epoch 563/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5832 - acc: 0.8312 - val_loss: 0.7159 - val_acc: 0.8046\n",
      "Epoch 564/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5833 - acc: 0.8307 - val_loss: 0.7149 - val_acc: 0.8032\n",
      "Epoch 565/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5824 - acc: 0.8304 - val_loss: 0.7150 - val_acc: 0.8031\n",
      "Epoch 566/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5824 - acc: 0.8320 - val_loss: 0.7205 - val_acc: 0.8011\n",
      "Epoch 567/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5824 - acc: 0.8311 - val_loss: 0.7152 - val_acc: 0.8026\n",
      "Epoch 568/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5821 - acc: 0.8310 - val_loss: 0.7147 - val_acc: 0.8032\n",
      "Epoch 569/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5827 - acc: 0.8315 - val_loss: 0.7146 - val_acc: 0.8035\n",
      "Epoch 570/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5824 - acc: 0.8305 - val_loss: 0.7147 - val_acc: 0.8031\n",
      "Epoch 571/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5819 - acc: 0.8298 - val_loss: 0.7146 - val_acc: 0.8034\n",
      "Epoch 572/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5822 - acc: 0.8307 - val_loss: 0.7147 - val_acc: 0.8043\n",
      "Epoch 573/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5816 - acc: 0.8299 - val_loss: 0.7164 - val_acc: 0.8018\n",
      "Epoch 574/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5821 - acc: 0.8310 - val_loss: 0.7179 - val_acc: 0.8004\n",
      "Epoch 575/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5823 - acc: 0.8307 - val_loss: 0.7173 - val_acc: 0.8026\n",
      "Epoch 576/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5818 - acc: 0.8305 - val_loss: 0.7168 - val_acc: 0.8027\n",
      "Epoch 577/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5818 - acc: 0.8304 - val_loss: 0.7143 - val_acc: 0.8041\n",
      "Epoch 578/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5816 - acc: 0.8311 - val_loss: 0.7149 - val_acc: 0.8028\n",
      "Epoch 579/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5819 - acc: 0.8303 - val_loss: 0.7170 - val_acc: 0.8013\n",
      "Epoch 580/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5812 - acc: 0.8309 - val_loss: 0.7149 - val_acc: 0.8023\n",
      "Epoch 581/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5818 - acc: 0.8304 - val_loss: 0.7150 - val_acc: 0.8035\n",
      "Epoch 582/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5810 - acc: 0.8315 - val_loss: 0.7147 - val_acc: 0.8038\n",
      "Epoch 583/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5805 - acc: 0.8309 - val_loss: 0.7162 - val_acc: 0.8027\n",
      "Epoch 584/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5809 - acc: 0.8315 - val_loss: 0.7156 - val_acc: 0.8019\n",
      "Epoch 585/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5812 - acc: 0.8318 - val_loss: 0.7143 - val_acc: 0.8039\n",
      "Epoch 586/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5802 - acc: 0.8312 - val_loss: 0.7162 - val_acc: 0.8018\n",
      "Epoch 587/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5807 - acc: 0.8303 - val_loss: 0.7159 - val_acc: 0.8027\n",
      "Epoch 588/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5801 - acc: 0.8316 - val_loss: 0.7161 - val_acc: 0.8028\n",
      "Epoch 589/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5808 - acc: 0.8307 - val_loss: 0.7153 - val_acc: 0.8033\n",
      "Epoch 590/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5800 - acc: 0.8307 - val_loss: 0.7153 - val_acc: 0.8031\n",
      "Epoch 591/2000\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.5798 - acc: 0.8312 - val_loss: 0.7141 - val_acc: 0.8041\n",
      "Epoch 592/2000\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.5803 - acc: 0.8313 - val_loss: 0.7144 - val_acc: 0.8034\n",
      "Epoch 593/2000\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.5801 - acc: 0.8321 - val_loss: 0.7153 - val_acc: 0.8028\n",
      "Epoch 594/2000\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.5801 - acc: 0.8306 - val_loss: 0.7126 - val_acc: 0.8039\n",
      "Epoch 595/2000\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.5797 - acc: 0.8313 - val_loss: 0.7152 - val_acc: 0.8036\n",
      "Epoch 596/2000\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.5800 - acc: 0.8315 - val_loss: 0.7148 - val_acc: 0.8024\n",
      "Epoch 597/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5800 - acc: 0.8319 - val_loss: 0.7133 - val_acc: 0.8038\n",
      "Epoch 598/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5797 - acc: 0.8316 - val_loss: 0.7138 - val_acc: 0.8042\n",
      "Epoch 599/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5798 - acc: 0.8310 - val_loss: 0.7150 - val_acc: 0.8028\n",
      "Epoch 600/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5794 - acc: 0.8318 - val_loss: 0.7147 - val_acc: 0.8043\n",
      "Epoch 601/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5798 - acc: 0.8312 - val_loss: 0.7142 - val_acc: 0.8042\n",
      "Epoch 602/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5792 - acc: 0.8317 - val_loss: 0.7136 - val_acc: 0.8038\n",
      "Epoch 603/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5794 - acc: 0.8318 - val_loss: 0.7134 - val_acc: 0.8049\n",
      "Epoch 604/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5792 - acc: 0.8316 - val_loss: 0.7138 - val_acc: 0.8036\n",
      "Epoch 605/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5800 - acc: 0.8317 - val_loss: 0.7143 - val_acc: 0.8041\n",
      "Epoch 606/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5790 - acc: 0.8320 - val_loss: 0.7136 - val_acc: 0.8039\n",
      "Epoch 607/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5787 - acc: 0.8323 - val_loss: 0.7129 - val_acc: 0.8038\n",
      "Epoch 608/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5786 - acc: 0.8322 - val_loss: 0.7125 - val_acc: 0.8046\n",
      "Epoch 609/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5783 - acc: 0.8321 - val_loss: 0.7136 - val_acc: 0.8039\n",
      "Epoch 610/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5784 - acc: 0.8315 - val_loss: 0.7137 - val_acc: 0.8038\n",
      "Epoch 611/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5785 - acc: 0.8319 - val_loss: 0.7134 - val_acc: 0.8051\n",
      "Epoch 612/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5789 - acc: 0.8314 - val_loss: 0.7143 - val_acc: 0.8042\n",
      "Epoch 613/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5786 - acc: 0.8317 - val_loss: 0.7143 - val_acc: 0.8036\n",
      "Epoch 614/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5785 - acc: 0.8325 - val_loss: 0.7139 - val_acc: 0.8036\n",
      "Epoch 615/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5785 - acc: 0.8315 - val_loss: 0.7126 - val_acc: 0.8047\n",
      "Epoch 616/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5783 - acc: 0.8314 - val_loss: 0.7160 - val_acc: 0.8024\n",
      "Epoch 617/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5784 - acc: 0.8313 - val_loss: 0.7145 - val_acc: 0.8025\n",
      "Epoch 618/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5780 - acc: 0.8323 - val_loss: 0.7162 - val_acc: 0.8023\n",
      "Epoch 619/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5780 - acc: 0.8322 - val_loss: 0.7139 - val_acc: 0.8024\n",
      "Epoch 620/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5778 - acc: 0.8313 - val_loss: 0.7148 - val_acc: 0.8024\n",
      "Epoch 621/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5778 - acc: 0.8320 - val_loss: 0.7132 - val_acc: 0.8039\n",
      "Epoch 622/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5777 - acc: 0.8323 - val_loss: 0.7145 - val_acc: 0.8034\n",
      "Epoch 623/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5780 - acc: 0.8311 - val_loss: 0.7151 - val_acc: 0.8034\n",
      "Epoch 624/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5776 - acc: 0.8324 - val_loss: 0.7129 - val_acc: 0.8038\n",
      "Epoch 625/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5775 - acc: 0.8310 - val_loss: 0.7157 - val_acc: 0.8022\n",
      "Epoch 626/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5778 - acc: 0.8313 - val_loss: 0.7130 - val_acc: 0.8038\n",
      "Epoch 627/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5774 - acc: 0.8320 - val_loss: 0.7137 - val_acc: 0.8037\n",
      "Epoch 628/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5771 - acc: 0.8328 - val_loss: 0.7141 - val_acc: 0.8031\n",
      "Epoch 629/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5767 - acc: 0.8328 - val_loss: 0.7151 - val_acc: 0.8024\n",
      "Epoch 630/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5768 - acc: 0.8328 - val_loss: 0.7123 - val_acc: 0.8038\n",
      "Epoch 631/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5774 - acc: 0.8319 - val_loss: 0.7143 - val_acc: 0.8027\n",
      "Epoch 632/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5769 - acc: 0.8324 - val_loss: 0.7126 - val_acc: 0.8033\n",
      "Epoch 633/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5767 - acc: 0.8321 - val_loss: 0.7125 - val_acc: 0.8038\n",
      "Epoch 634/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5764 - acc: 0.8322 - val_loss: 0.7128 - val_acc: 0.8048\n",
      "Epoch 635/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5765 - acc: 0.8323 - val_loss: 0.7147 - val_acc: 0.8031\n",
      "Epoch 636/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5770 - acc: 0.8318 - val_loss: 0.7127 - val_acc: 0.8058\n",
      "Epoch 637/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5767 - acc: 0.8324 - val_loss: 0.7136 - val_acc: 0.8055\n",
      "Epoch 638/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5762 - acc: 0.8325 - val_loss: 0.7153 - val_acc: 0.8026\n",
      "Epoch 639/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5757 - acc: 0.8327 - val_loss: 0.7125 - val_acc: 0.8040\n",
      "Epoch 640/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5760 - acc: 0.8324 - val_loss: 0.7133 - val_acc: 0.8041\n",
      "Epoch 641/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5760 - acc: 0.8331 - val_loss: 0.7120 - val_acc: 0.8034\n",
      "Epoch 642/2000\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 0.5763 - acc: 0.8324 - val_loss: 0.7129 - val_acc: 0.8031\n",
      "Epoch 643/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5762 - acc: 0.8325 - val_loss: 0.7132 - val_acc: 0.8036\n",
      "Epoch 644/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5759 - acc: 0.8331 - val_loss: 0.7116 - val_acc: 0.8041\n",
      "Epoch 645/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5754 - acc: 0.8323 - val_loss: 0.7139 - val_acc: 0.8031\n",
      "Epoch 646/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5758 - acc: 0.8331 - val_loss: 0.7123 - val_acc: 0.8032\n",
      "Epoch 647/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5754 - acc: 0.8329 - val_loss: 0.7120 - val_acc: 0.8046\n",
      "Epoch 648/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5755 - acc: 0.8326 - val_loss: 0.7130 - val_acc: 0.8041\n",
      "Epoch 649/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5761 - acc: 0.8325 - val_loss: 0.7136 - val_acc: 0.8045\n",
      "Epoch 650/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5755 - acc: 0.8323 - val_loss: 0.7116 - val_acc: 0.8042\n",
      "Epoch 651/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5756 - acc: 0.8322 - val_loss: 0.7121 - val_acc: 0.8039\n",
      "Epoch 652/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5750 - acc: 0.8330 - val_loss: 0.7127 - val_acc: 0.8043\n",
      "Epoch 653/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5748 - acc: 0.8327 - val_loss: 0.7124 - val_acc: 0.8052\n",
      "Epoch 654/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5749 - acc: 0.8325 - val_loss: 0.7120 - val_acc: 0.8047\n",
      "Epoch 655/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5747 - acc: 0.8328 - val_loss: 0.7137 - val_acc: 0.8043\n",
      "Epoch 656/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5746 - acc: 0.8330 - val_loss: 0.7127 - val_acc: 0.8027\n",
      "Epoch 657/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5750 - acc: 0.8331 - val_loss: 0.7132 - val_acc: 0.8033\n",
      "Epoch 658/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5746 - acc: 0.8323 - val_loss: 0.7117 - val_acc: 0.8036\n",
      "Epoch 659/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5748 - acc: 0.8330 - val_loss: 0.7110 - val_acc: 0.8051\n",
      "Epoch 660/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5744 - acc: 0.8326 - val_loss: 0.7111 - val_acc: 0.8055\n",
      "Epoch 661/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5744 - acc: 0.8327 - val_loss: 0.7118 - val_acc: 0.8041\n",
      "Epoch 662/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5745 - acc: 0.8330 - val_loss: 0.7121 - val_acc: 0.8036\n",
      "Epoch 663/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5746 - acc: 0.8332 - val_loss: 0.7128 - val_acc: 0.8036\n",
      "Epoch 664/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5742 - acc: 0.8334 - val_loss: 0.7120 - val_acc: 0.8050\n",
      "Epoch 665/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5738 - acc: 0.8325 - val_loss: 0.7123 - val_acc: 0.8045\n",
      "Epoch 666/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5744 - acc: 0.8335 - val_loss: 0.7131 - val_acc: 0.8051\n",
      "Epoch 667/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5740 - acc: 0.8329 - val_loss: 0.7127 - val_acc: 0.8039\n",
      "Epoch 668/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5742 - acc: 0.8329 - val_loss: 0.7127 - val_acc: 0.8032\n",
      "Epoch 669/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5738 - acc: 0.8323 - val_loss: 0.7125 - val_acc: 0.8041\n",
      "Epoch 670/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5735 - acc: 0.8330 - val_loss: 0.7137 - val_acc: 0.8039\n",
      "Epoch 671/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5738 - acc: 0.8331 - val_loss: 0.7120 - val_acc: 0.8059\n",
      "Epoch 672/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5737 - acc: 0.8328 - val_loss: 0.7117 - val_acc: 0.8043\n",
      "Epoch 673/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5734 - acc: 0.8329 - val_loss: 0.7110 - val_acc: 0.8053\n",
      "Epoch 674/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5735 - acc: 0.8341 - val_loss: 0.7122 - val_acc: 0.8053\n",
      "Epoch 675/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5738 - acc: 0.8334 - val_loss: 0.7123 - val_acc: 0.8049\n",
      "Epoch 676/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5733 - acc: 0.8329 - val_loss: 0.7127 - val_acc: 0.8040\n",
      "Epoch 677/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5732 - acc: 0.8329 - val_loss: 0.7114 - val_acc: 0.8047\n",
      "Epoch 678/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5735 - acc: 0.8337 - val_loss: 0.7118 - val_acc: 0.8058\n",
      "Epoch 679/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5738 - acc: 0.8333 - val_loss: 0.7117 - val_acc: 0.8046\n",
      "Epoch 680/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5733 - acc: 0.8339 - val_loss: 0.7117 - val_acc: 0.8036\n",
      "Epoch 681/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5732 - acc: 0.8325 - val_loss: 0.7132 - val_acc: 0.8045\n",
      "Epoch 682/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5734 - acc: 0.8332 - val_loss: 0.7105 - val_acc: 0.8048\n",
      "Epoch 683/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5734 - acc: 0.8335 - val_loss: 0.7125 - val_acc: 0.8031\n",
      "Epoch 684/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5727 - acc: 0.8327 - val_loss: 0.7106 - val_acc: 0.8043\n",
      "Epoch 685/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5724 - acc: 0.8337 - val_loss: 0.7110 - val_acc: 0.8051\n",
      "Epoch 686/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5727 - acc: 0.8333 - val_loss: 0.7130 - val_acc: 0.8041\n",
      "Epoch 687/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5728 - acc: 0.8333 - val_loss: 0.7104 - val_acc: 0.8055\n",
      "Epoch 688/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5723 - acc: 0.8333 - val_loss: 0.7123 - val_acc: 0.8044\n",
      "Epoch 689/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5728 - acc: 0.8331 - val_loss: 0.7114 - val_acc: 0.8044\n",
      "Epoch 690/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5726 - acc: 0.8332 - val_loss: 0.7138 - val_acc: 0.8027\n",
      "Epoch 691/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5727 - acc: 0.8328 - val_loss: 0.7110 - val_acc: 0.8045\n",
      "Epoch 692/2000\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 0.5722 - acc: 0.8332 - val_loss: 0.7120 - val_acc: 0.8049\n",
      "Epoch 693/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5729 - acc: 0.8338 - val_loss: 0.7112 - val_acc: 0.8057\n",
      "Epoch 694/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5717 - acc: 0.8335 - val_loss: 0.7114 - val_acc: 0.8042\n",
      "Epoch 695/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5718 - acc: 0.8340 - val_loss: 0.7116 - val_acc: 0.8034\n",
      "Epoch 696/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5719 - acc: 0.8344 - val_loss: 0.7104 - val_acc: 0.8058\n",
      "Epoch 697/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5717 - acc: 0.8336 - val_loss: 0.7110 - val_acc: 0.8036\n",
      "Epoch 698/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5714 - acc: 0.8338 - val_loss: 0.7125 - val_acc: 0.8047\n",
      "Epoch 699/2000\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 0.5719 - acc: 0.8330 - val_loss: 0.7107 - val_acc: 0.8049\n",
      "Epoch 700/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5712 - acc: 0.8335 - val_loss: 0.7117 - val_acc: 0.8042\n",
      "Epoch 701/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5717 - acc: 0.8335 - val_loss: 0.7097 - val_acc: 0.8058\n",
      "Epoch 702/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5718 - acc: 0.8333 - val_loss: 0.7109 - val_acc: 0.8044\n",
      "Epoch 703/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5715 - acc: 0.8343 - val_loss: 0.7103 - val_acc: 0.8051\n",
      "Epoch 704/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5713 - acc: 0.8334 - val_loss: 0.7119 - val_acc: 0.8034\n",
      "Epoch 705/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5716 - acc: 0.8331 - val_loss: 0.7100 - val_acc: 0.8057\n",
      "Epoch 706/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5714 - acc: 0.8338 - val_loss: 0.7108 - val_acc: 0.8051\n",
      "Epoch 707/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5712 - acc: 0.8345 - val_loss: 0.7101 - val_acc: 0.8059\n",
      "Epoch 708/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5711 - acc: 0.8336 - val_loss: 0.7103 - val_acc: 0.8051\n",
      "Epoch 709/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5711 - acc: 0.8341 - val_loss: 0.7108 - val_acc: 0.8044\n",
      "Epoch 710/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5708 - acc: 0.8336 - val_loss: 0.7108 - val_acc: 0.8047\n",
      "Epoch 711/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5710 - acc: 0.8347 - val_loss: 0.7112 - val_acc: 0.8047\n",
      "Epoch 712/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5710 - acc: 0.8340 - val_loss: 0.7093 - val_acc: 0.8063\n",
      "Epoch 713/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5711 - acc: 0.8342 - val_loss: 0.7094 - val_acc: 0.8052\n",
      "Epoch 714/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5709 - acc: 0.8341 - val_loss: 0.7122 - val_acc: 0.8043\n",
      "Epoch 715/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5711 - acc: 0.8340 - val_loss: 0.7105 - val_acc: 0.8055\n",
      "Epoch 716/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5701 - acc: 0.8340 - val_loss: 0.7107 - val_acc: 0.8047\n",
      "Epoch 717/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5708 - acc: 0.8344 - val_loss: 0.7105 - val_acc: 0.8057\n",
      "Epoch 718/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5708 - acc: 0.8343 - val_loss: 0.7108 - val_acc: 0.8047\n",
      "Epoch 719/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5704 - acc: 0.8346 - val_loss: 0.7110 - val_acc: 0.8058\n",
      "Epoch 720/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5700 - acc: 0.8338 - val_loss: 0.7102 - val_acc: 0.8057\n",
      "Epoch 721/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5701 - acc: 0.8344 - val_loss: 0.7099 - val_acc: 0.8053\n",
      "Epoch 722/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5700 - acc: 0.8350 - val_loss: 0.7108 - val_acc: 0.8043\n",
      "Epoch 723/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5700 - acc: 0.8342 - val_loss: 0.7098 - val_acc: 0.8046\n",
      "Epoch 724/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5702 - acc: 0.8345 - val_loss: 0.7105 - val_acc: 0.8053\n",
      "Epoch 725/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5698 - acc: 0.8335 - val_loss: 0.7117 - val_acc: 0.8041\n",
      "Epoch 726/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5703 - acc: 0.8336 - val_loss: 0.7097 - val_acc: 0.8064\n",
      "Epoch 727/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5697 - acc: 0.8349 - val_loss: 0.7097 - val_acc: 0.8059\n",
      "Epoch 728/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5699 - acc: 0.8337 - val_loss: 0.7113 - val_acc: 0.8059\n",
      "Epoch 729/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5696 - acc: 0.8347 - val_loss: 0.7097 - val_acc: 0.8053\n",
      "Epoch 730/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5695 - acc: 0.8341 - val_loss: 0.7105 - val_acc: 0.8037\n",
      "Epoch 731/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5698 - acc: 0.8343 - val_loss: 0.7096 - val_acc: 0.8046\n",
      "Epoch 732/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5692 - acc: 0.8338 - val_loss: 0.7100 - val_acc: 0.8049\n",
      "Epoch 733/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5697 - acc: 0.8335 - val_loss: 0.7098 - val_acc: 0.8053\n",
      "Epoch 734/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5691 - acc: 0.8342 - val_loss: 0.7102 - val_acc: 0.8050\n",
      "Epoch 735/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5694 - acc: 0.8339 - val_loss: 0.7101 - val_acc: 0.8062\n",
      "Epoch 736/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5689 - acc: 0.8345 - val_loss: 0.7104 - val_acc: 0.8048\n",
      "Epoch 737/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5690 - acc: 0.8334 - val_loss: 0.7099 - val_acc: 0.8049\n",
      "Epoch 738/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5689 - acc: 0.8350 - val_loss: 0.7113 - val_acc: 0.8047\n",
      "Epoch 739/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5688 - acc: 0.8348 - val_loss: 0.7106 - val_acc: 0.8053\n",
      "Epoch 740/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5694 - acc: 0.8346 - val_loss: 0.7101 - val_acc: 0.8050\n",
      "Epoch 741/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5687 - acc: 0.8343 - val_loss: 0.7092 - val_acc: 0.8050\n",
      "Epoch 742/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5688 - acc: 0.8341 - val_loss: 0.7083 - val_acc: 0.8070\n",
      "Epoch 743/2000\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 0.5689 - acc: 0.8334 - val_loss: 0.7104 - val_acc: 0.8052\n",
      "Epoch 744/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5684 - acc: 0.8350 - val_loss: 0.7093 - val_acc: 0.8057\n",
      "Epoch 745/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5683 - acc: 0.8357 - val_loss: 0.7104 - val_acc: 0.8046\n",
      "Epoch 746/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5691 - acc: 0.8335 - val_loss: 0.7108 - val_acc: 0.8052\n",
      "Epoch 747/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5689 - acc: 0.8348 - val_loss: 0.7090 - val_acc: 0.8053\n",
      "Epoch 748/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5681 - acc: 0.8356 - val_loss: 0.7093 - val_acc: 0.8057\n",
      "Epoch 749/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5684 - acc: 0.8349 - val_loss: 0.7092 - val_acc: 0.8056\n",
      "Epoch 750/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5679 - acc: 0.8352 - val_loss: 0.7105 - val_acc: 0.8050\n",
      "Epoch 751/2000\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 0.5682 - acc: 0.8353 - val_loss: 0.7102 - val_acc: 0.8053\n",
      "Epoch 752/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5678 - acc: 0.8346 - val_loss: 0.7090 - val_acc: 0.8064\n",
      "Epoch 753/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5678 - acc: 0.8349 - val_loss: 0.7110 - val_acc: 0.8045\n",
      "Epoch 754/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5679 - acc: 0.8350 - val_loss: 0.7097 - val_acc: 0.8061\n",
      "Epoch 755/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5676 - acc: 0.8346 - val_loss: 0.7094 - val_acc: 0.8055\n",
      "Epoch 756/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5681 - acc: 0.8349 - val_loss: 0.7096 - val_acc: 0.8052\n",
      "Epoch 757/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5679 - acc: 0.8345 - val_loss: 0.7111 - val_acc: 0.8044\n",
      "Epoch 758/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5684 - acc: 0.8347 - val_loss: 0.7091 - val_acc: 0.8057\n",
      "Epoch 759/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5676 - acc: 0.8350 - val_loss: 0.7103 - val_acc: 0.8054\n",
      "Epoch 760/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5676 - acc: 0.8345 - val_loss: 0.7091 - val_acc: 0.8041\n",
      "Epoch 761/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5680 - acc: 0.8350 - val_loss: 0.7087 - val_acc: 0.8042\n",
      "Epoch 762/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5674 - acc: 0.8345 - val_loss: 0.7083 - val_acc: 0.8049\n",
      "Epoch 763/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5676 - acc: 0.8345 - val_loss: 0.7081 - val_acc: 0.8066\n",
      "Epoch 764/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5679 - acc: 0.8348 - val_loss: 0.7076 - val_acc: 0.8066\n",
      "Epoch 765/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5672 - acc: 0.8350 - val_loss: 0.7093 - val_acc: 0.8049\n",
      "Epoch 766/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5676 - acc: 0.8357 - val_loss: 0.7083 - val_acc: 0.8069\n",
      "Epoch 767/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5675 - acc: 0.8345 - val_loss: 0.7106 - val_acc: 0.8051\n",
      "Epoch 768/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5673 - acc: 0.8346 - val_loss: 0.7097 - val_acc: 0.8056\n",
      "Epoch 769/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5671 - acc: 0.8357 - val_loss: 0.7087 - val_acc: 0.8064\n",
      "Epoch 770/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5665 - acc: 0.8359 - val_loss: 0.7090 - val_acc: 0.8059\n",
      "Epoch 771/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5671 - acc: 0.8356 - val_loss: 0.7090 - val_acc: 0.8055\n",
      "Epoch 772/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5669 - acc: 0.8354 - val_loss: 0.7091 - val_acc: 0.8059\n",
      "Epoch 773/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5668 - acc: 0.8355 - val_loss: 0.7092 - val_acc: 0.8060\n",
      "Epoch 774/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5669 - acc: 0.8353 - val_loss: 0.7100 - val_acc: 0.8064\n",
      "Epoch 775/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5667 - acc: 0.8355 - val_loss: 0.7084 - val_acc: 0.8062\n",
      "Epoch 776/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5667 - acc: 0.8353 - val_loss: 0.7080 - val_acc: 0.8062\n",
      "Epoch 777/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5661 - acc: 0.8356 - val_loss: 0.7117 - val_acc: 0.8030\n",
      "Epoch 778/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5662 - acc: 0.8362 - val_loss: 0.7085 - val_acc: 0.8068\n",
      "Epoch 779/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5662 - acc: 0.8352 - val_loss: 0.7089 - val_acc: 0.8049\n",
      "Epoch 780/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5668 - acc: 0.8360 - val_loss: 0.7076 - val_acc: 0.8057\n",
      "Epoch 781/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5667 - acc: 0.8352 - val_loss: 0.7086 - val_acc: 0.8051\n",
      "Epoch 782/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5660 - acc: 0.8352 - val_loss: 0.7098 - val_acc: 0.8052\n",
      "Epoch 783/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5659 - acc: 0.8355 - val_loss: 0.7089 - val_acc: 0.8060\n",
      "Epoch 784/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5661 - acc: 0.8355 - val_loss: 0.7095 - val_acc: 0.8059\n",
      "Epoch 785/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5666 - acc: 0.8348 - val_loss: 0.7084 - val_acc: 0.8064\n",
      "Epoch 786/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5659 - acc: 0.8357 - val_loss: 0.7084 - val_acc: 0.8060\n",
      "Epoch 787/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5660 - acc: 0.8361 - val_loss: 0.7077 - val_acc: 0.8075\n",
      "Epoch 788/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5655 - acc: 0.8356 - val_loss: 0.7085 - val_acc: 0.8068\n",
      "Epoch 789/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5663 - acc: 0.8345 - val_loss: 0.7086 - val_acc: 0.8058\n",
      "Epoch 790/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5660 - acc: 0.8359 - val_loss: 0.7095 - val_acc: 0.8061\n",
      "Epoch 791/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5657 - acc: 0.8359 - val_loss: 0.7092 - val_acc: 0.8067\n",
      "Epoch 792/2000\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 0.5657 - acc: 0.8360 - val_loss: 0.7091 - val_acc: 0.8053\n",
      "Epoch 793/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5655 - acc: 0.8358 - val_loss: 0.7081 - val_acc: 0.8056\n",
      "Epoch 794/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5660 - acc: 0.8351 - val_loss: 0.7080 - val_acc: 0.8074\n",
      "Epoch 795/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5651 - acc: 0.8354 - val_loss: 0.7079 - val_acc: 0.8066\n",
      "Epoch 796/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5653 - acc: 0.8353 - val_loss: 0.7097 - val_acc: 0.8061\n",
      "Epoch 797/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5653 - acc: 0.8356 - val_loss: 0.7082 - val_acc: 0.8058\n",
      "Epoch 798/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5654 - acc: 0.8359 - val_loss: 0.7073 - val_acc: 0.8063\n",
      "Epoch 799/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5649 - acc: 0.8358 - val_loss: 0.7093 - val_acc: 0.8056\n",
      "Epoch 800/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5652 - acc: 0.8357 - val_loss: 0.7075 - val_acc: 0.8061\n",
      "Epoch 801/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5654 - acc: 0.8350 - val_loss: 0.7082 - val_acc: 0.8063\n",
      "Epoch 802/2000\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 0.5655 - acc: 0.8359 - val_loss: 0.7075 - val_acc: 0.8065\n",
      "Epoch 803/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5648 - acc: 0.8360 - val_loss: 0.7075 - val_acc: 0.8068\n",
      "Epoch 804/2000\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 0.5647 - acc: 0.8360 - val_loss: 0.7081 - val_acc: 0.8054\n",
      "Epoch 805/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5653 - acc: 0.8358 - val_loss: 0.7076 - val_acc: 0.8056\n",
      "Epoch 806/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5646 - acc: 0.8357 - val_loss: 0.7086 - val_acc: 0.8066\n",
      "Epoch 807/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5648 - acc: 0.8356 - val_loss: 0.7078 - val_acc: 0.8058\n",
      "Epoch 808/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5643 - acc: 0.8368 - val_loss: 0.7089 - val_acc: 0.8057\n",
      "Epoch 809/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5645 - acc: 0.8359 - val_loss: 0.7076 - val_acc: 0.8071\n",
      "Epoch 810/2000\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 0.5650 - acc: 0.8350 - val_loss: 0.7081 - val_acc: 0.8053\n",
      "Epoch 811/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5654 - acc: 0.8352 - val_loss: 0.7071 - val_acc: 0.8060\n",
      "Epoch 812/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5646 - acc: 0.8358 - val_loss: 0.7079 - val_acc: 0.8053\n",
      "Epoch 813/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5642 - acc: 0.8363 - val_loss: 0.7076 - val_acc: 0.8065\n",
      "Epoch 814/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5645 - acc: 0.8363 - val_loss: 0.7103 - val_acc: 0.8053\n",
      "Epoch 815/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5644 - acc: 0.8360 - val_loss: 0.7082 - val_acc: 0.8064\n",
      "Epoch 816/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5642 - acc: 0.8358 - val_loss: 0.7075 - val_acc: 0.8058\n",
      "Epoch 817/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5640 - acc: 0.8355 - val_loss: 0.7081 - val_acc: 0.8052\n",
      "Epoch 818/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5643 - acc: 0.8362 - val_loss: 0.7079 - val_acc: 0.8052\n",
      "Epoch 819/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5638 - acc: 0.8361 - val_loss: 0.7082 - val_acc: 0.8073\n",
      "Epoch 820/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5644 - acc: 0.8363 - val_loss: 0.7074 - val_acc: 0.8073\n",
      "Epoch 821/2000\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 0.5645 - acc: 0.8362 - val_loss: 0.7079 - val_acc: 0.8067\n",
      "Epoch 822/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5641 - acc: 0.8359 - val_loss: 0.7072 - val_acc: 0.8068\n",
      "Epoch 823/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5644 - acc: 0.8353 - val_loss: 0.7069 - val_acc: 0.8072\n",
      "Epoch 824/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5640 - acc: 0.8360 - val_loss: 0.7080 - val_acc: 0.8066\n",
      "Epoch 825/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5640 - acc: 0.8361 - val_loss: 0.7076 - val_acc: 0.8059\n",
      "Epoch 826/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5637 - acc: 0.8364 - val_loss: 0.7083 - val_acc: 0.8048\n",
      "Epoch 827/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5634 - acc: 0.8365 - val_loss: 0.7071 - val_acc: 0.8065\n",
      "Epoch 828/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5641 - acc: 0.8363 - val_loss: 0.7077 - val_acc: 0.8056\n",
      "Epoch 829/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5632 - acc: 0.8363 - val_loss: 0.7083 - val_acc: 0.8058\n",
      "Epoch 830/2000\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.5630 - acc: 0.8359 - val_loss: 0.7074 - val_acc: 0.8053\n",
      "Epoch 831/2000\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.5633 - acc: 0.8374 - val_loss: 0.7075 - val_acc: 0.8068\n",
      "Epoch 832/2000\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.5636 - acc: 0.8355 - val_loss: 0.7081 - val_acc: 0.8067\n",
      "Epoch 833/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5638 - acc: 0.8358 - val_loss: 0.7070 - val_acc: 0.8078\n",
      "Epoch 834/2000\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.5634 - acc: 0.8355 - val_loss: 0.7077 - val_acc: 0.8057\n",
      "Epoch 835/2000\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.5631 - acc: 0.8365 - val_loss: 0.7072 - val_acc: 0.8077\n",
      "Epoch 836/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5633 - acc: 0.8362 - val_loss: 0.7079 - val_acc: 0.8051\n",
      "Epoch 837/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5630 - acc: 0.8361 - val_loss: 0.7071 - val_acc: 0.8059\n",
      "Epoch 838/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5633 - acc: 0.8366 - val_loss: 0.7078 - val_acc: 0.8069\n",
      "Epoch 839/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5634 - acc: 0.8364 - val_loss: 0.7065 - val_acc: 0.8069\n",
      "Epoch 840/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5625 - acc: 0.8367 - val_loss: 0.7068 - val_acc: 0.8064\n",
      "Epoch 841/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5626 - acc: 0.8361 - val_loss: 0.7067 - val_acc: 0.8072\n",
      "Epoch 842/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5629 - acc: 0.8366 - val_loss: 0.7062 - val_acc: 0.8074\n",
      "Epoch 843/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5624 - acc: 0.8369 - val_loss: 0.7072 - val_acc: 0.8071\n",
      "Epoch 844/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5629 - acc: 0.8363 - val_loss: 0.7073 - val_acc: 0.8061\n",
      "Epoch 845/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5625 - acc: 0.8364 - val_loss: 0.7069 - val_acc: 0.8061\n",
      "Epoch 846/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5628 - acc: 0.8366 - val_loss: 0.7069 - val_acc: 0.8063\n",
      "Epoch 847/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5630 - acc: 0.8361 - val_loss: 0.7076 - val_acc: 0.8067\n",
      "Epoch 848/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5630 - acc: 0.8360 - val_loss: 0.7072 - val_acc: 0.8068\n",
      "Epoch 849/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5626 - acc: 0.8363 - val_loss: 0.7060 - val_acc: 0.8074\n",
      "Epoch 850/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5621 - acc: 0.8364 - val_loss: 0.7081 - val_acc: 0.8047\n",
      "Epoch 851/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5624 - acc: 0.8367 - val_loss: 0.7069 - val_acc: 0.8059\n",
      "Epoch 852/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5622 - acc: 0.8367 - val_loss: 0.7063 - val_acc: 0.8072\n",
      "Epoch 853/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5623 - acc: 0.8361 - val_loss: 0.7076 - val_acc: 0.8061\n",
      "Epoch 854/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5621 - acc: 0.8370 - val_loss: 0.7063 - val_acc: 0.8073\n",
      "Epoch 855/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5618 - acc: 0.8369 - val_loss: 0.7069 - val_acc: 0.8062\n",
      "Epoch 856/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5622 - acc: 0.8363 - val_loss: 0.7065 - val_acc: 0.8071\n",
      "Epoch 857/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5620 - acc: 0.8371 - val_loss: 0.7069 - val_acc: 0.8076\n",
      "Epoch 858/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5619 - acc: 0.8369 - val_loss: 0.7073 - val_acc: 0.8067\n",
      "Epoch 859/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5615 - acc: 0.8364 - val_loss: 0.7078 - val_acc: 0.8059\n",
      "Epoch 860/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5618 - acc: 0.8373 - val_loss: 0.7079 - val_acc: 0.8070\n",
      "Epoch 861/2000\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 0.5616 - acc: 0.8369 - val_loss: 0.7084 - val_acc: 0.8055\n",
      "Epoch 862/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5623 - acc: 0.8367 - val_loss: 0.7065 - val_acc: 0.8072\n",
      "Epoch 863/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5616 - acc: 0.8368 - val_loss: 0.7088 - val_acc: 0.8058\n",
      "Epoch 864/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5617 - acc: 0.8364 - val_loss: 0.7062 - val_acc: 0.8076\n",
      "Epoch 865/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5612 - acc: 0.8369 - val_loss: 0.7071 - val_acc: 0.8068\n",
      "Epoch 866/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5612 - acc: 0.8374 - val_loss: 0.7054 - val_acc: 0.8071\n",
      "Epoch 867/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5618 - acc: 0.8363 - val_loss: 0.7077 - val_acc: 0.8071\n",
      "Epoch 868/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5619 - acc: 0.8366 - val_loss: 0.7073 - val_acc: 0.8071\n",
      "Epoch 869/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5611 - acc: 0.8374 - val_loss: 0.7068 - val_acc: 0.8067\n",
      "Epoch 870/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5611 - acc: 0.8363 - val_loss: 0.7058 - val_acc: 0.8070\n",
      "Epoch 871/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5612 - acc: 0.8369 - val_loss: 0.7069 - val_acc: 0.8060\n",
      "Epoch 872/2000\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 0.5612 - acc: 0.8377 - val_loss: 0.7073 - val_acc: 0.8072\n",
      "Epoch 873/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5611 - acc: 0.8370 - val_loss: 0.7064 - val_acc: 0.8067\n",
      "Epoch 874/2000\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 0.5607 - acc: 0.8369 - val_loss: 0.7061 - val_acc: 0.8073\n",
      "Epoch 875/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5615 - acc: 0.8370 - val_loss: 0.7069 - val_acc: 0.8077\n",
      "Epoch 876/2000\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 0.5610 - acc: 0.8375 - val_loss: 0.7055 - val_acc: 0.8073\n",
      "Epoch 877/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5607 - acc: 0.8365 - val_loss: 0.7072 - val_acc: 0.8062\n",
      "Epoch 878/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5611 - acc: 0.8370 - val_loss: 0.7058 - val_acc: 0.8073\n",
      "Epoch 879/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5609 - acc: 0.8370 - val_loss: 0.7064 - val_acc: 0.8074\n",
      "Epoch 880/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5605 - acc: 0.8369 - val_loss: 0.7058 - val_acc: 0.8070\n",
      "Epoch 881/2000\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.5603 - acc: 0.8382 - val_loss: 0.7058 - val_acc: 0.8074\n",
      "Epoch 882/2000\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.5606 - acc: 0.8370 - val_loss: 0.7069 - val_acc: 0.8062\n",
      "Epoch 883/2000\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.5607 - acc: 0.8368 - val_loss: 0.7056 - val_acc: 0.8074\n",
      "Epoch 884/2000\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.5602 - acc: 0.8372 - val_loss: 0.7062 - val_acc: 0.8065\n",
      "Epoch 885/2000\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.5604 - acc: 0.8370 - val_loss: 0.7063 - val_acc: 0.8076\n",
      "Epoch 886/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5607 - acc: 0.8369 - val_loss: 0.7061 - val_acc: 0.8069\n",
      "Epoch 887/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5601 - acc: 0.8375 - val_loss: 0.7050 - val_acc: 0.8079\n",
      "Epoch 888/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5601 - acc: 0.8366 - val_loss: 0.7058 - val_acc: 0.8076\n",
      "Epoch 889/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5599 - acc: 0.8378 - val_loss: 0.7067 - val_acc: 0.8072\n",
      "Epoch 890/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5600 - acc: 0.8381 - val_loss: 0.7060 - val_acc: 0.8081\n",
      "Epoch 891/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5601 - acc: 0.8384 - val_loss: 0.7064 - val_acc: 0.8071\n",
      "Epoch 892/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5602 - acc: 0.8370 - val_loss: 0.7059 - val_acc: 0.8069\n",
      "Epoch 893/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5599 - acc: 0.8374 - val_loss: 0.7068 - val_acc: 0.8078\n",
      "Epoch 894/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5597 - acc: 0.8374 - val_loss: 0.7063 - val_acc: 0.8069\n",
      "Epoch 895/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5598 - acc: 0.8376 - val_loss: 0.7063 - val_acc: 0.8068\n",
      "Epoch 896/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5601 - acc: 0.8375 - val_loss: 0.7064 - val_acc: 0.8072\n",
      "Epoch 897/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5602 - acc: 0.8375 - val_loss: 0.7064 - val_acc: 0.8069\n",
      "Epoch 898/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5601 - acc: 0.8377 - val_loss: 0.7061 - val_acc: 0.8070\n",
      "Epoch 899/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5596 - acc: 0.8378 - val_loss: 0.7064 - val_acc: 0.8067\n",
      "Epoch 900/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5599 - acc: 0.8366 - val_loss: 0.7065 - val_acc: 0.8071\n",
      "Epoch 901/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5595 - acc: 0.8382 - val_loss: 0.7063 - val_acc: 0.8080\n",
      "Epoch 902/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5595 - acc: 0.8376 - val_loss: 0.7087 - val_acc: 0.8056\n",
      "Epoch 903/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5594 - acc: 0.8373 - val_loss: 0.7100 - val_acc: 0.8048\n",
      "Epoch 904/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5599 - acc: 0.8372 - val_loss: 0.7055 - val_acc: 0.8074\n",
      "Epoch 905/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5593 - acc: 0.8374 - val_loss: 0.7053 - val_acc: 0.8069\n",
      "Epoch 906/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5591 - acc: 0.8376 - val_loss: 0.7056 - val_acc: 0.8079\n",
      "Epoch 907/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5595 - acc: 0.8376 - val_loss: 0.7078 - val_acc: 0.8058\n",
      "Epoch 908/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5596 - acc: 0.8368 - val_loss: 0.7057 - val_acc: 0.8072\n",
      "Epoch 909/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5592 - acc: 0.8378 - val_loss: 0.7077 - val_acc: 0.8069\n",
      "Epoch 910/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5591 - acc: 0.8379 - val_loss: 0.7054 - val_acc: 0.8065\n",
      "Epoch 911/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5590 - acc: 0.8377 - val_loss: 0.7062 - val_acc: 0.8067\n",
      "Epoch 912/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5591 - acc: 0.8375 - val_loss: 0.7051 - val_acc: 0.8087\n",
      "Epoch 913/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5593 - acc: 0.8380 - val_loss: 0.7061 - val_acc: 0.8071\n",
      "Epoch 914/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5588 - acc: 0.8378 - val_loss: 0.7063 - val_acc: 0.8077\n",
      "Epoch 915/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5587 - acc: 0.8375 - val_loss: 0.7056 - val_acc: 0.8067\n",
      "Epoch 916/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5591 - acc: 0.8382 - val_loss: 0.7054 - val_acc: 0.8072\n",
      "Epoch 917/2000\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.5588 - acc: 0.8384 - val_loss: 0.7053 - val_acc: 0.8072\n",
      "Epoch 918/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5584 - acc: 0.8385 - val_loss: 0.7063 - val_acc: 0.8069\n",
      "Epoch 919/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5585 - acc: 0.8375 - val_loss: 0.7059 - val_acc: 0.8071\n",
      "Epoch 920/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5586 - acc: 0.8385 - val_loss: 0.7060 - val_acc: 0.8082\n",
      "Epoch 921/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5586 - acc: 0.8383 - val_loss: 0.7050 - val_acc: 0.8073\n",
      "Epoch 922/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5586 - acc: 0.8376 - val_loss: 0.7049 - val_acc: 0.8077\n",
      "Epoch 923/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5583 - acc: 0.8384 - val_loss: 0.7052 - val_acc: 0.8072\n",
      "Epoch 924/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5583 - acc: 0.8384 - val_loss: 0.7054 - val_acc: 0.8076\n",
      "Epoch 925/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5583 - acc: 0.8380 - val_loss: 0.7051 - val_acc: 0.8083\n",
      "Epoch 926/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5584 - acc: 0.8372 - val_loss: 0.7055 - val_acc: 0.8077\n",
      "Epoch 927/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5587 - acc: 0.8375 - val_loss: 0.7055 - val_acc: 0.8070\n",
      "Epoch 928/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5583 - acc: 0.8381 - val_loss: 0.7052 - val_acc: 0.8080\n",
      "Epoch 929/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5582 - acc: 0.8382 - val_loss: 0.7053 - val_acc: 0.8077\n",
      "Epoch 930/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5580 - acc: 0.8377 - val_loss: 0.7050 - val_acc: 0.8089\n",
      "Epoch 931/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5583 - acc: 0.8382 - val_loss: 0.7046 - val_acc: 0.8087\n",
      "Epoch 932/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5580 - acc: 0.8376 - val_loss: 0.7061 - val_acc: 0.8070\n",
      "Epoch 933/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5579 - acc: 0.8386 - val_loss: 0.7054 - val_acc: 0.8079\n",
      "Epoch 934/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5580 - acc: 0.8380 - val_loss: 0.7051 - val_acc: 0.8083\n",
      "Epoch 935/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5581 - acc: 0.8378 - val_loss: 0.7054 - val_acc: 0.8078\n",
      "Epoch 936/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5581 - acc: 0.8375 - val_loss: 0.7046 - val_acc: 0.8076\n",
      "Epoch 937/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5580 - acc: 0.8378 - val_loss: 0.7058 - val_acc: 0.8076\n",
      "Epoch 938/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5579 - acc: 0.8376 - val_loss: 0.7058 - val_acc: 0.8077\n",
      "Epoch 939/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5575 - acc: 0.8381 - val_loss: 0.7053 - val_acc: 0.8079\n",
      "Epoch 940/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5576 - acc: 0.8380 - val_loss: 0.7045 - val_acc: 0.8078\n",
      "Epoch 941/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5577 - acc: 0.8386 - val_loss: 0.7058 - val_acc: 0.8074\n",
      "Epoch 942/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5577 - acc: 0.8382 - val_loss: 0.7051 - val_acc: 0.8072\n",
      "Epoch 943/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5580 - acc: 0.8379 - val_loss: 0.7049 - val_acc: 0.8072\n",
      "Epoch 944/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5576 - acc: 0.8380 - val_loss: 0.7042 - val_acc: 0.8077\n",
      "Epoch 945/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5574 - acc: 0.8381 - val_loss: 0.7046 - val_acc: 0.8077\n",
      "Epoch 946/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5576 - acc: 0.8384 - val_loss: 0.7047 - val_acc: 0.8078\n",
      "Epoch 947/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5572 - acc: 0.8378 - val_loss: 0.7053 - val_acc: 0.8072\n",
      "Epoch 948/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5572 - acc: 0.8382 - val_loss: 0.7059 - val_acc: 0.8069\n",
      "Epoch 949/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5571 - acc: 0.8381 - val_loss: 0.7048 - val_acc: 0.8081\n",
      "Epoch 950/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5570 - acc: 0.8383 - val_loss: 0.7041 - val_acc: 0.8093\n",
      "Epoch 951/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5573 - acc: 0.8390 - val_loss: 0.7058 - val_acc: 0.8084\n",
      "Epoch 952/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5570 - acc: 0.8381 - val_loss: 0.7051 - val_acc: 0.8084\n",
      "Epoch 953/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5569 - acc: 0.8385 - val_loss: 0.7045 - val_acc: 0.8079\n",
      "Epoch 954/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5568 - acc: 0.8391 - val_loss: 0.7073 - val_acc: 0.8061\n",
      "Epoch 955/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5577 - acc: 0.8379 - val_loss: 0.7047 - val_acc: 0.8072\n",
      "Epoch 956/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5570 - acc: 0.8386 - val_loss: 0.7074 - val_acc: 0.8056\n",
      "Epoch 957/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5572 - acc: 0.8387 - val_loss: 0.7047 - val_acc: 0.8069\n",
      "Epoch 958/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5569 - acc: 0.8382 - val_loss: 0.7043 - val_acc: 0.8077\n",
      "Epoch 959/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5571 - acc: 0.8390 - val_loss: 0.7060 - val_acc: 0.8071\n",
      "Epoch 960/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5568 - acc: 0.8381 - val_loss: 0.7047 - val_acc: 0.8074\n",
      "Epoch 961/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5567 - acc: 0.8389 - val_loss: 0.7047 - val_acc: 0.8094\n",
      "Epoch 962/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5570 - acc: 0.8386 - val_loss: 0.7046 - val_acc: 0.8086\n",
      "Epoch 963/2000\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 0.5563 - acc: 0.8381 - val_loss: 0.7046 - val_acc: 0.8080\n",
      "Epoch 964/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5563 - acc: 0.8380 - val_loss: 0.7044 - val_acc: 0.8083\n",
      "Epoch 965/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5563 - acc: 0.8383 - val_loss: 0.7056 - val_acc: 0.8076\n",
      "Epoch 966/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5566 - acc: 0.8385 - val_loss: 0.7051 - val_acc: 0.8078\n",
      "Epoch 967/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5562 - acc: 0.8385 - val_loss: 0.7056 - val_acc: 0.8065\n",
      "Epoch 968/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5567 - acc: 0.8386 - val_loss: 0.7040 - val_acc: 0.8082\n",
      "Epoch 969/2000\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 0.5563 - acc: 0.8388 - val_loss: 0.7051 - val_acc: 0.8080\n",
      "Epoch 970/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5566 - acc: 0.8381 - val_loss: 0.7044 - val_acc: 0.8087\n",
      "Epoch 971/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5563 - acc: 0.8391 - val_loss: 0.7046 - val_acc: 0.8086\n",
      "Epoch 972/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5562 - acc: 0.8381 - val_loss: 0.7038 - val_acc: 0.8091\n",
      "Epoch 973/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5564 - acc: 0.8380 - val_loss: 0.7036 - val_acc: 0.8090\n",
      "Epoch 974/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5558 - acc: 0.8385 - val_loss: 0.7041 - val_acc: 0.8090\n",
      "Epoch 975/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5562 - acc: 0.8390 - val_loss: 0.7056 - val_acc: 0.8076\n",
      "Epoch 976/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5564 - acc: 0.8384 - val_loss: 0.7037 - val_acc: 0.8073\n",
      "Epoch 977/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5560 - acc: 0.8383 - val_loss: 0.7044 - val_acc: 0.8074\n",
      "Epoch 978/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5558 - acc: 0.8390 - val_loss: 0.7059 - val_acc: 0.8072\n",
      "Epoch 979/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5560 - acc: 0.8388 - val_loss: 0.7047 - val_acc: 0.8085\n",
      "Epoch 980/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5561 - acc: 0.8386 - val_loss: 0.7047 - val_acc: 0.8074\n",
      "Epoch 981/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5557 - acc: 0.8381 - val_loss: 0.7043 - val_acc: 0.8081\n",
      "Epoch 982/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5561 - acc: 0.8384 - val_loss: 0.7049 - val_acc: 0.8082\n",
      "Epoch 983/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5557 - acc: 0.8390 - val_loss: 0.7039 - val_acc: 0.8097\n",
      "Epoch 984/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5557 - acc: 0.8389 - val_loss: 0.7043 - val_acc: 0.8074\n",
      "Epoch 985/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5552 - acc: 0.8384 - val_loss: 0.7046 - val_acc: 0.8082\n",
      "Epoch 986/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5554 - acc: 0.8386 - val_loss: 0.7040 - val_acc: 0.8073\n",
      "Epoch 987/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5556 - acc: 0.8389 - val_loss: 0.7045 - val_acc: 0.8069\n",
      "Epoch 988/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5555 - acc: 0.8387 - val_loss: 0.7041 - val_acc: 0.8084\n",
      "Epoch 989/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5553 - acc: 0.8392 - val_loss: 0.7039 - val_acc: 0.8086\n",
      "Epoch 990/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5553 - acc: 0.8387 - val_loss: 0.7041 - val_acc: 0.8092\n",
      "Epoch 991/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5553 - acc: 0.8395 - val_loss: 0.7044 - val_acc: 0.8081\n",
      "Epoch 992/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5555 - acc: 0.8386 - val_loss: 0.7040 - val_acc: 0.8083\n",
      "Epoch 993/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5551 - acc: 0.8388 - val_loss: 0.7045 - val_acc: 0.8076\n",
      "Epoch 994/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5552 - acc: 0.8384 - val_loss: 0.7042 - val_acc: 0.8080\n",
      "Epoch 995/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5546 - acc: 0.8384 - val_loss: 0.7039 - val_acc: 0.8081\n",
      "Epoch 996/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5549 - acc: 0.8389 - val_loss: 0.7041 - val_acc: 0.8073\n",
      "Epoch 997/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5553 - acc: 0.8384 - val_loss: 0.7044 - val_acc: 0.8076\n",
      "Epoch 998/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5551 - acc: 0.8390 - val_loss: 0.7042 - val_acc: 0.8086\n",
      "Epoch 999/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5551 - acc: 0.8387 - val_loss: 0.7052 - val_acc: 0.8082\n",
      "Epoch 1000/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5548 - acc: 0.8390 - val_loss: 0.7051 - val_acc: 0.8077\n",
      "Epoch 1001/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5552 - acc: 0.8391 - val_loss: 0.7036 - val_acc: 0.8080\n",
      "Epoch 1002/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5547 - acc: 0.8400 - val_loss: 0.7046 - val_acc: 0.8082\n",
      "Epoch 1003/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5546 - acc: 0.8387 - val_loss: 0.7043 - val_acc: 0.8073\n",
      "Epoch 1004/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5546 - acc: 0.8388 - val_loss: 0.7044 - val_acc: 0.8087\n",
      "Epoch 1005/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5545 - acc: 0.8388 - val_loss: 0.7047 - val_acc: 0.8071\n",
      "Epoch 1006/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5544 - acc: 0.8388 - val_loss: 0.7043 - val_acc: 0.8080\n",
      "Epoch 1007/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5546 - acc: 0.8386 - val_loss: 0.7047 - val_acc: 0.8073\n",
      "Epoch 1008/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5548 - acc: 0.8382 - val_loss: 0.7044 - val_acc: 0.8081\n",
      "Epoch 1009/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5543 - acc: 0.8397 - val_loss: 0.7063 - val_acc: 0.8051\n",
      "Epoch 1010/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5545 - acc: 0.8385 - val_loss: 0.7040 - val_acc: 0.8082\n",
      "Epoch 1011/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5544 - acc: 0.8393 - val_loss: 0.7044 - val_acc: 0.8083\n",
      "Epoch 1012/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5543 - acc: 0.8399 - val_loss: 0.7027 - val_acc: 0.8088\n",
      "Epoch 1013/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5542 - acc: 0.8384 - val_loss: 0.7033 - val_acc: 0.8089\n",
      "Epoch 1014/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5545 - acc: 0.8393 - val_loss: 0.7050 - val_acc: 0.8089\n",
      "Epoch 1015/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5544 - acc: 0.8394 - val_loss: 0.7057 - val_acc: 0.8072\n",
      "Epoch 1016/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5547 - acc: 0.8390 - val_loss: 0.7045 - val_acc: 0.8083\n",
      "Epoch 1017/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5543 - acc: 0.8391 - val_loss: 0.7035 - val_acc: 0.8084\n",
      "Epoch 1018/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5543 - acc: 0.8393 - val_loss: 0.7036 - val_acc: 0.8090\n",
      "Epoch 1019/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5543 - acc: 0.8390 - val_loss: 0.7034 - val_acc: 0.8089\n",
      "Epoch 1020/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5539 - acc: 0.8392 - val_loss: 0.7033 - val_acc: 0.8078\n",
      "Epoch 1021/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5539 - acc: 0.8393 - val_loss: 0.7032 - val_acc: 0.8078\n",
      "Epoch 1022/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5541 - acc: 0.8391 - val_loss: 0.7036 - val_acc: 0.8081\n",
      "Epoch 1023/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5542 - acc: 0.8395 - val_loss: 0.7044 - val_acc: 0.8081\n",
      "Epoch 1024/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5541 - acc: 0.8400 - val_loss: 0.7036 - val_acc: 0.8090\n",
      "Epoch 1025/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5536 - acc: 0.8387 - val_loss: 0.7041 - val_acc: 0.8075\n",
      "Epoch 1026/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5538 - acc: 0.8386 - val_loss: 0.7030 - val_acc: 0.8093\n",
      "Epoch 1027/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5536 - acc: 0.8392 - val_loss: 0.7038 - val_acc: 0.8072\n",
      "Epoch 1028/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5539 - acc: 0.8394 - val_loss: 0.7035 - val_acc: 0.8083\n",
      "Epoch 1029/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5536 - acc: 0.8388 - val_loss: 0.7049 - val_acc: 0.8069\n",
      "Epoch 1030/2000\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 0.5537 - acc: 0.8391 - val_loss: 0.7047 - val_acc: 0.8077\n",
      "Epoch 1031/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5535 - acc: 0.8393 - val_loss: 0.7029 - val_acc: 0.8086\n",
      "Epoch 1032/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5536 - acc: 0.8397 - val_loss: 0.7031 - val_acc: 0.8084\n",
      "Epoch 1033/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5536 - acc: 0.8391 - val_loss: 0.7040 - val_acc: 0.8076\n",
      "Epoch 1034/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5535 - acc: 0.8394 - val_loss: 0.7031 - val_acc: 0.8078\n",
      "Epoch 1035/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5532 - acc: 0.8389 - val_loss: 0.7039 - val_acc: 0.8074\n",
      "Epoch 1036/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5534 - acc: 0.8390 - val_loss: 0.7039 - val_acc: 0.8079\n",
      "Epoch 1037/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5531 - acc: 0.8391 - val_loss: 0.7031 - val_acc: 0.8090\n",
      "Epoch 1038/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5532 - acc: 0.8388 - val_loss: 0.7036 - val_acc: 0.8084\n",
      "Epoch 1039/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5531 - acc: 0.8396 - val_loss: 0.7032 - val_acc: 0.8095\n",
      "Epoch 1040/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5532 - acc: 0.8393 - val_loss: 0.7036 - val_acc: 0.8090\n",
      "Epoch 1041/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5529 - acc: 0.8391 - val_loss: 0.7030 - val_acc: 0.8084\n",
      "Epoch 1042/2000\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.5531 - acc: 0.8399 - val_loss: 0.7026 - val_acc: 0.8079\n",
      "Epoch 1043/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5530 - acc: 0.8393 - val_loss: 0.7035 - val_acc: 0.8076\n",
      "Epoch 1044/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5533 - acc: 0.8393 - val_loss: 0.7030 - val_acc: 0.8087\n",
      "Epoch 1045/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5529 - acc: 0.8396 - val_loss: 0.7038 - val_acc: 0.8084\n",
      "Epoch 1046/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5527 - acc: 0.8402 - val_loss: 0.7029 - val_acc: 0.8093\n",
      "Epoch 1047/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5528 - acc: 0.8398 - val_loss: 0.7033 - val_acc: 0.8083\n",
      "Epoch 1048/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5531 - acc: 0.8400 - val_loss: 0.7038 - val_acc: 0.8083\n",
      "Epoch 1049/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5529 - acc: 0.8399 - val_loss: 0.7036 - val_acc: 0.8086\n",
      "Epoch 1050/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5526 - acc: 0.8393 - val_loss: 0.7031 - val_acc: 0.8083\n",
      "Epoch 1051/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5526 - acc: 0.8396 - val_loss: 0.7033 - val_acc: 0.8090\n",
      "Epoch 1052/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5528 - acc: 0.8392 - val_loss: 0.7039 - val_acc: 0.8089\n",
      "Epoch 1053/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5529 - acc: 0.8400 - val_loss: 0.7029 - val_acc: 0.8087\n",
      "Epoch 1054/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5525 - acc: 0.8400 - val_loss: 0.7035 - val_acc: 0.8084\n",
      "Epoch 1055/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5527 - acc: 0.8389 - val_loss: 0.7047 - val_acc: 0.8086\n",
      "Epoch 1056/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5529 - acc: 0.8392 - val_loss: 0.7029 - val_acc: 0.8092\n",
      "Epoch 1057/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5526 - acc: 0.8397 - val_loss: 0.7041 - val_acc: 0.8079\n",
      "Epoch 1058/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5523 - acc: 0.8395 - val_loss: 0.7035 - val_acc: 0.8084\n",
      "Epoch 1059/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5524 - acc: 0.8400 - val_loss: 0.7027 - val_acc: 0.8084\n",
      "Epoch 1060/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5524 - acc: 0.8385 - val_loss: 0.7048 - val_acc: 0.8077\n",
      "Epoch 1061/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5524 - acc: 0.8395 - val_loss: 0.7027 - val_acc: 0.8079\n",
      "Epoch 1062/2000\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 0.5527 - acc: 0.8389 - val_loss: 0.7032 - val_acc: 0.8091\n",
      "Epoch 1063/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5527 - acc: 0.8389 - val_loss: 0.7024 - val_acc: 0.8089\n",
      "Epoch 1064/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5521 - acc: 0.8395 - val_loss: 0.7026 - val_acc: 0.8094\n",
      "Epoch 1065/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5522 - acc: 0.8393 - val_loss: 0.7024 - val_acc: 0.8096\n",
      "Epoch 1066/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5519 - acc: 0.8395 - val_loss: 0.7030 - val_acc: 0.8088\n",
      "Epoch 1067/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5520 - acc: 0.8400 - val_loss: 0.7042 - val_acc: 0.8077\n",
      "Epoch 1068/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5525 - acc: 0.8398 - val_loss: 0.7029 - val_acc: 0.8093\n",
      "Epoch 1069/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5521 - acc: 0.8399 - val_loss: 0.7024 - val_acc: 0.8080\n",
      "Epoch 1070/2000\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 0.5521 - acc: 0.8402 - val_loss: 0.7034 - val_acc: 0.8078\n",
      "Epoch 1071/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5524 - acc: 0.8390 - val_loss: 0.7028 - val_acc: 0.8086\n",
      "Epoch 1072/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5517 - acc: 0.8392 - val_loss: 0.7024 - val_acc: 0.8093\n",
      "Epoch 1073/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5521 - acc: 0.8394 - val_loss: 0.7042 - val_acc: 0.8074\n",
      "Epoch 1074/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5516 - acc: 0.8395 - val_loss: 0.7025 - val_acc: 0.8089\n",
      "Epoch 1075/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5516 - acc: 0.8397 - val_loss: 0.7030 - val_acc: 0.8082\n",
      "Epoch 1076/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5515 - acc: 0.8403 - val_loss: 0.7031 - val_acc: 0.8077\n",
      "Epoch 1077/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5517 - acc: 0.8400 - val_loss: 0.7030 - val_acc: 0.8084\n",
      "Epoch 1078/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5523 - acc: 0.8398 - val_loss: 0.7037 - val_acc: 0.8093\n",
      "Epoch 1079/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5515 - acc: 0.8397 - val_loss: 0.7023 - val_acc: 0.8089\n",
      "Epoch 1080/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5516 - acc: 0.8400 - val_loss: 0.7028 - val_acc: 0.8082\n",
      "Epoch 1081/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5518 - acc: 0.8396 - val_loss: 0.7031 - val_acc: 0.8085\n",
      "Epoch 1082/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5513 - acc: 0.8400 - val_loss: 0.7026 - val_acc: 0.8092\n",
      "Epoch 1083/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5515 - acc: 0.8403 - val_loss: 0.7033 - val_acc: 0.8092\n",
      "Epoch 1084/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5514 - acc: 0.8395 - val_loss: 0.7028 - val_acc: 0.8093\n",
      "Epoch 1085/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5515 - acc: 0.8401 - val_loss: 0.7029 - val_acc: 0.8085\n",
      "Epoch 1086/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5515 - acc: 0.8398 - val_loss: 0.7027 - val_acc: 0.8082\n",
      "Epoch 1087/2000\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 0.5515 - acc: 0.8400 - val_loss: 0.7029 - val_acc: 0.8080\n",
      "Epoch 1088/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5513 - acc: 0.8400 - val_loss: 0.7041 - val_acc: 0.8067\n",
      "Epoch 1089/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5514 - acc: 0.8401 - val_loss: 0.7027 - val_acc: 0.8099\n",
      "Epoch 1090/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5514 - acc: 0.8398 - val_loss: 0.7033 - val_acc: 0.8088\n",
      "Epoch 1091/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5512 - acc: 0.8397 - val_loss: 0.7023 - val_acc: 0.8096\n",
      "Epoch 1092/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5511 - acc: 0.8398 - val_loss: 0.7034 - val_acc: 0.8086\n",
      "Epoch 1093/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5513 - acc: 0.8403 - val_loss: 0.7037 - val_acc: 0.8094\n",
      "Epoch 1094/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5510 - acc: 0.8405 - val_loss: 0.7036 - val_acc: 0.8075\n",
      "Epoch 1095/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5510 - acc: 0.8395 - val_loss: 0.7027 - val_acc: 0.8087\n",
      "Epoch 1096/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5509 - acc: 0.8395 - val_loss: 0.7030 - val_acc: 0.8092\n",
      "Epoch 1097/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5507 - acc: 0.8405 - val_loss: 0.7026 - val_acc: 0.8081\n",
      "Epoch 1098/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5509 - acc: 0.8399 - val_loss: 0.7022 - val_acc: 0.8087\n",
      "Epoch 1099/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5506 - acc: 0.8410 - val_loss: 0.7047 - val_acc: 0.8078\n",
      "Epoch 1100/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5509 - acc: 0.8402 - val_loss: 0.7034 - val_acc: 0.8083\n",
      "Epoch 1101/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5509 - acc: 0.8402 - val_loss: 0.7027 - val_acc: 0.8086\n",
      "Epoch 1102/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5508 - acc: 0.8399 - val_loss: 0.7025 - val_acc: 0.8091\n",
      "Epoch 1103/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5508 - acc: 0.8404 - val_loss: 0.7021 - val_acc: 0.8089\n",
      "Epoch 1104/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5506 - acc: 0.8402 - val_loss: 0.7039 - val_acc: 0.8083\n",
      "Epoch 1105/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5506 - acc: 0.8406 - val_loss: 0.7022 - val_acc: 0.8094\n",
      "Epoch 1106/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5506 - acc: 0.8396 - val_loss: 0.7023 - val_acc: 0.8102\n",
      "Epoch 1107/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5504 - acc: 0.8403 - val_loss: 0.7025 - val_acc: 0.8089\n",
      "Epoch 1108/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5510 - acc: 0.8403 - val_loss: 0.7027 - val_acc: 0.8087\n",
      "Epoch 1109/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5501 - acc: 0.8403 - val_loss: 0.7024 - val_acc: 0.8092\n",
      "Epoch 1110/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5503 - acc: 0.8397 - val_loss: 0.7026 - val_acc: 0.8083\n",
      "Epoch 1111/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5506 - acc: 0.8401 - val_loss: 0.7030 - val_acc: 0.8085\n",
      "Epoch 1112/2000\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 0.5502 - acc: 0.8404 - val_loss: 0.7018 - val_acc: 0.8097\n",
      "Epoch 1113/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5505 - acc: 0.8404 - val_loss: 0.7027 - val_acc: 0.8083\n",
      "Epoch 1114/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5500 - acc: 0.8403 - val_loss: 0.7024 - val_acc: 0.8093\n",
      "Epoch 1115/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5500 - acc: 0.8401 - val_loss: 0.7022 - val_acc: 0.8096\n",
      "Epoch 1116/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5500 - acc: 0.8406 - val_loss: 0.7020 - val_acc: 0.8097\n",
      "Epoch 1117/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5501 - acc: 0.8399 - val_loss: 0.7028 - val_acc: 0.8084\n",
      "Epoch 1118/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5498 - acc: 0.8406 - val_loss: 0.7018 - val_acc: 0.8092\n",
      "Epoch 1119/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5502 - acc: 0.8401 - val_loss: 0.7018 - val_acc: 0.8092\n",
      "Epoch 1120/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5497 - acc: 0.8405 - val_loss: 0.7018 - val_acc: 0.8086\n",
      "Epoch 1121/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5499 - acc: 0.8410 - val_loss: 0.7041 - val_acc: 0.8086\n",
      "Epoch 1122/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5503 - acc: 0.8410 - val_loss: 0.7018 - val_acc: 0.8100\n",
      "Epoch 1123/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5499 - acc: 0.8401 - val_loss: 0.7033 - val_acc: 0.8088\n",
      "Epoch 1124/2000\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.5499 - acc: 0.8400 - val_loss: 0.7023 - val_acc: 0.8082\n",
      "Epoch 1125/2000\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.5499 - acc: 0.8405 - val_loss: 0.7025 - val_acc: 0.8077\n",
      "Epoch 1126/2000\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.5498 - acc: 0.8409 - val_loss: 0.7022 - val_acc: 0.8094\n",
      "Epoch 1127/2000\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.5498 - acc: 0.8402 - val_loss: 0.7015 - val_acc: 0.8101\n",
      "Epoch 1128/2000\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.5500 - acc: 0.8409 - val_loss: 0.7020 - val_acc: 0.8090\n",
      "Epoch 1129/2000\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.5499 - acc: 0.8407 - val_loss: 0.7018 - val_acc: 0.8086\n",
      "Epoch 1130/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5495 - acc: 0.8405 - val_loss: 0.7027 - val_acc: 0.8088\n",
      "Epoch 1131/2000\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.5493 - acc: 0.8410 - val_loss: 0.7017 - val_acc: 0.8103\n",
      "Epoch 1132/2000\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.5494 - acc: 0.8407 - val_loss: 0.7016 - val_acc: 0.8090\n",
      "Epoch 1133/2000\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.5495 - acc: 0.8406 - val_loss: 0.7027 - val_acc: 0.8086\n",
      "Epoch 1134/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5496 - acc: 0.8403 - val_loss: 0.7020 - val_acc: 0.8086\n",
      "Epoch 1135/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5492 - acc: 0.8403 - val_loss: 0.7025 - val_acc: 0.8084\n",
      "Epoch 1136/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5493 - acc: 0.8405 - val_loss: 0.7017 - val_acc: 0.8086\n",
      "Epoch 1137/2000\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.5495 - acc: 0.8403 - val_loss: 0.7020 - val_acc: 0.8098\n",
      "Epoch 1138/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5494 - acc: 0.8406 - val_loss: 0.7018 - val_acc: 0.8086\n",
      "Epoch 1139/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5496 - acc: 0.8398 - val_loss: 0.7020 - val_acc: 0.8091\n",
      "Epoch 1140/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5496 - acc: 0.8404 - val_loss: 0.7019 - val_acc: 0.8091\n",
      "Epoch 1141/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5490 - acc: 0.8412 - val_loss: 0.7033 - val_acc: 0.8086\n",
      "Epoch 1142/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5493 - acc: 0.8409 - val_loss: 0.7014 - val_acc: 0.8088\n",
      "Epoch 1143/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5491 - acc: 0.8410 - val_loss: 0.7023 - val_acc: 0.8089\n",
      "Epoch 1144/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5489 - acc: 0.8410 - val_loss: 0.7016 - val_acc: 0.8099\n",
      "Epoch 1145/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5491 - acc: 0.8406 - val_loss: 0.7025 - val_acc: 0.8089\n",
      "Epoch 1146/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5490 - acc: 0.8405 - val_loss: 0.7024 - val_acc: 0.8082\n",
      "Epoch 1147/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5488 - acc: 0.8407 - val_loss: 0.7036 - val_acc: 0.8077\n",
      "Epoch 1148/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5489 - acc: 0.8408 - val_loss: 0.7021 - val_acc: 0.8091\n",
      "Epoch 1149/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5489 - acc: 0.8409 - val_loss: 0.7018 - val_acc: 0.8101\n",
      "Epoch 1150/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5485 - acc: 0.8410 - val_loss: 0.7018 - val_acc: 0.8094\n",
      "Epoch 1151/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5488 - acc: 0.8414 - val_loss: 0.7019 - val_acc: 0.8102\n",
      "Epoch 1152/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5486 - acc: 0.8404 - val_loss: 0.7018 - val_acc: 0.8102\n",
      "Epoch 1153/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5485 - acc: 0.8413 - val_loss: 0.7016 - val_acc: 0.8088\n",
      "Epoch 1154/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5488 - acc: 0.8404 - val_loss: 0.7031 - val_acc: 0.8087\n",
      "Epoch 1155/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5490 - acc: 0.8400 - val_loss: 0.7016 - val_acc: 0.8092\n",
      "Epoch 1156/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5489 - acc: 0.8410 - val_loss: 0.7031 - val_acc: 0.8082\n",
      "Epoch 1157/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5490 - acc: 0.8404 - val_loss: 0.7011 - val_acc: 0.8097\n",
      "Epoch 1158/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5487 - acc: 0.8409 - val_loss: 0.7027 - val_acc: 0.8088\n",
      "Epoch 1159/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5487 - acc: 0.8410 - val_loss: 0.7015 - val_acc: 0.8096\n",
      "Epoch 1160/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5484 - acc: 0.8407 - val_loss: 0.7016 - val_acc: 0.8084\n",
      "Epoch 1161/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5484 - acc: 0.8411 - val_loss: 0.7015 - val_acc: 0.8098\n",
      "Epoch 1162/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5486 - acc: 0.8406 - val_loss: 0.7024 - val_acc: 0.8090\n",
      "Epoch 1163/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5485 - acc: 0.8409 - val_loss: 0.7025 - val_acc: 0.8090\n",
      "Epoch 1164/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5482 - acc: 0.8408 - val_loss: 0.7013 - val_acc: 0.8100\n",
      "Epoch 1165/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5483 - acc: 0.8407 - val_loss: 0.7011 - val_acc: 0.8089\n",
      "Epoch 1166/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5482 - acc: 0.8414 - val_loss: 0.7015 - val_acc: 0.8089\n",
      "Epoch 1167/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5481 - acc: 0.8406 - val_loss: 0.7019 - val_acc: 0.8089\n",
      "Epoch 1168/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5485 - acc: 0.8410 - val_loss: 0.7022 - val_acc: 0.8088\n",
      "Epoch 1169/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5482 - acc: 0.8414 - val_loss: 0.7014 - val_acc: 0.8101\n",
      "Epoch 1170/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5481 - acc: 0.8414 - val_loss: 0.7019 - val_acc: 0.8106\n",
      "Epoch 1171/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5484 - acc: 0.8409 - val_loss: 0.7018 - val_acc: 0.8097\n",
      "Epoch 1172/2000\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.5483 - acc: 0.8409 - val_loss: 0.7026 - val_acc: 0.8086\n",
      "Epoch 1173/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5480 - acc: 0.8414 - val_loss: 0.7013 - val_acc: 0.8092\n",
      "Epoch 1174/2000\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.5477 - acc: 0.8412 - val_loss: 0.7020 - val_acc: 0.8094\n",
      "Epoch 1175/2000\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.5478 - acc: 0.8413 - val_loss: 0.7014 - val_acc: 0.8087\n",
      "Epoch 1176/2000\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.5478 - acc: 0.8409 - val_loss: 0.7028 - val_acc: 0.8086\n",
      "Epoch 1177/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5478 - acc: 0.8408 - val_loss: 0.7023 - val_acc: 0.8092\n",
      "Epoch 1178/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5477 - acc: 0.8403 - val_loss: 0.7017 - val_acc: 0.8083\n",
      "Epoch 1179/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5477 - acc: 0.8406 - val_loss: 0.7015 - val_acc: 0.8090\n",
      "Epoch 1180/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5478 - acc: 0.8408 - val_loss: 0.7012 - val_acc: 0.8096\n",
      "Epoch 1181/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5475 - acc: 0.8413 - val_loss: 0.7024 - val_acc: 0.8085\n",
      "Epoch 1182/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5480 - acc: 0.8408 - val_loss: 0.7014 - val_acc: 0.8095\n",
      "Epoch 1183/2000\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 0.5476 - acc: 0.8407 - val_loss: 0.7023 - val_acc: 0.8089\n",
      "Epoch 1184/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5477 - acc: 0.8414 - val_loss: 0.7012 - val_acc: 0.8095\n",
      "Epoch 1185/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5476 - acc: 0.8413 - val_loss: 0.7021 - val_acc: 0.8081\n",
      "Epoch 1186/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5475 - acc: 0.8413 - val_loss: 0.7009 - val_acc: 0.8097\n",
      "Epoch 1187/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5475 - acc: 0.8406 - val_loss: 0.7019 - val_acc: 0.8093\n",
      "Epoch 1188/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5476 - acc: 0.8413 - val_loss: 0.7007 - val_acc: 0.8097\n",
      "Epoch 1189/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5472 - acc: 0.8403 - val_loss: 0.7021 - val_acc: 0.8093\n",
      "Epoch 1190/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5474 - acc: 0.8411 - val_loss: 0.7006 - val_acc: 0.8103\n",
      "Epoch 1191/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5472 - acc: 0.8404 - val_loss: 0.7008 - val_acc: 0.8101\n",
      "Epoch 1192/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5473 - acc: 0.8410 - val_loss: 0.7022 - val_acc: 0.8095\n",
      "Epoch 1193/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5472 - acc: 0.8415 - val_loss: 0.7029 - val_acc: 0.8078\n",
      "Epoch 1194/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5475 - acc: 0.8411 - val_loss: 0.7025 - val_acc: 0.8089\n",
      "Epoch 1195/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5474 - acc: 0.8412 - val_loss: 0.7017 - val_acc: 0.8087\n",
      "Epoch 1196/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5470 - acc: 0.8412 - val_loss: 0.7012 - val_acc: 0.8088\n",
      "Epoch 1197/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5472 - acc: 0.8414 - val_loss: 0.7018 - val_acc: 0.8097\n",
      "Epoch 1198/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5471 - acc: 0.8417 - val_loss: 0.7005 - val_acc: 0.8091\n",
      "Epoch 1199/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5469 - acc: 0.8415 - val_loss: 0.7023 - val_acc: 0.8091\n",
      "Epoch 1200/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5471 - acc: 0.8411 - val_loss: 0.7010 - val_acc: 0.8091\n",
      "Epoch 1201/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5468 - acc: 0.8411 - val_loss: 0.7023 - val_acc: 0.8098\n",
      "Epoch 1202/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5470 - acc: 0.8414 - val_loss: 0.7023 - val_acc: 0.8084\n",
      "Epoch 1203/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5470 - acc: 0.8418 - val_loss: 0.7010 - val_acc: 0.8093\n",
      "Epoch 1204/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5468 - acc: 0.8415 - val_loss: 0.7011 - val_acc: 0.8089\n",
      "Epoch 1205/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5471 - acc: 0.8408 - val_loss: 0.7019 - val_acc: 0.8086\n",
      "Epoch 1206/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5470 - acc: 0.8414 - val_loss: 0.7005 - val_acc: 0.8098\n",
      "Epoch 1207/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5466 - acc: 0.8410 - val_loss: 0.7017 - val_acc: 0.8089\n",
      "Epoch 1208/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5466 - acc: 0.8414 - val_loss: 0.7013 - val_acc: 0.8086\n",
      "Epoch 1209/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5469 - acc: 0.8411 - val_loss: 0.7015 - val_acc: 0.8093\n",
      "Epoch 1210/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5467 - acc: 0.8414 - val_loss: 0.7021 - val_acc: 0.8091\n",
      "Epoch 1211/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5468 - acc: 0.8413 - val_loss: 0.7010 - val_acc: 0.8091\n",
      "Epoch 1212/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5463 - acc: 0.8416 - val_loss: 0.7014 - val_acc: 0.8097\n",
      "Epoch 1213/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5466 - acc: 0.8405 - val_loss: 0.7014 - val_acc: 0.8092\n",
      "Epoch 1214/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5466 - acc: 0.8412 - val_loss: 0.7009 - val_acc: 0.8091\n",
      "Epoch 1215/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5464 - acc: 0.8420 - val_loss: 0.7022 - val_acc: 0.8098\n",
      "Epoch 1216/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5467 - acc: 0.8412 - val_loss: 0.7011 - val_acc: 0.8102\n",
      "Epoch 1217/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5463 - acc: 0.8411 - val_loss: 0.7011 - val_acc: 0.8102\n",
      "Epoch 1218/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5464 - acc: 0.8410 - val_loss: 0.7017 - val_acc: 0.8101\n",
      "Epoch 1219/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5463 - acc: 0.8412 - val_loss: 0.7009 - val_acc: 0.8096\n",
      "Epoch 1220/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5464 - acc: 0.8413 - val_loss: 0.7001 - val_acc: 0.8099\n",
      "Epoch 1221/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5464 - acc: 0.8413 - val_loss: 0.7009 - val_acc: 0.8099\n",
      "Epoch 1222/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5464 - acc: 0.8416 - val_loss: 0.7010 - val_acc: 0.8097\n",
      "Epoch 1223/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5463 - acc: 0.8421 - val_loss: 0.7016 - val_acc: 0.8093\n",
      "Epoch 1224/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5463 - acc: 0.8411 - val_loss: 0.7008 - val_acc: 0.8090\n",
      "Epoch 1225/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5459 - acc: 0.8406 - val_loss: 0.7014 - val_acc: 0.8097\n",
      "Epoch 1226/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5465 - acc: 0.8415 - val_loss: 0.7015 - val_acc: 0.8086\n",
      "Epoch 1227/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5463 - acc: 0.8411 - val_loss: 0.7022 - val_acc: 0.8082\n",
      "Epoch 1228/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5461 - acc: 0.8416 - val_loss: 0.7012 - val_acc: 0.8095\n",
      "Epoch 1229/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5462 - acc: 0.8413 - val_loss: 0.7006 - val_acc: 0.8102\n",
      "Epoch 1230/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5461 - acc: 0.8412 - val_loss: 0.7012 - val_acc: 0.8096\n",
      "Epoch 1231/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5460 - acc: 0.8414 - val_loss: 0.7003 - val_acc: 0.8097\n",
      "Epoch 1232/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5458 - acc: 0.8419 - val_loss: 0.7013 - val_acc: 0.8098\n",
      "Epoch 1233/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5459 - acc: 0.8414 - val_loss: 0.7011 - val_acc: 0.8106\n",
      "Epoch 1234/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5457 - acc: 0.8421 - val_loss: 0.7008 - val_acc: 0.8088\n",
      "Epoch 1235/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5460 - acc: 0.8421 - val_loss: 0.7005 - val_acc: 0.8091\n",
      "Epoch 1236/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5457 - acc: 0.8419 - val_loss: 0.7009 - val_acc: 0.8095\n",
      "Epoch 1237/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5457 - acc: 0.8421 - val_loss: 0.7011 - val_acc: 0.8093\n",
      "Epoch 1238/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5458 - acc: 0.8415 - val_loss: 0.7018 - val_acc: 0.8094\n",
      "Epoch 1239/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5458 - acc: 0.8421 - val_loss: 0.7009 - val_acc: 0.8097\n",
      "Epoch 1240/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5457 - acc: 0.8420 - val_loss: 0.7013 - val_acc: 0.8094\n",
      "Epoch 1241/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5456 - acc: 0.8423 - val_loss: 0.7016 - val_acc: 0.8095\n",
      "Epoch 1242/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5457 - acc: 0.8418 - val_loss: 0.7010 - val_acc: 0.8094\n",
      "Epoch 1243/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5455 - acc: 0.8420 - val_loss: 0.7008 - val_acc: 0.8100\n",
      "Epoch 1244/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5454 - acc: 0.8419 - val_loss: 0.7012 - val_acc: 0.8088\n",
      "Epoch 1245/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5455 - acc: 0.8421 - val_loss: 0.7015 - val_acc: 0.8091\n",
      "Epoch 1246/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5454 - acc: 0.8414 - val_loss: 0.7012 - val_acc: 0.8096\n",
      "Epoch 1247/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5458 - acc: 0.8417 - val_loss: 0.7000 - val_acc: 0.8106\n",
      "Epoch 1248/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5454 - acc: 0.8415 - val_loss: 0.7006 - val_acc: 0.8104\n",
      "Epoch 1249/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5457 - acc: 0.8412 - val_loss: 0.7003 - val_acc: 0.8110\n",
      "Epoch 1250/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5451 - acc: 0.8415 - val_loss: 0.7007 - val_acc: 0.8099\n",
      "Epoch 1251/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5453 - acc: 0.8417 - val_loss: 0.7013 - val_acc: 0.8092\n",
      "Epoch 1252/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5450 - acc: 0.8409 - val_loss: 0.7010 - val_acc: 0.8094\n",
      "Epoch 1253/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5453 - acc: 0.8423 - val_loss: 0.7022 - val_acc: 0.8082\n",
      "Epoch 1254/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5454 - acc: 0.8415 - val_loss: 0.7007 - val_acc: 0.8098\n",
      "Epoch 1255/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5453 - acc: 0.8419 - val_loss: 0.6995 - val_acc: 0.8107\n",
      "Epoch 1256/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5448 - acc: 0.8419 - val_loss: 0.7021 - val_acc: 0.8092\n",
      "Epoch 1257/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5452 - acc: 0.8426 - val_loss: 0.7010 - val_acc: 0.8104\n",
      "Epoch 1258/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5452 - acc: 0.8413 - val_loss: 0.7009 - val_acc: 0.8097\n",
      "Epoch 1259/2000\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.5450 - acc: 0.8416 - val_loss: 0.6998 - val_acc: 0.8106\n",
      "Epoch 1260/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5449 - acc: 0.8422 - val_loss: 0.7005 - val_acc: 0.8098\n",
      "Epoch 1261/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5454 - acc: 0.8408 - val_loss: 0.6996 - val_acc: 0.8106\n",
      "Epoch 1262/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5447 - acc: 0.8425 - val_loss: 0.7015 - val_acc: 0.8091\n",
      "Epoch 1263/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5452 - acc: 0.8410 - val_loss: 0.7009 - val_acc: 0.8091\n",
      "Epoch 1264/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5448 - acc: 0.8421 - val_loss: 0.7022 - val_acc: 0.8094\n",
      "Epoch 1265/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5448 - acc: 0.8421 - val_loss: 0.7008 - val_acc: 0.8088\n",
      "Epoch 1266/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5447 - acc: 0.8413 - val_loss: 0.6996 - val_acc: 0.8103\n",
      "Epoch 1267/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5448 - acc: 0.8417 - val_loss: 0.7014 - val_acc: 0.8084\n",
      "Epoch 1268/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5447 - acc: 0.8422 - val_loss: 0.7010 - val_acc: 0.8094\n",
      "Epoch 1269/2000\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.5450 - acc: 0.8420 - val_loss: 0.7004 - val_acc: 0.8100\n",
      "Epoch 1270/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5445 - acc: 0.8417 - val_loss: 0.7008 - val_acc: 0.8103\n",
      "Epoch 1271/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5445 - acc: 0.8413 - val_loss: 0.7004 - val_acc: 0.8098\n",
      "Epoch 1272/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5447 - acc: 0.8420 - val_loss: 0.7003 - val_acc: 0.8097\n",
      "Epoch 1273/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5443 - acc: 0.8421 - val_loss: 0.7012 - val_acc: 0.8092\n",
      "Epoch 1274/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5446 - acc: 0.8427 - val_loss: 0.7004 - val_acc: 0.8099\n",
      "Epoch 1275/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5446 - acc: 0.8419 - val_loss: 0.7003 - val_acc: 0.8099\n",
      "Epoch 1276/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5446 - acc: 0.8417 - val_loss: 0.7013 - val_acc: 0.8111\n",
      "Epoch 1277/2000\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.5445 - acc: 0.8419 - val_loss: 0.7012 - val_acc: 0.8097\n",
      "Epoch 1278/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5443 - acc: 0.8418 - val_loss: 0.7014 - val_acc: 0.8094\n",
      "Epoch 1279/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5443 - acc: 0.8423 - val_loss: 0.7014 - val_acc: 0.8099\n",
      "Epoch 1280/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5444 - acc: 0.8415 - val_loss: 0.7008 - val_acc: 0.8101\n",
      "Epoch 1281/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5441 - acc: 0.8417 - val_loss: 0.7011 - val_acc: 0.8095\n",
      "Epoch 1282/2000\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.5443 - acc: 0.8418 - val_loss: 0.7001 - val_acc: 0.8099\n",
      "Epoch 1283/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5442 - acc: 0.8420 - val_loss: 0.7003 - val_acc: 0.8097\n",
      "Epoch 1284/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5441 - acc: 0.8418 - val_loss: 0.7010 - val_acc: 0.8094\n",
      "Epoch 1285/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5440 - acc: 0.8420 - val_loss: 0.7004 - val_acc: 0.8097\n",
      "Epoch 1286/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5443 - acc: 0.8431 - val_loss: 0.6999 - val_acc: 0.8104\n",
      "Epoch 1287/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5439 - acc: 0.8424 - val_loss: 0.7000 - val_acc: 0.8094\n",
      "Epoch 1288/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5441 - acc: 0.8415 - val_loss: 0.7023 - val_acc: 0.8092\n",
      "Epoch 1289/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5439 - acc: 0.8417 - val_loss: 0.7001 - val_acc: 0.8103\n",
      "Epoch 1290/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5441 - acc: 0.8424 - val_loss: 0.7010 - val_acc: 0.8088\n",
      "Epoch 1291/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5439 - acc: 0.8417 - val_loss: 0.6999 - val_acc: 0.8107\n",
      "Epoch 1292/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5441 - acc: 0.8422 - val_loss: 0.7008 - val_acc: 0.8103\n",
      "Epoch 1293/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5441 - acc: 0.8417 - val_loss: 0.6998 - val_acc: 0.8106\n",
      "Epoch 1294/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5439 - acc: 0.8423 - val_loss: 0.7008 - val_acc: 0.8097\n",
      "Epoch 1295/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5439 - acc: 0.8419 - val_loss: 0.6994 - val_acc: 0.8104\n",
      "Epoch 1296/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5439 - acc: 0.8423 - val_loss: 0.7000 - val_acc: 0.8097\n",
      "Epoch 1297/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5439 - acc: 0.8423 - val_loss: 0.7001 - val_acc: 0.8092\n",
      "Epoch 1298/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5438 - acc: 0.8426 - val_loss: 0.7003 - val_acc: 0.8110\n",
      "Epoch 1299/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5438 - acc: 0.8422 - val_loss: 0.7005 - val_acc: 0.8101\n",
      "Epoch 1300/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5436 - acc: 0.8420 - val_loss: 0.7002 - val_acc: 0.8104\n",
      "Epoch 1301/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5438 - acc: 0.8421 - val_loss: 0.6995 - val_acc: 0.8103\n",
      "Epoch 1303/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5435 - acc: 0.8420 - val_loss: 0.6999 - val_acc: 0.8101\n",
      "Epoch 1304/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5436 - acc: 0.8415 - val_loss: 0.7010 - val_acc: 0.8102\n",
      "Epoch 1305/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5435 - acc: 0.8423 - val_loss: 0.7003 - val_acc: 0.8098\n",
      "Epoch 1306/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5435 - acc: 0.8422 - val_loss: 0.6998 - val_acc: 0.8109\n",
      "Epoch 1307/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5438 - acc: 0.8420 - val_loss: 0.6996 - val_acc: 0.8103\n",
      "Epoch 1308/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5431 - acc: 0.8420 - val_loss: 0.7005 - val_acc: 0.8093\n",
      "Epoch 1309/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5435 - acc: 0.8427 - val_loss: 0.7010 - val_acc: 0.8097\n",
      "Epoch 1310/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5434 - acc: 0.8428 - val_loss: 0.7009 - val_acc: 0.8099\n",
      "Epoch 1311/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5432 - acc: 0.8419 - val_loss: 0.7000 - val_acc: 0.8096\n",
      "Epoch 1312/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5433 - acc: 0.8425 - val_loss: 0.7002 - val_acc: 0.8098\n",
      "Epoch 1313/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5434 - acc: 0.8421 - val_loss: 0.7005 - val_acc: 0.8106\n",
      "Epoch 1314/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5433 - acc: 0.8428 - val_loss: 0.7010 - val_acc: 0.8099\n",
      "Epoch 1315/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5434 - acc: 0.8423 - val_loss: 0.7001 - val_acc: 0.8102\n",
      "Epoch 1316/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5433 - acc: 0.8416 - val_loss: 0.6998 - val_acc: 0.8102\n",
      "Epoch 1317/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5432 - acc: 0.8421 - val_loss: 0.7004 - val_acc: 0.8099\n",
      "Epoch 1318/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5431 - acc: 0.8426 - val_loss: 0.7011 - val_acc: 0.8084\n",
      "Epoch 1319/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5434 - acc: 0.8419 - val_loss: 0.7000 - val_acc: 0.8094\n",
      "Epoch 1320/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5431 - acc: 0.8429 - val_loss: 0.7001 - val_acc: 0.8103\n",
      "Epoch 1321/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5430 - acc: 0.8427 - val_loss: 0.6999 - val_acc: 0.8096\n",
      "Epoch 1322/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5429 - acc: 0.8424 - val_loss: 0.7023 - val_acc: 0.8084\n",
      "Epoch 1323/2000\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 0.5431 - acc: 0.8420 - val_loss: 0.7000 - val_acc: 0.8106\n",
      "Epoch 1324/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5427 - acc: 0.8424 - val_loss: 0.6998 - val_acc: 0.8096\n",
      "Epoch 1325/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5429 - acc: 0.8422 - val_loss: 0.7008 - val_acc: 0.8101\n",
      "Epoch 1326/2000\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 0.5428 - acc: 0.8428 - val_loss: 0.7002 - val_acc: 0.8099\n",
      "Epoch 1327/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5430 - acc: 0.8423 - val_loss: 0.6997 - val_acc: 0.8099\n",
      "Epoch 1328/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5429 - acc: 0.8428 - val_loss: 0.7006 - val_acc: 0.8098\n",
      "Epoch 1329/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5428 - acc: 0.8420 - val_loss: 0.6994 - val_acc: 0.8110\n",
      "Epoch 1330/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5425 - acc: 0.8421 - val_loss: 0.7000 - val_acc: 0.8098\n",
      "Epoch 1331/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5429 - acc: 0.8419 - val_loss: 0.6999 - val_acc: 0.8092\n",
      "Epoch 1332/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5429 - acc: 0.8431 - val_loss: 0.7004 - val_acc: 0.8091\n",
      "Epoch 1333/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5430 - acc: 0.8421 - val_loss: 0.7003 - val_acc: 0.8093\n",
      "Epoch 1334/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5427 - acc: 0.8420 - val_loss: 0.7012 - val_acc: 0.8079\n",
      "Epoch 1335/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5426 - acc: 0.8418 - val_loss: 0.7002 - val_acc: 0.8105\n",
      "Epoch 1336/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5426 - acc: 0.8422 - val_loss: 0.7000 - val_acc: 0.8098\n",
      "Epoch 1337/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5426 - acc: 0.8428 - val_loss: 0.7002 - val_acc: 0.8094\n",
      "Epoch 1338/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5425 - acc: 0.8421 - val_loss: 0.6994 - val_acc: 0.8097\n",
      "Epoch 1339/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5426 - acc: 0.8426 - val_loss: 0.6998 - val_acc: 0.8101\n",
      "Epoch 1340/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5426 - acc: 0.8427 - val_loss: 0.6999 - val_acc: 0.8106\n",
      "Epoch 1341/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5425 - acc: 0.8425 - val_loss: 0.6995 - val_acc: 0.8096\n",
      "Epoch 1342/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5423 - acc: 0.8426 - val_loss: 0.6994 - val_acc: 0.8102\n",
      "Epoch 1343/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5424 - acc: 0.8427 - val_loss: 0.6997 - val_acc: 0.8106\n",
      "Epoch 1344/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5425 - acc: 0.8426 - val_loss: 0.6996 - val_acc: 0.8108\n",
      "Epoch 1345/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5423 - acc: 0.8425 - val_loss: 0.6996 - val_acc: 0.8096\n",
      "Epoch 1346/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5423 - acc: 0.8423 - val_loss: 0.7001 - val_acc: 0.8103\n",
      "Epoch 1347/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5422 - acc: 0.8426 - val_loss: 0.7001 - val_acc: 0.8097\n",
      "Epoch 1348/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5420 - acc: 0.8428 - val_loss: 0.6990 - val_acc: 0.8109\n",
      "Epoch 1349/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5424 - acc: 0.8430 - val_loss: 0.6995 - val_acc: 0.8096\n",
      "Epoch 1350/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5419 - acc: 0.8428 - val_loss: 0.7002 - val_acc: 0.8106\n",
      "Epoch 1351/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5422 - acc: 0.8429 - val_loss: 0.7007 - val_acc: 0.8108\n",
      "Epoch 1352/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5421 - acc: 0.8435 - val_loss: 0.7013 - val_acc: 0.8094\n",
      "Epoch 1353/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5419 - acc: 0.8423 - val_loss: 0.6997 - val_acc: 0.8096\n",
      "Epoch 1354/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5418 - acc: 0.8431 - val_loss: 0.6998 - val_acc: 0.8109\n",
      "Epoch 1355/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5421 - acc: 0.8428 - val_loss: 0.6996 - val_acc: 0.8105\n",
      "Epoch 1356/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5420 - acc: 0.8425 - val_loss: 0.7002 - val_acc: 0.8108\n",
      "Epoch 1357/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5420 - acc: 0.8430 - val_loss: 0.7006 - val_acc: 0.8096\n",
      "Epoch 1358/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5418 - acc: 0.8429 - val_loss: 0.6992 - val_acc: 0.8107\n",
      "Epoch 1359/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5419 - acc: 0.8427 - val_loss: 0.6989 - val_acc: 0.8104\n",
      "Epoch 1360/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5417 - acc: 0.8424 - val_loss: 0.6999 - val_acc: 0.8100\n",
      "Epoch 1361/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5419 - acc: 0.8427 - val_loss: 0.6995 - val_acc: 0.8102\n",
      "Epoch 1362/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5418 - acc: 0.8432 - val_loss: 0.6990 - val_acc: 0.8094\n",
      "Epoch 1363/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5417 - acc: 0.8421 - val_loss: 0.6994 - val_acc: 0.8101\n",
      "Epoch 1364/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5420 - acc: 0.8424 - val_loss: 0.6999 - val_acc: 0.8103\n",
      "Epoch 1365/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5418 - acc: 0.8429 - val_loss: 0.7003 - val_acc: 0.8098\n",
      "Epoch 1366/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5416 - acc: 0.8429 - val_loss: 0.6999 - val_acc: 0.8103\n",
      "Epoch 1367/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5413 - acc: 0.8427 - val_loss: 0.6999 - val_acc: 0.8098\n",
      "Epoch 1368/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5416 - acc: 0.8427 - val_loss: 0.7000 - val_acc: 0.8093\n",
      "Epoch 1369/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5418 - acc: 0.8425 - val_loss: 0.6994 - val_acc: 0.8101\n",
      "Epoch 1370/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5415 - acc: 0.8433 - val_loss: 0.6994 - val_acc: 0.8103\n",
      "Epoch 1371/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5415 - acc: 0.8423 - val_loss: 0.6994 - val_acc: 0.8104\n",
      "Epoch 1372/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5416 - acc: 0.8421 - val_loss: 0.6999 - val_acc: 0.8106\n",
      "Epoch 1373/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5413 - acc: 0.8429 - val_loss: 0.6993 - val_acc: 0.8099\n",
      "Epoch 1374/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5412 - acc: 0.8431 - val_loss: 0.6999 - val_acc: 0.8102\n",
      "Epoch 1375/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5416 - acc: 0.8432 - val_loss: 0.6993 - val_acc: 0.8106\n",
      "Epoch 1376/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5415 - acc: 0.8429 - val_loss: 0.6993 - val_acc: 0.8102\n",
      "Epoch 1377/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5413 - acc: 0.8430 - val_loss: 0.6988 - val_acc: 0.8106\n",
      "Epoch 1378/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5414 - acc: 0.8433 - val_loss: 0.6989 - val_acc: 0.8107\n",
      "Epoch 1379/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5413 - acc: 0.8427 - val_loss: 0.6993 - val_acc: 0.8102\n",
      "Epoch 1380/2000\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.5414 - acc: 0.8430 - val_loss: 0.6988 - val_acc: 0.8103\n",
      "Epoch 1381/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5410 - acc: 0.8429 - val_loss: 0.6994 - val_acc: 0.8106\n",
      "Epoch 1382/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5412 - acc: 0.8428 - val_loss: 0.6991 - val_acc: 0.8107\n",
      "Epoch 1383/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5411 - acc: 0.8431 - val_loss: 0.7001 - val_acc: 0.8108\n",
      "Epoch 1384/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5411 - acc: 0.8435 - val_loss: 0.6993 - val_acc: 0.8105\n",
      "Epoch 1385/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5411 - acc: 0.8430 - val_loss: 0.6987 - val_acc: 0.8101\n",
      "Epoch 1386/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5413 - acc: 0.8429 - val_loss: 0.6993 - val_acc: 0.8103\n",
      "Epoch 1387/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5410 - acc: 0.8431 - val_loss: 0.6991 - val_acc: 0.8107\n",
      "Epoch 1388/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5410 - acc: 0.8432 - val_loss: 0.7000 - val_acc: 0.8097\n",
      "Epoch 1389/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5409 - acc: 0.8429 - val_loss: 0.6991 - val_acc: 0.8103\n",
      "Epoch 1390/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5408 - acc: 0.8426 - val_loss: 0.7000 - val_acc: 0.8102\n",
      "Epoch 1391/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5411 - acc: 0.8429 - val_loss: 0.6995 - val_acc: 0.8104\n",
      "Epoch 1392/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5413 - acc: 0.8425 - val_loss: 0.6997 - val_acc: 0.8096\n",
      "Epoch 1393/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5411 - acc: 0.8428 - val_loss: 0.6989 - val_acc: 0.8108\n",
      "Epoch 1394/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5409 - acc: 0.8429 - val_loss: 0.6999 - val_acc: 0.8107\n",
      "Epoch 1395/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5407 - acc: 0.8433 - val_loss: 0.6989 - val_acc: 0.8104\n",
      "Epoch 1396/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5407 - acc: 0.8427 - val_loss: 0.6991 - val_acc: 0.8108\n",
      "Epoch 1397/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5407 - acc: 0.8429 - val_loss: 0.6993 - val_acc: 0.8109\n",
      "Epoch 1398/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5407 - acc: 0.8430 - val_loss: 0.6996 - val_acc: 0.8103\n",
      "Epoch 1399/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5408 - acc: 0.8426 - val_loss: 0.6994 - val_acc: 0.8096\n",
      "Epoch 1400/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5408 - acc: 0.8427 - val_loss: 0.6987 - val_acc: 0.8106\n",
      "Epoch 1401/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5409 - acc: 0.8430 - val_loss: 0.6991 - val_acc: 0.8105\n",
      "Epoch 1402/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5407 - acc: 0.8431 - val_loss: 0.6993 - val_acc: 0.8103\n",
      "Epoch 1403/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5407 - acc: 0.8428 - val_loss: 0.6996 - val_acc: 0.8107\n",
      "Epoch 1404/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5406 - acc: 0.8430 - val_loss: 0.7000 - val_acc: 0.8096\n",
      "Epoch 1405/2000\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 0.5408 - acc: 0.8432 - val_loss: 0.6994 - val_acc: 0.8101\n",
      "Epoch 1406/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5406 - acc: 0.8430 - val_loss: 0.6997 - val_acc: 0.8104\n",
      "Epoch 1407/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5406 - acc: 0.8434 - val_loss: 0.6994 - val_acc: 0.8103\n",
      "Epoch 1408/2000\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 0.5403 - acc: 0.8427 - val_loss: 0.6987 - val_acc: 0.8101\n",
      "Epoch 1409/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5403 - acc: 0.8432 - val_loss: 0.6988 - val_acc: 0.8112\n",
      "Epoch 1410/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5405 - acc: 0.8437 - val_loss: 0.6988 - val_acc: 0.8112\n",
      "Epoch 1411/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5401 - acc: 0.8436 - val_loss: 0.6999 - val_acc: 0.8100\n",
      "Epoch 1412/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5405 - acc: 0.8433 - val_loss: 0.6992 - val_acc: 0.8106\n",
      "Epoch 1413/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5402 - acc: 0.8429 - val_loss: 0.6986 - val_acc: 0.8107\n",
      "Epoch 1414/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5403 - acc: 0.8433 - val_loss: 0.6992 - val_acc: 0.8108\n",
      "Epoch 1415/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5405 - acc: 0.8436 - val_loss: 0.6988 - val_acc: 0.8101\n",
      "Epoch 1416/2000\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 0.5402 - acc: 0.8433 - val_loss: 0.6992 - val_acc: 0.8096\n",
      "Epoch 1417/2000\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.5401 - acc: 0.8433 - val_loss: 0.6993 - val_acc: 0.8108\n",
      "Epoch 1418/2000\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.5401 - acc: 0.8430 - val_loss: 0.7005 - val_acc: 0.8099\n",
      "Epoch 1419/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5402 - acc: 0.8434 - val_loss: 0.6997 - val_acc: 0.8107\n",
      "Epoch 1420/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5403 - acc: 0.8436 - val_loss: 0.6995 - val_acc: 0.8100\n",
      "Epoch 1421/2000\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.5401 - acc: 0.8435 - val_loss: 0.6991 - val_acc: 0.8104\n",
      "Epoch 1422/2000\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.5400 - acc: 0.8429 - val_loss: 0.6988 - val_acc: 0.8101\n",
      "Epoch 1423/2000\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.5400 - acc: 0.8435 - val_loss: 0.6987 - val_acc: 0.8102\n",
      "Epoch 1424/2000\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.5401 - acc: 0.8434 - val_loss: 0.6998 - val_acc: 0.8103\n",
      "Epoch 1425/2000\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.5399 - acc: 0.8438 - val_loss: 0.6994 - val_acc: 0.8097\n",
      "Epoch 1426/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5400 - acc: 0.8434 - val_loss: 0.6992 - val_acc: 0.8112\n",
      "Epoch 1427/2000\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 0.5400 - acc: 0.8430 - val_loss: 0.6989 - val_acc: 0.8097\n",
      "Epoch 1428/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5401 - acc: 0.8431 - val_loss: 0.6988 - val_acc: 0.8114\n",
      "Epoch 1429/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5399 - acc: 0.8432 - val_loss: 0.6992 - val_acc: 0.8103\n",
      "Epoch 1430/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5401 - acc: 0.8434 - val_loss: 0.6988 - val_acc: 0.8105\n",
      "Epoch 1431/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5397 - acc: 0.8439 - val_loss: 0.7002 - val_acc: 0.8093\n",
      "Epoch 1432/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5398 - acc: 0.8440 - val_loss: 0.6994 - val_acc: 0.8100\n",
      "Epoch 1433/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5401 - acc: 0.8430 - val_loss: 0.6991 - val_acc: 0.8103\n",
      "Epoch 1434/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5398 - acc: 0.8429 - val_loss: 0.6989 - val_acc: 0.8107\n",
      "Epoch 1435/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5397 - acc: 0.8434 - val_loss: 0.7002 - val_acc: 0.8093\n",
      "Epoch 1436/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5397 - acc: 0.8430 - val_loss: 0.6996 - val_acc: 0.8102\n",
      "Epoch 1437/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5396 - acc: 0.8432 - val_loss: 0.6987 - val_acc: 0.8104\n",
      "Epoch 1438/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5396 - acc: 0.8434 - val_loss: 0.6987 - val_acc: 0.8111\n",
      "Epoch 1439/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5397 - acc: 0.8436 - val_loss: 0.6990 - val_acc: 0.8103\n",
      "Epoch 1440/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5394 - acc: 0.8434 - val_loss: 0.6998 - val_acc: 0.8110\n",
      "Epoch 1441/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5392 - acc: 0.8440 - val_loss: 0.6990 - val_acc: 0.8113\n",
      "Epoch 1442/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5395 - acc: 0.8430 - val_loss: 0.6987 - val_acc: 0.8116\n",
      "Epoch 1443/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5395 - acc: 0.8433 - val_loss: 0.6984 - val_acc: 0.8102\n",
      "Epoch 1444/2000\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 0.5394 - acc: 0.8434 - val_loss: 0.6993 - val_acc: 0.8103\n",
      "Epoch 1445/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5397 - acc: 0.8430 - val_loss: 0.6993 - val_acc: 0.8110\n",
      "Epoch 1446/2000\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 0.5397 - acc: 0.8436 - val_loss: 0.6991 - val_acc: 0.8108\n",
      "Epoch 1447/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5393 - acc: 0.8431 - val_loss: 0.6995 - val_acc: 0.8113\n",
      "Epoch 1448/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5395 - acc: 0.8434 - val_loss: 0.6982 - val_acc: 0.8119\n",
      "Epoch 1449/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5394 - acc: 0.8433 - val_loss: 0.6993 - val_acc: 0.8103\n",
      "Epoch 1450/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5393 - acc: 0.8434 - val_loss: 0.6987 - val_acc: 0.8100\n",
      "Epoch 1451/2000\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 0.5394 - acc: 0.8437 - val_loss: 0.6988 - val_acc: 0.8114\n",
      "Epoch 1452/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5393 - acc: 0.8435 - val_loss: 0.6985 - val_acc: 0.8105\n",
      "Epoch 1453/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5393 - acc: 0.8434 - val_loss: 0.6985 - val_acc: 0.8115\n",
      "Epoch 1454/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5392 - acc: 0.8438 - val_loss: 0.6984 - val_acc: 0.8105\n",
      "Epoch 1455/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5392 - acc: 0.8435 - val_loss: 0.6984 - val_acc: 0.8109\n",
      "Epoch 1456/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5392 - acc: 0.8431 - val_loss: 0.6992 - val_acc: 0.8106\n",
      "Epoch 1457/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5389 - acc: 0.8430 - val_loss: 0.6988 - val_acc: 0.8112\n",
      "Epoch 1458/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5391 - acc: 0.8439 - val_loss: 0.6985 - val_acc: 0.8110\n",
      "Epoch 1459/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5389 - acc: 0.8444 - val_loss: 0.6992 - val_acc: 0.8107\n",
      "Epoch 1460/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5389 - acc: 0.8438 - val_loss: 0.6983 - val_acc: 0.8109\n",
      "Epoch 1461/2000\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.5391 - acc: 0.8448 - val_loss: 0.6993 - val_acc: 0.8106\n",
      "Epoch 1462/2000\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.5390 - acc: 0.8436 - val_loss: 0.6990 - val_acc: 0.8112\n",
      "Epoch 1463/2000\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.5388 - acc: 0.8436 - val_loss: 0.6982 - val_acc: 0.8106\n",
      "Epoch 1464/2000\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.5390 - acc: 0.8442 - val_loss: 0.6978 - val_acc: 0.8113\n",
      "Epoch 1465/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5389 - acc: 0.8430 - val_loss: 0.6978 - val_acc: 0.8113\n",
      "Epoch 1466/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5389 - acc: 0.8436 - val_loss: 0.6986 - val_acc: 0.8108\n",
      "Epoch 1467/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5388 - acc: 0.8432 - val_loss: 0.6985 - val_acc: 0.8114\n",
      "Epoch 1468/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5387 - acc: 0.8438 - val_loss: 0.6989 - val_acc: 0.8103\n",
      "Epoch 1469/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5391 - acc: 0.8439 - val_loss: 0.6981 - val_acc: 0.8112\n",
      "Epoch 1470/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5386 - acc: 0.8441 - val_loss: 0.6986 - val_acc: 0.8111\n",
      "Epoch 1471/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5388 - acc: 0.8435 - val_loss: 0.6989 - val_acc: 0.8102\n",
      "Epoch 1472/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5386 - acc: 0.8439 - val_loss: 0.6986 - val_acc: 0.8112\n",
      "Epoch 1473/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5386 - acc: 0.8438 - val_loss: 0.6988 - val_acc: 0.8108\n",
      "Epoch 1474/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5387 - acc: 0.8441 - val_loss: 0.6990 - val_acc: 0.8103\n",
      "Epoch 1475/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5387 - acc: 0.8441 - val_loss: 0.6986 - val_acc: 0.8099\n",
      "Epoch 1476/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5385 - acc: 0.8444 - val_loss: 0.6984 - val_acc: 0.8108\n",
      "Epoch 1477/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5387 - acc: 0.8441 - val_loss: 0.6983 - val_acc: 0.8102\n",
      "Epoch 1478/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5386 - acc: 0.8440 - val_loss: 0.6983 - val_acc: 0.8107\n",
      "Epoch 1479/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5386 - acc: 0.8435 - val_loss: 0.6983 - val_acc: 0.8115\n",
      "Epoch 1480/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5384 - acc: 0.8441 - val_loss: 0.6992 - val_acc: 0.8102\n",
      "Epoch 1481/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5384 - acc: 0.8440 - val_loss: 0.6992 - val_acc: 0.8108\n",
      "Epoch 1482/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5384 - acc: 0.8434 - val_loss: 0.6988 - val_acc: 0.8109\n",
      "Epoch 1483/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5384 - acc: 0.8440 - val_loss: 0.6982 - val_acc: 0.8106\n",
      "Epoch 1484/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5383 - acc: 0.8443 - val_loss: 0.6983 - val_acc: 0.8114\n",
      "Epoch 1485/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5383 - acc: 0.8439 - val_loss: 0.6987 - val_acc: 0.8107\n",
      "Epoch 1486/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5382 - acc: 0.8436 - val_loss: 0.6981 - val_acc: 0.8118\n",
      "Epoch 1487/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5384 - acc: 0.8442 - val_loss: 0.6988 - val_acc: 0.8112\n",
      "Epoch 1488/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5381 - acc: 0.8443 - val_loss: 0.6986 - val_acc: 0.8109\n",
      "Epoch 1489/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5381 - acc: 0.8442 - val_loss: 0.6985 - val_acc: 0.8112\n",
      "Epoch 1490/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5381 - acc: 0.8443 - val_loss: 0.6981 - val_acc: 0.8105\n",
      "Epoch 1491/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5383 - acc: 0.8439 - val_loss: 0.6995 - val_acc: 0.8099\n",
      "Epoch 1492/2000\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 0.5381 - acc: 0.8432 - val_loss: 0.6983 - val_acc: 0.8107\n",
      "Epoch 1493/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5381 - acc: 0.8439 - val_loss: 0.6989 - val_acc: 0.8104\n",
      "Epoch 1494/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5382 - acc: 0.8447 - val_loss: 0.6985 - val_acc: 0.8112\n",
      "Epoch 1495/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5383 - acc: 0.8440 - val_loss: 0.6990 - val_acc: 0.8106\n",
      "Epoch 1496/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5380 - acc: 0.8445 - val_loss: 0.6979 - val_acc: 0.8108\n",
      "Epoch 1497/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5380 - acc: 0.8439 - val_loss: 0.6981 - val_acc: 0.8108\n",
      "Epoch 1498/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5381 - acc: 0.8437 - val_loss: 0.6981 - val_acc: 0.8112\n",
      "Epoch 1499/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5379 - acc: 0.8446 - val_loss: 0.6985 - val_acc: 0.8116\n",
      "Epoch 1500/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5378 - acc: 0.8440 - val_loss: 0.6993 - val_acc: 0.8104\n",
      "Epoch 1501/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5378 - acc: 0.8439 - val_loss: 0.6979 - val_acc: 0.8112\n",
      "Epoch 1502/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5379 - acc: 0.8443 - val_loss: 0.7000 - val_acc: 0.8099\n",
      "Epoch 1503/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5379 - acc: 0.8439 - val_loss: 0.6985 - val_acc: 0.8110\n",
      "Epoch 1504/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5378 - acc: 0.8440 - val_loss: 0.6985 - val_acc: 0.8109\n",
      "Epoch 1505/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5378 - acc: 0.8440 - val_loss: 0.6981 - val_acc: 0.8114\n",
      "Epoch 1506/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5378 - acc: 0.8442 - val_loss: 0.6991 - val_acc: 0.8112\n",
      "Epoch 1507/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5378 - acc: 0.8440 - val_loss: 0.6979 - val_acc: 0.8111\n",
      "Epoch 1508/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5377 - acc: 0.8446 - val_loss: 0.6987 - val_acc: 0.8109\n",
      "Epoch 1509/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5377 - acc: 0.8440 - val_loss: 0.6987 - val_acc: 0.8114\n",
      "Epoch 1510/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5378 - acc: 0.8439 - val_loss: 0.6980 - val_acc: 0.8117\n",
      "Epoch 1511/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5378 - acc: 0.8446 - val_loss: 0.6990 - val_acc: 0.8106\n",
      "Epoch 1512/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5375 - acc: 0.8444 - val_loss: 0.6980 - val_acc: 0.8103\n",
      "Epoch 1513/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5376 - acc: 0.8443 - val_loss: 0.6990 - val_acc: 0.8109\n",
      "Epoch 1514/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5374 - acc: 0.8441 - val_loss: 0.6990 - val_acc: 0.8108\n",
      "Epoch 1515/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5376 - acc: 0.8440 - val_loss: 0.6983 - val_acc: 0.8107\n",
      "Epoch 1516/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5376 - acc: 0.8442 - val_loss: 0.6980 - val_acc: 0.8118\n",
      "Epoch 1517/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5376 - acc: 0.8444 - val_loss: 0.6978 - val_acc: 0.8106\n",
      "Epoch 1518/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5372 - acc: 0.8442 - val_loss: 0.6992 - val_acc: 0.8103\n",
      "Epoch 1519/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5372 - acc: 0.8449 - val_loss: 0.6992 - val_acc: 0.8116\n",
      "Epoch 1520/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5376 - acc: 0.8437 - val_loss: 0.6995 - val_acc: 0.8103\n",
      "Epoch 1521/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5375 - acc: 0.8440 - val_loss: 0.6978 - val_acc: 0.8110\n",
      "Epoch 1522/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5373 - acc: 0.8443 - val_loss: 0.6983 - val_acc: 0.8107\n",
      "Epoch 1523/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5375 - acc: 0.8441 - val_loss: 0.6991 - val_acc: 0.8107\n",
      "Epoch 1524/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5373 - acc: 0.8438 - val_loss: 0.6982 - val_acc: 0.8106\n",
      "Epoch 1525/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5372 - acc: 0.8438 - val_loss: 0.6985 - val_acc: 0.8111\n",
      "Epoch 1526/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5376 - acc: 0.8442 - val_loss: 0.6989 - val_acc: 0.8103\n",
      "Epoch 1527/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5373 - acc: 0.8451 - val_loss: 0.6993 - val_acc: 0.8105\n",
      "Epoch 1528/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5372 - acc: 0.8443 - val_loss: 0.6990 - val_acc: 0.8116\n",
      "Epoch 1529/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5374 - acc: 0.8440 - val_loss: 0.6981 - val_acc: 0.8112\n",
      "Epoch 1530/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5372 - acc: 0.8440 - val_loss: 0.6988 - val_acc: 0.8110\n",
      "Epoch 1531/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5370 - acc: 0.8440 - val_loss: 0.6980 - val_acc: 0.8113\n",
      "Epoch 1532/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5371 - acc: 0.8446 - val_loss: 0.6983 - val_acc: 0.8112\n",
      "Epoch 1533/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5370 - acc: 0.8441 - val_loss: 0.6985 - val_acc: 0.8099\n",
      "Epoch 1534/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5370 - acc: 0.8439 - val_loss: 0.6978 - val_acc: 0.8114\n",
      "Epoch 1535/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5374 - acc: 0.8445 - val_loss: 0.6981 - val_acc: 0.8107\n",
      "Epoch 1536/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5371 - acc: 0.8439 - val_loss: 0.6985 - val_acc: 0.8113\n",
      "Epoch 1537/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5369 - acc: 0.8445 - val_loss: 0.6984 - val_acc: 0.8105\n",
      "Epoch 1538/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5365 - acc: 0.8448 - val_loss: 0.6983 - val_acc: 0.8108\n",
      "Epoch 1539/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5368 - acc: 0.8444 - val_loss: 0.6982 - val_acc: 0.8110\n",
      "Epoch 1540/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5368 - acc: 0.8441 - val_loss: 0.6982 - val_acc: 0.8112\n",
      "Epoch 1541/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5369 - acc: 0.8443 - val_loss: 0.6975 - val_acc: 0.8113\n",
      "Epoch 1542/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5367 - acc: 0.8447 - val_loss: 0.6980 - val_acc: 0.8116\n",
      "Epoch 1543/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5367 - acc: 0.8444 - val_loss: 0.6977 - val_acc: 0.8106\n",
      "Epoch 1544/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5367 - acc: 0.8447 - val_loss: 0.6979 - val_acc: 0.8107\n",
      "Epoch 1545/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5367 - acc: 0.8445 - val_loss: 0.6979 - val_acc: 0.8116\n",
      "Epoch 1546/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5366 - acc: 0.8444 - val_loss: 0.6983 - val_acc: 0.8109\n",
      "Epoch 1547/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5365 - acc: 0.8443 - val_loss: 0.6987 - val_acc: 0.8109\n",
      "Epoch 1548/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5368 - acc: 0.8445 - val_loss: 0.6984 - val_acc: 0.8115\n",
      "Epoch 1549/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5367 - acc: 0.8445 - val_loss: 0.6970 - val_acc: 0.8113\n",
      "Epoch 1550/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5364 - acc: 0.8448 - val_loss: 0.6980 - val_acc: 0.8113\n",
      "Epoch 1551/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5365 - acc: 0.8446 - val_loss: 0.6980 - val_acc: 0.8108\n",
      "Epoch 1552/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5367 - acc: 0.8442 - val_loss: 0.6979 - val_acc: 0.8107\n",
      "Epoch 1553/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5365 - acc: 0.8447 - val_loss: 0.6973 - val_acc: 0.8112\n",
      "Epoch 1554/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5365 - acc: 0.8435 - val_loss: 0.6995 - val_acc: 0.8105\n",
      "Epoch 1555/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5365 - acc: 0.8452 - val_loss: 0.6979 - val_acc: 0.8111\n",
      "Epoch 1556/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5367 - acc: 0.8448 - val_loss: 0.6980 - val_acc: 0.8111\n",
      "Epoch 1557/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5365 - acc: 0.8438 - val_loss: 0.6980 - val_acc: 0.8117\n",
      "Epoch 1558/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5367 - acc: 0.8447 - val_loss: 0.6979 - val_acc: 0.8106\n",
      "Epoch 1559/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5364 - acc: 0.8442 - val_loss: 0.6982 - val_acc: 0.8112\n",
      "Epoch 1560/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5364 - acc: 0.8447 - val_loss: 0.6977 - val_acc: 0.8110\n",
      "Epoch 1561/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5362 - acc: 0.8450 - val_loss: 0.6982 - val_acc: 0.8116\n",
      "Epoch 1562/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5364 - acc: 0.8450 - val_loss: 0.6970 - val_acc: 0.8108\n",
      "Epoch 1563/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5364 - acc: 0.8444 - val_loss: 0.6985 - val_acc: 0.8102\n",
      "Epoch 1564/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5362 - acc: 0.8443 - val_loss: 0.6975 - val_acc: 0.8114\n",
      "Epoch 1565/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5363 - acc: 0.8440 - val_loss: 0.6980 - val_acc: 0.8114\n",
      "Epoch 1566/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5363 - acc: 0.8448 - val_loss: 0.6976 - val_acc: 0.8111\n",
      "Epoch 1567/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5362 - acc: 0.8447 - val_loss: 0.6985 - val_acc: 0.8111\n",
      "Epoch 1568/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5361 - acc: 0.8441 - val_loss: 0.6976 - val_acc: 0.8114\n",
      "Epoch 1569/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5362 - acc: 0.8446 - val_loss: 0.6976 - val_acc: 0.8122\n",
      "Epoch 1570/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5361 - acc: 0.8445 - val_loss: 0.6973 - val_acc: 0.8112\n",
      "Epoch 1571/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5363 - acc: 0.8439 - val_loss: 0.6985 - val_acc: 0.8108\n",
      "Epoch 1572/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5361 - acc: 0.8447 - val_loss: 0.6982 - val_acc: 0.8105\n",
      "Epoch 1573/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5360 - acc: 0.8448 - val_loss: 0.6978 - val_acc: 0.8116\n",
      "Epoch 1574/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5359 - acc: 0.8447 - val_loss: 0.6974 - val_acc: 0.8114\n",
      "Epoch 1575/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5360 - acc: 0.8448 - val_loss: 0.6982 - val_acc: 0.8109\n",
      "Epoch 1576/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5360 - acc: 0.8441 - val_loss: 0.6981 - val_acc: 0.8107\n",
      "Epoch 1577/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5360 - acc: 0.8452 - val_loss: 0.6981 - val_acc: 0.8108\n",
      "Epoch 1578/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5359 - acc: 0.8450 - val_loss: 0.6981 - val_acc: 0.8114\n",
      "Epoch 1579/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5360 - acc: 0.8443 - val_loss: 0.6977 - val_acc: 0.8114\n",
      "Epoch 1580/2000\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 0.5359 - acc: 0.8450 - val_loss: 0.6975 - val_acc: 0.8122\n",
      "Epoch 1581/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5358 - acc: 0.8449 - val_loss: 0.6971 - val_acc: 0.8112\n",
      "Epoch 1582/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5357 - acc: 0.8448 - val_loss: 0.6980 - val_acc: 0.8114\n",
      "Epoch 1583/2000\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.5358 - acc: 0.8451 - val_loss: 0.6977 - val_acc: 0.8113\n",
      "Epoch 1584/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5357 - acc: 0.8448 - val_loss: 0.6974 - val_acc: 0.8120\n",
      "Epoch 1585/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5359 - acc: 0.8445 - val_loss: 0.6977 - val_acc: 0.8111\n",
      "Epoch 1586/2000\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.5358 - acc: 0.8447 - val_loss: 0.6973 - val_acc: 0.8113\n",
      "Epoch 1587/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5358 - acc: 0.8447 - val_loss: 0.6980 - val_acc: 0.8113\n",
      "Epoch 1588/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5355 - acc: 0.8451 - val_loss: 0.6978 - val_acc: 0.8111\n",
      "Epoch 1589/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5358 - acc: 0.8450 - val_loss: 0.6972 - val_acc: 0.8118\n",
      "Epoch 1590/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5357 - acc: 0.8449 - val_loss: 0.6972 - val_acc: 0.8121\n",
      "Epoch 1591/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5356 - acc: 0.8447 - val_loss: 0.6971 - val_acc: 0.8118\n",
      "Epoch 1592/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5356 - acc: 0.8443 - val_loss: 0.6981 - val_acc: 0.8111\n",
      "Epoch 1593/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5358 - acc: 0.8447 - val_loss: 0.6978 - val_acc: 0.8112\n",
      "Epoch 1594/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5357 - acc: 0.8443 - val_loss: 0.6979 - val_acc: 0.8112\n",
      "Epoch 1595/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5354 - acc: 0.8448 - val_loss: 0.6977 - val_acc: 0.8109\n",
      "Epoch 1596/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5353 - acc: 0.8450 - val_loss: 0.6980 - val_acc: 0.8122\n",
      "Epoch 1597/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5356 - acc: 0.8449 - val_loss: 0.6976 - val_acc: 0.8113\n",
      "Epoch 1598/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5353 - acc: 0.8451 - val_loss: 0.6975 - val_acc: 0.8121\n",
      "Epoch 1599/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5356 - acc: 0.8444 - val_loss: 0.6974 - val_acc: 0.8109\n",
      "Epoch 1600/2000\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 0.5356 - acc: 0.8445 - val_loss: 0.6971 - val_acc: 0.8117\n",
      "Epoch 1601/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5353 - acc: 0.8455 - val_loss: 0.6976 - val_acc: 0.8115\n",
      "Epoch 1602/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5352 - acc: 0.8446 - val_loss: 0.6980 - val_acc: 0.8113\n",
      "Epoch 1603/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5354 - acc: 0.8450 - val_loss: 0.6981 - val_acc: 0.8111\n",
      "Epoch 1604/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5351 - acc: 0.8449 - val_loss: 0.6984 - val_acc: 0.8114\n",
      "Epoch 1605/2000\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 0.5355 - acc: 0.8445 - val_loss: 0.6987 - val_acc: 0.8102\n",
      "Epoch 1606/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5352 - acc: 0.8447 - val_loss: 0.6981 - val_acc: 0.8113\n",
      "Epoch 1607/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5353 - acc: 0.8451 - val_loss: 0.6975 - val_acc: 0.8114\n",
      "Epoch 1608/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5350 - acc: 0.8451 - val_loss: 0.6979 - val_acc: 0.8118\n",
      "Epoch 1609/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5354 - acc: 0.8446 - val_loss: 0.6981 - val_acc: 0.8111\n",
      "Epoch 1610/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5352 - acc: 0.8445 - val_loss: 0.6973 - val_acc: 0.8114\n",
      "Epoch 1611/2000\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 0.5352 - acc: 0.8445 - val_loss: 0.6983 - val_acc: 0.8109\n",
      "Epoch 1612/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5350 - acc: 0.8447 - val_loss: 0.6972 - val_acc: 0.8110\n",
      "Epoch 1613/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5352 - acc: 0.8446 - val_loss: 0.6978 - val_acc: 0.8115\n",
      "Epoch 1614/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5350 - acc: 0.8449 - val_loss: 0.6967 - val_acc: 0.8118\n",
      "Epoch 1615/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5348 - acc: 0.8449 - val_loss: 0.6981 - val_acc: 0.8112\n",
      "Epoch 1616/2000\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.5351 - acc: 0.8449 - val_loss: 0.6982 - val_acc: 0.8109\n",
      "Epoch 1617/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5347 - acc: 0.8451 - val_loss: 0.6972 - val_acc: 0.8113\n",
      "Epoch 1618/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5349 - acc: 0.8453 - val_loss: 0.6978 - val_acc: 0.8113\n",
      "Epoch 1619/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5349 - acc: 0.8446 - val_loss: 0.6972 - val_acc: 0.8118\n",
      "Epoch 1620/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5348 - acc: 0.8450 - val_loss: 0.6973 - val_acc: 0.8118\n",
      "Epoch 1621/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5348 - acc: 0.8449 - val_loss: 0.6969 - val_acc: 0.8114\n",
      "Epoch 1622/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5347 - acc: 0.8448 - val_loss: 0.6971 - val_acc: 0.8116\n",
      "Epoch 1623/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5348 - acc: 0.8447 - val_loss: 0.6977 - val_acc: 0.8116\n",
      "Epoch 1624/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5349 - acc: 0.8454 - val_loss: 0.6972 - val_acc: 0.8118\n",
      "Epoch 1625/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5347 - acc: 0.8446 - val_loss: 0.6978 - val_acc: 0.8111\n",
      "Epoch 1626/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5350 - acc: 0.8451 - val_loss: 0.6971 - val_acc: 0.8120\n",
      "Epoch 1627/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5346 - acc: 0.8454 - val_loss: 0.6973 - val_acc: 0.8119\n",
      "Epoch 1628/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5345 - acc: 0.8455 - val_loss: 0.6978 - val_acc: 0.8115\n",
      "Epoch 1629/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5348 - acc: 0.8446 - val_loss: 0.6970 - val_acc: 0.8111\n",
      "Epoch 1630/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5347 - acc: 0.8452 - val_loss: 0.6982 - val_acc: 0.8109\n",
      "Epoch 1631/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5345 - acc: 0.8453 - val_loss: 0.6978 - val_acc: 0.8112\n",
      "Epoch 1632/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5348 - acc: 0.8447 - val_loss: 0.6969 - val_acc: 0.8119\n",
      "Epoch 1633/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5349 - acc: 0.8447 - val_loss: 0.6972 - val_acc: 0.8114\n",
      "Epoch 1634/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5349 - acc: 0.8448 - val_loss: 0.6970 - val_acc: 0.8111\n",
      "Epoch 1635/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5346 - acc: 0.8449 - val_loss: 0.6973 - val_acc: 0.8118\n",
      "Epoch 1636/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5344 - acc: 0.8456 - val_loss: 0.6973 - val_acc: 0.8115\n",
      "Epoch 1637/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5347 - acc: 0.8446 - val_loss: 0.6973 - val_acc: 0.8113\n",
      "Epoch 1638/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5345 - acc: 0.8448 - val_loss: 0.6968 - val_acc: 0.8119\n",
      "Epoch 1639/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5345 - acc: 0.8446 - val_loss: 0.6977 - val_acc: 0.8111\n",
      "Epoch 1640/2000\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 0.5345 - acc: 0.8449 - val_loss: 0.6976 - val_acc: 0.8113\n",
      "Epoch 1641/2000\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 0.5341 - acc: 0.8455 - val_loss: 0.6986 - val_acc: 0.8113\n",
      "Epoch 1642/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5347 - acc: 0.8452 - val_loss: 0.6975 - val_acc: 0.8111\n",
      "Epoch 1643/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5345 - acc: 0.8455 - val_loss: 0.6970 - val_acc: 0.8115\n",
      "Epoch 1644/2000\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 0.5343 - acc: 0.8445 - val_loss: 0.6971 - val_acc: 0.8112\n",
      "Epoch 1645/2000\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 0.5344 - acc: 0.8449 - val_loss: 0.6975 - val_acc: 0.8118\n",
      "Epoch 1646/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5343 - acc: 0.8450 - val_loss: 0.6975 - val_acc: 0.8116\n",
      "Epoch 1647/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5341 - acc: 0.8446 - val_loss: 0.6974 - val_acc: 0.8114\n",
      "Epoch 1648/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5343 - acc: 0.8453 - val_loss: 0.6968 - val_acc: 0.8121\n",
      "Epoch 1649/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5342 - acc: 0.8452 - val_loss: 0.6984 - val_acc: 0.8110\n",
      "Epoch 1650/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5342 - acc: 0.8452 - val_loss: 0.6978 - val_acc: 0.8101\n",
      "Epoch 1651/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5340 - acc: 0.8458 - val_loss: 0.6968 - val_acc: 0.8119\n",
      "Epoch 1652/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5342 - acc: 0.8457 - val_loss: 0.6980 - val_acc: 0.8111\n",
      "Epoch 1653/2000\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 0.5342 - acc: 0.8451 - val_loss: 0.6971 - val_acc: 0.8123\n",
      "Epoch 1654/2000\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 0.5340 - acc: 0.8450 - val_loss: 0.6974 - val_acc: 0.8116\n",
      "Epoch 1655/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5342 - acc: 0.8451 - val_loss: 0.6972 - val_acc: 0.8119\n",
      "Epoch 1656/2000\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 0.5339 - acc: 0.8457 - val_loss: 0.6977 - val_acc: 0.8109\n",
      "Epoch 1657/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5341 - acc: 0.8453 - val_loss: 0.6978 - val_acc: 0.8112\n",
      "Epoch 1658/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5341 - acc: 0.8452 - val_loss: 0.6966 - val_acc: 0.8118\n",
      "Epoch 1659/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5339 - acc: 0.8455 - val_loss: 0.6974 - val_acc: 0.8116\n",
      "Epoch 1660/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5338 - acc: 0.8455 - val_loss: 0.6973 - val_acc: 0.8114\n",
      "Epoch 1661/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5340 - acc: 0.8448 - val_loss: 0.6970 - val_acc: 0.8119\n",
      "Epoch 1662/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5336 - acc: 0.8452 - val_loss: 0.6968 - val_acc: 0.8119\n",
      "Epoch 1663/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5339 - acc: 0.8450 - val_loss: 0.6973 - val_acc: 0.8121\n",
      "Epoch 1664/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5339 - acc: 0.8454 - val_loss: 0.6970 - val_acc: 0.8117\n",
      "Epoch 1665/2000\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 0.5338 - acc: 0.8451 - val_loss: 0.6966 - val_acc: 0.8116\n",
      "Epoch 1666/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5338 - acc: 0.8452 - val_loss: 0.6971 - val_acc: 0.8119\n",
      "Epoch 1667/2000\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 0.5338 - acc: 0.8450 - val_loss: 0.6979 - val_acc: 0.8112\n",
      "Epoch 1668/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5338 - acc: 0.8451 - val_loss: 0.6964 - val_acc: 0.8121\n",
      "Epoch 1669/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5339 - acc: 0.8454 - val_loss: 0.6972 - val_acc: 0.8119\n",
      "Epoch 1670/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5335 - acc: 0.8455 - val_loss: 0.6977 - val_acc: 0.8112\n",
      "Epoch 1671/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5334 - acc: 0.8453 - val_loss: 0.6969 - val_acc: 0.8119\n",
      "Epoch 1672/2000\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 0.5337 - acc: 0.8449 - val_loss: 0.6967 - val_acc: 0.8125\n",
      "Epoch 1673/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5336 - acc: 0.8454 - val_loss: 0.6976 - val_acc: 0.8110\n",
      "Epoch 1674/2000\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 0.5336 - acc: 0.8448 - val_loss: 0.6971 - val_acc: 0.8125\n",
      "Epoch 1675/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5336 - acc: 0.8458 - val_loss: 0.6974 - val_acc: 0.8116\n",
      "Epoch 1676/2000\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 0.5338 - acc: 0.8457 - val_loss: 0.6968 - val_acc: 0.8122\n",
      "Epoch 1677/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5337 - acc: 0.8454 - val_loss: 0.6967 - val_acc: 0.8116\n",
      "Epoch 1678/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5335 - acc: 0.8456 - val_loss: 0.6968 - val_acc: 0.8117\n",
      "Epoch 1679/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5332 - acc: 0.8465 - val_loss: 0.6969 - val_acc: 0.8125\n",
      "Epoch 1680/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5336 - acc: 0.8456 - val_loss: 0.6974 - val_acc: 0.8113\n",
      "Epoch 1681/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5335 - acc: 0.8453 - val_loss: 0.6981 - val_acc: 0.8107\n",
      "Epoch 1682/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5335 - acc: 0.8454 - val_loss: 0.6975 - val_acc: 0.8111\n",
      "Epoch 1683/2000\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 0.5335 - acc: 0.8461 - val_loss: 0.6970 - val_acc: 0.8108\n",
      "Epoch 1684/2000\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 0.5334 - acc: 0.8458 - val_loss: 0.6970 - val_acc: 0.8114\n",
      "Epoch 1685/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5334 - acc: 0.8458 - val_loss: 0.6965 - val_acc: 0.8122\n",
      "Epoch 1686/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5332 - acc: 0.8453 - val_loss: 0.6978 - val_acc: 0.8112\n",
      "Epoch 1687/2000\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 0.5335 - acc: 0.8454 - val_loss: 0.6970 - val_acc: 0.8118\n",
      "Epoch 1688/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5333 - acc: 0.8456 - val_loss: 0.6965 - val_acc: 0.8122\n",
      "Epoch 1689/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5335 - acc: 0.8455 - val_loss: 0.6974 - val_acc: 0.8112\n",
      "Epoch 1690/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5332 - acc: 0.8455 - val_loss: 0.6971 - val_acc: 0.8117\n",
      "Epoch 1691/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5332 - acc: 0.8461 - val_loss: 0.6978 - val_acc: 0.8113\n",
      "Epoch 1692/2000\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 0.5331 - acc: 0.8449 - val_loss: 0.6973 - val_acc: 0.8119\n",
      "Epoch 1693/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5332 - acc: 0.8460 - val_loss: 0.6968 - val_acc: 0.8119\n",
      "Epoch 1694/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5330 - acc: 0.8454 - val_loss: 0.6965 - val_acc: 0.8116\n",
      "Epoch 1695/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5329 - acc: 0.8461 - val_loss: 0.6966 - val_acc: 0.8120\n",
      "Epoch 1696/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5330 - acc: 0.8457 - val_loss: 0.6966 - val_acc: 0.8120\n",
      "Epoch 1697/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5331 - acc: 0.8456 - val_loss: 0.6965 - val_acc: 0.8123\n",
      "Epoch 1698/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5332 - acc: 0.8460 - val_loss: 0.6968 - val_acc: 0.8117\n",
      "Epoch 1699/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5332 - acc: 0.8455 - val_loss: 0.6963 - val_acc: 0.8119\n",
      "Epoch 1700/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5330 - acc: 0.8462 - val_loss: 0.6968 - val_acc: 0.8118\n",
      "Epoch 1701/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5330 - acc: 0.8453 - val_loss: 0.6962 - val_acc: 0.8126\n",
      "Epoch 1702/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5329 - acc: 0.8461 - val_loss: 0.6971 - val_acc: 0.8116\n",
      "Epoch 1703/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5329 - acc: 0.8455 - val_loss: 0.6966 - val_acc: 0.8119\n",
      "Epoch 1704/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5329 - acc: 0.8461 - val_loss: 0.6965 - val_acc: 0.8123\n",
      "Epoch 1705/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5329 - acc: 0.8463 - val_loss: 0.6965 - val_acc: 0.8117\n",
      "Epoch 1706/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5329 - acc: 0.8454 - val_loss: 0.6972 - val_acc: 0.8118\n",
      "Epoch 1707/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5329 - acc: 0.8460 - val_loss: 0.6975 - val_acc: 0.8121\n",
      "Epoch 1708/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5329 - acc: 0.8463 - val_loss: 0.6969 - val_acc: 0.8123\n",
      "Epoch 1709/2000\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 0.5328 - acc: 0.8460 - val_loss: 0.6964 - val_acc: 0.8121\n",
      "Epoch 1710/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5327 - acc: 0.8459 - val_loss: 0.6975 - val_acc: 0.8117\n",
      "Epoch 1711/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5329 - acc: 0.8452 - val_loss: 0.6970 - val_acc: 0.8118\n",
      "Epoch 1712/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5327 - acc: 0.8455 - val_loss: 0.6972 - val_acc: 0.8115\n",
      "Epoch 1713/2000\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.5328 - acc: 0.8458 - val_loss: 0.6966 - val_acc: 0.8119\n",
      "Epoch 1714/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5325 - acc: 0.8463 - val_loss: 0.6969 - val_acc: 0.8113\n",
      "Epoch 1715/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5326 - acc: 0.8459 - val_loss: 0.6970 - val_acc: 0.8118\n",
      "Epoch 1716/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5326 - acc: 0.8464 - val_loss: 0.6960 - val_acc: 0.8121\n",
      "Epoch 1717/2000\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.5329 - acc: 0.8455 - val_loss: 0.6964 - val_acc: 0.8121\n",
      "Epoch 1718/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5323 - acc: 0.8459 - val_loss: 0.6968 - val_acc: 0.8119\n",
      "Epoch 1719/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5329 - acc: 0.8453 - val_loss: 0.6969 - val_acc: 0.8115\n",
      "Epoch 1720/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5326 - acc: 0.8455 - val_loss: 0.6983 - val_acc: 0.8117\n",
      "Epoch 1721/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5326 - acc: 0.8456 - val_loss: 0.6965 - val_acc: 0.8122\n",
      "Epoch 1722/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5327 - acc: 0.8459 - val_loss: 0.6975 - val_acc: 0.8108\n",
      "Epoch 1723/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5327 - acc: 0.8460 - val_loss: 0.6967 - val_acc: 0.8117\n",
      "Epoch 1724/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5324 - acc: 0.8460 - val_loss: 0.6969 - val_acc: 0.8123\n",
      "Epoch 1725/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5326 - acc: 0.8455 - val_loss: 0.6965 - val_acc: 0.8117\n",
      "Epoch 1726/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5323 - acc: 0.8456 - val_loss: 0.6966 - val_acc: 0.8122\n",
      "Epoch 1727/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5323 - acc: 0.8456 - val_loss: 0.6968 - val_acc: 0.8117\n",
      "Epoch 1728/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5324 - acc: 0.8455 - val_loss: 0.6968 - val_acc: 0.8124\n",
      "Epoch 1729/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5324 - acc: 0.8457 - val_loss: 0.6966 - val_acc: 0.8114\n",
      "Epoch 1730/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5324 - acc: 0.8457 - val_loss: 0.6964 - val_acc: 0.8124\n",
      "Epoch 1731/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5323 - acc: 0.8459 - val_loss: 0.6962 - val_acc: 0.8122\n",
      "Epoch 1732/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5322 - acc: 0.8460 - val_loss: 0.6981 - val_acc: 0.8105\n",
      "Epoch 1733/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5327 - acc: 0.8454 - val_loss: 0.6964 - val_acc: 0.8114\n",
      "Epoch 1734/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5321 - acc: 0.8462 - val_loss: 0.6970 - val_acc: 0.8109\n",
      "Epoch 1735/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5325 - acc: 0.8464 - val_loss: 0.6964 - val_acc: 0.8119\n",
      "Epoch 1736/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5321 - acc: 0.8461 - val_loss: 0.6970 - val_acc: 0.8121\n",
      "Epoch 1737/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5321 - acc: 0.8462 - val_loss: 0.6970 - val_acc: 0.8116\n",
      "Epoch 1738/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5320 - acc: 0.8456 - val_loss: 0.6964 - val_acc: 0.8121\n",
      "Epoch 1739/2000\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 0.5321 - acc: 0.8461 - val_loss: 0.6963 - val_acc: 0.8114\n",
      "Epoch 1740/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5320 - acc: 0.8460 - val_loss: 0.6969 - val_acc: 0.8115\n",
      "Epoch 1741/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5321 - acc: 0.8462 - val_loss: 0.6963 - val_acc: 0.8121\n",
      "Epoch 1742/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5320 - acc: 0.8462 - val_loss: 0.6969 - val_acc: 0.8118\n",
      "Epoch 1743/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5321 - acc: 0.8462 - val_loss: 0.6962 - val_acc: 0.8121\n",
      "Epoch 1744/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5325 - acc: 0.8460 - val_loss: 0.6964 - val_acc: 0.8119\n",
      "Epoch 1745/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5320 - acc: 0.8462 - val_loss: 0.6971 - val_acc: 0.8112\n",
      "Epoch 1746/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5321 - acc: 0.8459 - val_loss: 0.6965 - val_acc: 0.8116\n",
      "Epoch 1747/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5321 - acc: 0.8461 - val_loss: 0.6964 - val_acc: 0.8117\n",
      "Epoch 1748/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5320 - acc: 0.8464 - val_loss: 0.6968 - val_acc: 0.8111\n",
      "Epoch 1749/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5322 - acc: 0.8462 - val_loss: 0.6976 - val_acc: 0.8116\n",
      "Epoch 1750/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5322 - acc: 0.8466 - val_loss: 0.6970 - val_acc: 0.8111\n",
      "Epoch 1751/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5318 - acc: 0.8460 - val_loss: 0.6963 - val_acc: 0.8121\n",
      "Epoch 1752/2000\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.5320 - acc: 0.8456 - val_loss: 0.6965 - val_acc: 0.8113\n",
      "Epoch 1753/2000\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.5319 - acc: 0.8459 - val_loss: 0.6961 - val_acc: 0.8124\n",
      "Epoch 1754/2000\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.5317 - acc: 0.8462 - val_loss: 0.6967 - val_acc: 0.8124\n",
      "Epoch 1755/2000\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.5317 - acc: 0.8464 - val_loss: 0.6966 - val_acc: 0.8124\n",
      "Epoch 1756/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5319 - acc: 0.8455 - val_loss: 0.6961 - val_acc: 0.8123\n",
      "Epoch 1757/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5318 - acc: 0.8465 - val_loss: 0.6965 - val_acc: 0.8127\n",
      "Epoch 1758/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5317 - acc: 0.8465 - val_loss: 0.6964 - val_acc: 0.8127\n",
      "Epoch 1759/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5318 - acc: 0.8463 - val_loss: 0.6961 - val_acc: 0.8124\n",
      "Epoch 1760/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5319 - acc: 0.8463 - val_loss: 0.6959 - val_acc: 0.8127\n",
      "Epoch 1761/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5318 - acc: 0.8458 - val_loss: 0.6976 - val_acc: 0.8116\n",
      "Epoch 1762/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5316 - acc: 0.8468 - val_loss: 0.6962 - val_acc: 0.8122\n",
      "Epoch 1763/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5317 - acc: 0.8457 - val_loss: 0.6964 - val_acc: 0.8116\n",
      "Epoch 1764/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5315 - acc: 0.8462 - val_loss: 0.6961 - val_acc: 0.8126\n",
      "Epoch 1765/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5315 - acc: 0.8462 - val_loss: 0.6962 - val_acc: 0.8121\n",
      "Epoch 1766/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5315 - acc: 0.8458 - val_loss: 0.6961 - val_acc: 0.8120\n",
      "Epoch 1767/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5314 - acc: 0.8461 - val_loss: 0.6964 - val_acc: 0.8127\n",
      "Epoch 1768/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5318 - acc: 0.8462 - val_loss: 0.6970 - val_acc: 0.8116\n",
      "Epoch 1769/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5314 - acc: 0.8459 - val_loss: 0.6970 - val_acc: 0.8115\n",
      "Epoch 1770/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5315 - acc: 0.8463 - val_loss: 0.6964 - val_acc: 0.8116\n",
      "Epoch 1771/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5318 - acc: 0.8458 - val_loss: 0.6959 - val_acc: 0.8121\n",
      "Epoch 1772/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5316 - acc: 0.8464 - val_loss: 0.6968 - val_acc: 0.8118\n",
      "Epoch 1773/2000\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 0.5315 - acc: 0.8462 - val_loss: 0.6967 - val_acc: 0.8116\n",
      "Epoch 1774/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5313 - acc: 0.8463 - val_loss: 0.6962 - val_acc: 0.8124\n",
      "Epoch 1775/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5313 - acc: 0.8461 - val_loss: 0.6959 - val_acc: 0.8129\n",
      "Epoch 1776/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5312 - acc: 0.8462 - val_loss: 0.6960 - val_acc: 0.8125\n",
      "Epoch 1777/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5314 - acc: 0.8466 - val_loss: 0.6958 - val_acc: 0.8127\n",
      "Epoch 1778/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5313 - acc: 0.8464 - val_loss: 0.6972 - val_acc: 0.8112\n",
      "Epoch 1779/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5315 - acc: 0.8464 - val_loss: 0.6962 - val_acc: 0.8123\n",
      "Epoch 1780/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5312 - acc: 0.8456 - val_loss: 0.6962 - val_acc: 0.8118\n",
      "Epoch 1781/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5314 - acc: 0.8458 - val_loss: 0.6965 - val_acc: 0.8119\n",
      "Epoch 1782/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5314 - acc: 0.8455 - val_loss: 0.6962 - val_acc: 0.8119\n",
      "Epoch 1783/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5310 - acc: 0.8468 - val_loss: 0.6960 - val_acc: 0.8121\n",
      "Epoch 1784/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5312 - acc: 0.8461 - val_loss: 0.6965 - val_acc: 0.8121\n",
      "Epoch 1785/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5311 - acc: 0.8462 - val_loss: 0.6959 - val_acc: 0.8121\n",
      "Epoch 1786/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5314 - acc: 0.8465 - val_loss: 0.6963 - val_acc: 0.8129\n",
      "Epoch 1787/2000\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 0.5311 - acc: 0.8459 - val_loss: 0.6963 - val_acc: 0.8118\n",
      "Epoch 1788/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5310 - acc: 0.8460 - val_loss: 0.6972 - val_acc: 0.8115\n",
      "Epoch 1789/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5309 - acc: 0.8458 - val_loss: 0.6969 - val_acc: 0.8116\n",
      "Epoch 1790/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5310 - acc: 0.8466 - val_loss: 0.6957 - val_acc: 0.8118\n",
      "Epoch 1791/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5312 - acc: 0.8460 - val_loss: 0.6963 - val_acc: 0.8122\n",
      "Epoch 1792/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5309 - acc: 0.8460 - val_loss: 0.6959 - val_acc: 0.8123\n",
      "Epoch 1793/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5310 - acc: 0.8462 - val_loss: 0.6962 - val_acc: 0.8122\n",
      "Epoch 1794/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5311 - acc: 0.8467 - val_loss: 0.6964 - val_acc: 0.8121\n",
      "Epoch 1795/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5310 - acc: 0.8465 - val_loss: 0.6966 - val_acc: 0.8122\n",
      "Epoch 1796/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5308 - acc: 0.8459 - val_loss: 0.6957 - val_acc: 0.8122\n",
      "Epoch 1797/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5308 - acc: 0.8464 - val_loss: 0.6965 - val_acc: 0.8126\n",
      "Epoch 1798/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5309 - acc: 0.8462 - val_loss: 0.6960 - val_acc: 0.8117\n",
      "Epoch 1799/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5310 - acc: 0.8464 - val_loss: 0.6961 - val_acc: 0.8122\n",
      "Epoch 1800/2000\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 0.5306 - acc: 0.8467 - val_loss: 0.6971 - val_acc: 0.8116\n",
      "Epoch 1801/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5310 - acc: 0.8457 - val_loss: 0.6964 - val_acc: 0.8117\n",
      "Epoch 1802/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5309 - acc: 0.8462 - val_loss: 0.6956 - val_acc: 0.8118\n",
      "Epoch 1803/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5306 - acc: 0.8467 - val_loss: 0.6964 - val_acc: 0.8121\n",
      "Epoch 1804/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5308 - acc: 0.8467 - val_loss: 0.6962 - val_acc: 0.8126\n",
      "Epoch 1805/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5305 - acc: 0.8466 - val_loss: 0.6969 - val_acc: 0.8109\n",
      "Epoch 1806/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5305 - acc: 0.8470 - val_loss: 0.6957 - val_acc: 0.8128\n",
      "Epoch 1807/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5305 - acc: 0.8465 - val_loss: 0.6961 - val_acc: 0.8125\n",
      "Epoch 1808/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5307 - acc: 0.8465 - val_loss: 0.6954 - val_acc: 0.8118\n",
      "Epoch 1809/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5305 - acc: 0.8465 - val_loss: 0.6976 - val_acc: 0.8116\n",
      "Epoch 1810/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5306 - acc: 0.8465 - val_loss: 0.6965 - val_acc: 0.8117\n",
      "Epoch 1811/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5305 - acc: 0.8467 - val_loss: 0.6957 - val_acc: 0.8122\n",
      "Epoch 1812/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5307 - acc: 0.8470 - val_loss: 0.6963 - val_acc: 0.8118\n",
      "Epoch 1813/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5305 - acc: 0.8468 - val_loss: 0.6960 - val_acc: 0.8121\n",
      "Epoch 1814/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5306 - acc: 0.8467 - val_loss: 0.6960 - val_acc: 0.8125\n",
      "Epoch 1815/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5305 - acc: 0.8464 - val_loss: 0.6961 - val_acc: 0.8121\n",
      "Epoch 1816/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5305 - acc: 0.8468 - val_loss: 0.6958 - val_acc: 0.8123\n",
      "Epoch 1817/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5304 - acc: 0.8461 - val_loss: 0.6975 - val_acc: 0.8114\n",
      "Epoch 1818/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5308 - acc: 0.8470 - val_loss: 0.6958 - val_acc: 0.8126\n",
      "Epoch 1819/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5303 - acc: 0.8469 - val_loss: 0.6959 - val_acc: 0.8117\n",
      "Epoch 1820/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5304 - acc: 0.8467 - val_loss: 0.6956 - val_acc: 0.8124\n",
      "Epoch 1821/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5303 - acc: 0.8465 - val_loss: 0.6958 - val_acc: 0.8117\n",
      "Epoch 1822/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5303 - acc: 0.8465 - val_loss: 0.6954 - val_acc: 0.8127\n",
      "Epoch 1823/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5303 - acc: 0.8463 - val_loss: 0.6967 - val_acc: 0.8123\n",
      "Epoch 1824/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5303 - acc: 0.8467 - val_loss: 0.6963 - val_acc: 0.8123\n",
      "Epoch 1825/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5302 - acc: 0.8459 - val_loss: 0.6950 - val_acc: 0.8131\n",
      "Epoch 1826/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5302 - acc: 0.8463 - val_loss: 0.6960 - val_acc: 0.8126\n",
      "Epoch 1827/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5302 - acc: 0.8470 - val_loss: 0.6963 - val_acc: 0.8118\n",
      "Epoch 1828/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5301 - acc: 0.8461 - val_loss: 0.6957 - val_acc: 0.8116\n",
      "Epoch 1829/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5304 - acc: 0.8463 - val_loss: 0.6961 - val_acc: 0.8121\n",
      "Epoch 1830/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5301 - acc: 0.8467 - val_loss: 0.6962 - val_acc: 0.8126\n",
      "Epoch 1831/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5301 - acc: 0.8464 - val_loss: 0.6957 - val_acc: 0.8120\n",
      "Epoch 1832/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5301 - acc: 0.8464 - val_loss: 0.6965 - val_acc: 0.8117\n",
      "Epoch 1833/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5301 - acc: 0.8463 - val_loss: 0.6965 - val_acc: 0.8114\n",
      "Epoch 1834/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5300 - acc: 0.8467 - val_loss: 0.6961 - val_acc: 0.8129\n",
      "Epoch 1835/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5301 - acc: 0.8467 - val_loss: 0.6957 - val_acc: 0.8127\n",
      "Epoch 1836/2000\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.5299 - acc: 0.8468 - val_loss: 0.6968 - val_acc: 0.8116\n",
      "Epoch 1837/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5301 - acc: 0.8465 - val_loss: 0.6958 - val_acc: 0.8127\n",
      "Epoch 1838/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5301 - acc: 0.8466 - val_loss: 0.6959 - val_acc: 0.8126\n",
      "Epoch 1839/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5299 - acc: 0.8471 - val_loss: 0.6964 - val_acc: 0.8122\n",
      "Epoch 1840/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5298 - acc: 0.8463 - val_loss: 0.6961 - val_acc: 0.8124\n",
      "Epoch 1841/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5301 - acc: 0.8465 - val_loss: 0.6955 - val_acc: 0.8122\n",
      "Epoch 1842/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5299 - acc: 0.8469 - val_loss: 0.6956 - val_acc: 0.8129\n",
      "Epoch 1843/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5301 - acc: 0.8468 - val_loss: 0.6961 - val_acc: 0.8113\n",
      "Epoch 1844/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5299 - acc: 0.8464 - val_loss: 0.6958 - val_acc: 0.8121\n",
      "Epoch 1845/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5300 - acc: 0.8464 - val_loss: 0.6954 - val_acc: 0.8117\n",
      "Epoch 1846/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5298 - acc: 0.8468 - val_loss: 0.6963 - val_acc: 0.8121\n",
      "Epoch 1847/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5298 - acc: 0.8460 - val_loss: 0.6959 - val_acc: 0.8122\n",
      "Epoch 1848/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5301 - acc: 0.8463 - val_loss: 0.6952 - val_acc: 0.8126\n",
      "Epoch 1849/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5299 - acc: 0.8463 - val_loss: 0.6958 - val_acc: 0.8119\n",
      "Epoch 1850/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5297 - acc: 0.8464 - val_loss: 0.6964 - val_acc: 0.8117\n",
      "Epoch 1851/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5298 - acc: 0.8467 - val_loss: 0.6956 - val_acc: 0.8121\n",
      "Epoch 1852/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5301 - acc: 0.8467 - val_loss: 0.6960 - val_acc: 0.8121\n",
      "Epoch 1853/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5298 - acc: 0.8465 - val_loss: 0.6960 - val_acc: 0.8122\n",
      "Epoch 1854/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5297 - acc: 0.8470 - val_loss: 0.6955 - val_acc: 0.8116\n",
      "Epoch 1855/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5297 - acc: 0.8467 - val_loss: 0.6960 - val_acc: 0.8122\n",
      "Epoch 1856/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5296 - acc: 0.8467 - val_loss: 0.6954 - val_acc: 0.8134\n",
      "Epoch 1857/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5296 - acc: 0.8468 - val_loss: 0.6955 - val_acc: 0.8123\n",
      "Epoch 1858/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5296 - acc: 0.8467 - val_loss: 0.6961 - val_acc: 0.8117\n",
      "Epoch 1859/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5300 - acc: 0.8468 - val_loss: 0.6965 - val_acc: 0.8119\n",
      "Epoch 1860/2000\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 0.5296 - acc: 0.8466 - val_loss: 0.6954 - val_acc: 0.8129\n",
      "Epoch 1861/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5295 - acc: 0.8475 - val_loss: 0.6957 - val_acc: 0.8123\n",
      "Epoch 1862/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5296 - acc: 0.8472 - val_loss: 0.6957 - val_acc: 0.8127\n",
      "Epoch 1863/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5296 - acc: 0.8467 - val_loss: 0.6956 - val_acc: 0.8126\n",
      "Epoch 1864/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5295 - acc: 0.8464 - val_loss: 0.6957 - val_acc: 0.8126\n",
      "Epoch 1865/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5295 - acc: 0.8470 - val_loss: 0.6957 - val_acc: 0.8122\n",
      "Epoch 1866/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5293 - acc: 0.8469 - val_loss: 0.6961 - val_acc: 0.8127\n",
      "Epoch 1867/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5295 - acc: 0.8467 - val_loss: 0.6956 - val_acc: 0.8129\n",
      "Epoch 1868/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5294 - acc: 0.8467 - val_loss: 0.6954 - val_acc: 0.8122\n",
      "Epoch 1869/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5292 - acc: 0.8470 - val_loss: 0.6952 - val_acc: 0.8125\n",
      "Epoch 1870/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5294 - acc: 0.8468 - val_loss: 0.6961 - val_acc: 0.8122\n",
      "Epoch 1871/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5292 - acc: 0.8468 - val_loss: 0.6960 - val_acc: 0.8118\n",
      "Epoch 1872/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5293 - acc: 0.8469 - val_loss: 0.6956 - val_acc: 0.8126\n",
      "Epoch 1873/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5293 - acc: 0.8473 - val_loss: 0.6956 - val_acc: 0.8129\n",
      "Epoch 1874/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5294 - acc: 0.8471 - val_loss: 0.6957 - val_acc: 0.8116\n",
      "Epoch 1875/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5292 - acc: 0.8470 - val_loss: 0.6957 - val_acc: 0.8124\n",
      "Epoch 1876/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5292 - acc: 0.8466 - val_loss: 0.6954 - val_acc: 0.8128\n",
      "Epoch 1877/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5291 - acc: 0.8471 - val_loss: 0.6956 - val_acc: 0.8119\n",
      "Epoch 1878/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5291 - acc: 0.8466 - val_loss: 0.6953 - val_acc: 0.8126\n",
      "Epoch 1879/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5292 - acc: 0.8470 - val_loss: 0.6967 - val_acc: 0.8119\n",
      "Epoch 1880/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5295 - acc: 0.8463 - val_loss: 0.6964 - val_acc: 0.8116\n",
      "Epoch 1881/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5291 - acc: 0.8470 - val_loss: 0.6956 - val_acc: 0.8129\n",
      "Epoch 1882/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5292 - acc: 0.8467 - val_loss: 0.6953 - val_acc: 0.8125\n",
      "Epoch 1883/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5290 - acc: 0.8473 - val_loss: 0.6959 - val_acc: 0.8122\n",
      "Epoch 1884/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5293 - acc: 0.8468 - val_loss: 0.6953 - val_acc: 0.8124\n",
      "Epoch 1885/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5291 - acc: 0.8467 - val_loss: 0.6964 - val_acc: 0.8124\n",
      "Epoch 1886/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5291 - acc: 0.8474 - val_loss: 0.6958 - val_acc: 0.8132\n",
      "Epoch 1887/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5290 - acc: 0.8469 - val_loss: 0.6948 - val_acc: 0.8128\n",
      "Epoch 1888/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5290 - acc: 0.8468 - val_loss: 0.6950 - val_acc: 0.8122\n",
      "Epoch 1889/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5291 - acc: 0.8462 - val_loss: 0.6958 - val_acc: 0.8121\n",
      "Epoch 1890/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5290 - acc: 0.8471 - val_loss: 0.6954 - val_acc: 0.8127\n",
      "Epoch 1891/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5288 - acc: 0.8473 - val_loss: 0.6953 - val_acc: 0.8127\n",
      "Epoch 1892/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5290 - acc: 0.8464 - val_loss: 0.6954 - val_acc: 0.8128\n",
      "Epoch 1893/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5288 - acc: 0.8473 - val_loss: 0.6960 - val_acc: 0.8121\n",
      "Epoch 1894/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5292 - acc: 0.8467 - val_loss: 0.6956 - val_acc: 0.8118\n",
      "Epoch 1895/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5289 - acc: 0.8466 - val_loss: 0.6954 - val_acc: 0.8121\n",
      "Epoch 1896/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5288 - acc: 0.8478 - val_loss: 0.6951 - val_acc: 0.8124\n",
      "Epoch 1897/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5292 - acc: 0.8465 - val_loss: 0.6960 - val_acc: 0.8120\n",
      "Epoch 1898/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5288 - acc: 0.8476 - val_loss: 0.6954 - val_acc: 0.8122\n",
      "Epoch 1899/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5288 - acc: 0.8468 - val_loss: 0.6955 - val_acc: 0.8116\n",
      "Epoch 1900/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5292 - acc: 0.8466 - val_loss: 0.6958 - val_acc: 0.8117\n",
      "Epoch 1901/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5288 - acc: 0.8470 - val_loss: 0.6955 - val_acc: 0.8123\n",
      "Epoch 1902/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5286 - acc: 0.8472 - val_loss: 0.6950 - val_acc: 0.8126\n",
      "Epoch 1903/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5288 - acc: 0.8473 - val_loss: 0.6952 - val_acc: 0.8126\n",
      "Epoch 1904/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5291 - acc: 0.8470 - val_loss: 0.6953 - val_acc: 0.8115\n",
      "Epoch 1905/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5287 - acc: 0.8472 - val_loss: 0.6951 - val_acc: 0.8118\n",
      "Epoch 1906/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5288 - acc: 0.8476 - val_loss: 0.6952 - val_acc: 0.8124\n",
      "Epoch 1907/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5286 - acc: 0.8475 - val_loss: 0.6952 - val_acc: 0.8127\n",
      "Epoch 1908/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5285 - acc: 0.8472 - val_loss: 0.6960 - val_acc: 0.8121\n",
      "Epoch 1909/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5287 - acc: 0.8468 - val_loss: 0.6953 - val_acc: 0.8119\n",
      "Epoch 1910/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5286 - acc: 0.8469 - val_loss: 0.6955 - val_acc: 0.8124\n",
      "Epoch 1911/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5286 - acc: 0.8470 - val_loss: 0.6963 - val_acc: 0.8124\n",
      "Epoch 1912/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5289 - acc: 0.8468 - val_loss: 0.6950 - val_acc: 0.8121\n",
      "Epoch 1913/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5286 - acc: 0.8472 - val_loss: 0.6957 - val_acc: 0.8125\n",
      "Epoch 1914/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5284 - acc: 0.8468 - val_loss: 0.6955 - val_acc: 0.8124\n",
      "Epoch 1915/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5285 - acc: 0.8468 - val_loss: 0.6949 - val_acc: 0.8129\n",
      "Epoch 1916/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5286 - acc: 0.8475 - val_loss: 0.6955 - val_acc: 0.8133\n",
      "Epoch 1917/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5283 - acc: 0.8470 - val_loss: 0.6961 - val_acc: 0.8118\n",
      "Epoch 1918/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5285 - acc: 0.8472 - val_loss: 0.6954 - val_acc: 0.8124\n",
      "Epoch 1919/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5284 - acc: 0.8472 - val_loss: 0.6948 - val_acc: 0.8126\n",
      "Epoch 1920/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5286 - acc: 0.8471 - val_loss: 0.6956 - val_acc: 0.8123\n",
      "Epoch 1921/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5283 - acc: 0.8473 - val_loss: 0.6953 - val_acc: 0.8128\n",
      "Epoch 1922/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5283 - acc: 0.8467 - val_loss: 0.6949 - val_acc: 0.8121\n",
      "Epoch 1923/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5284 - acc: 0.8476 - val_loss: 0.6956 - val_acc: 0.8119\n",
      "Epoch 1924/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5282 - acc: 0.8474 - val_loss: 0.6956 - val_acc: 0.8122\n",
      "Epoch 1925/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5283 - acc: 0.8470 - val_loss: 0.6956 - val_acc: 0.8123\n",
      "Epoch 1926/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5281 - acc: 0.8467 - val_loss: 0.6949 - val_acc: 0.8122\n",
      "Epoch 1927/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5283 - acc: 0.8475 - val_loss: 0.6949 - val_acc: 0.8124\n",
      "Epoch 1928/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5282 - acc: 0.8474 - val_loss: 0.6954 - val_acc: 0.8114\n",
      "Epoch 1929/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5282 - acc: 0.8472 - val_loss: 0.6948 - val_acc: 0.8127\n",
      "Epoch 1930/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5282 - acc: 0.8472 - val_loss: 0.6953 - val_acc: 0.8124\n",
      "Epoch 1931/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5283 - acc: 0.8470 - val_loss: 0.6960 - val_acc: 0.8113\n",
      "Epoch 1932/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5283 - acc: 0.8467 - val_loss: 0.6951 - val_acc: 0.8129\n",
      "Epoch 1933/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5283 - acc: 0.8468 - val_loss: 0.6954 - val_acc: 0.8118\n",
      "Epoch 1934/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5282 - acc: 0.8470 - val_loss: 0.6958 - val_acc: 0.8120\n",
      "Epoch 1935/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5281 - acc: 0.8469 - val_loss: 0.6950 - val_acc: 0.8126\n",
      "Epoch 1936/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5281 - acc: 0.8469 - val_loss: 0.6954 - val_acc: 0.8120\n",
      "Epoch 1937/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5281 - acc: 0.8468 - val_loss: 0.6956 - val_acc: 0.8118\n",
      "Epoch 1938/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5279 - acc: 0.8471 - val_loss: 0.6949 - val_acc: 0.8119\n",
      "Epoch 1939/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5282 - acc: 0.8471 - val_loss: 0.6948 - val_acc: 0.8127\n",
      "Epoch 1940/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5280 - acc: 0.8473 - val_loss: 0.6947 - val_acc: 0.8126\n",
      "Epoch 1941/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5279 - acc: 0.8478 - val_loss: 0.6951 - val_acc: 0.8122\n",
      "Epoch 1942/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5280 - acc: 0.8470 - val_loss: 0.6950 - val_acc: 0.8124\n",
      "Epoch 1943/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5279 - acc: 0.8475 - val_loss: 0.6956 - val_acc: 0.8123\n",
      "Epoch 1944/2000\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 0.5280 - acc: 0.8476 - val_loss: 0.6949 - val_acc: 0.8123\n",
      "Epoch 1945/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5279 - acc: 0.8474 - val_loss: 0.6949 - val_acc: 0.8126\n",
      "Epoch 1946/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5280 - acc: 0.8471 - val_loss: 0.6953 - val_acc: 0.8127\n",
      "Epoch 1947/2000\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 0.5277 - acc: 0.8473 - val_loss: 0.6952 - val_acc: 0.8122\n",
      "Epoch 1948/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5281 - acc: 0.8475 - val_loss: 0.6951 - val_acc: 0.8127\n",
      "Epoch 1949/2000\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 0.5282 - acc: 0.8474 - val_loss: 0.6946 - val_acc: 0.8126\n",
      "Epoch 1950/2000\n",
      "42000/42000 [==============================] - 1s 26us/sample - loss: 0.5278 - acc: 0.8468 - val_loss: 0.6949 - val_acc: 0.8127\n",
      "Epoch 1951/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5279 - acc: 0.8474 - val_loss: 0.6945 - val_acc: 0.8122\n",
      "Epoch 1952/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5277 - acc: 0.8471 - val_loss: 0.6954 - val_acc: 0.8115\n",
      "Epoch 1953/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5279 - acc: 0.8475 - val_loss: 0.6952 - val_acc: 0.8121\n",
      "Epoch 1954/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5278 - acc: 0.8472 - val_loss: 0.6954 - val_acc: 0.8122\n",
      "Epoch 1955/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5277 - acc: 0.8470 - val_loss: 0.6946 - val_acc: 0.8123\n",
      "Epoch 1956/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5277 - acc: 0.8470 - val_loss: 0.6944 - val_acc: 0.8129\n",
      "Epoch 1957/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5279 - acc: 0.8474 - val_loss: 0.6952 - val_acc: 0.8128\n",
      "Epoch 1958/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5277 - acc: 0.8475 - val_loss: 0.6947 - val_acc: 0.8123\n",
      "Epoch 1959/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5278 - acc: 0.8471 - val_loss: 0.6952 - val_acc: 0.8121\n",
      "Epoch 1960/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5276 - acc: 0.8472 - val_loss: 0.6961 - val_acc: 0.8119\n",
      "Epoch 1961/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5278 - acc: 0.8473 - val_loss: 0.6947 - val_acc: 0.8123\n",
      "Epoch 1962/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5276 - acc: 0.8477 - val_loss: 0.6947 - val_acc: 0.8117\n",
      "Epoch 1963/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5279 - acc: 0.8469 - val_loss: 0.6953 - val_acc: 0.8118\n",
      "Epoch 1964/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5276 - acc: 0.8474 - val_loss: 0.6955 - val_acc: 0.8127\n",
      "Epoch 1965/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5274 - acc: 0.8475 - val_loss: 0.6956 - val_acc: 0.8120\n",
      "Epoch 1966/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5273 - acc: 0.8473 - val_loss: 0.6952 - val_acc: 0.8122\n",
      "Epoch 1967/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5275 - acc: 0.8473 - val_loss: 0.6950 - val_acc: 0.8119\n",
      "Epoch 1968/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5274 - acc: 0.8472 - val_loss: 0.6947 - val_acc: 0.8132\n",
      "Epoch 1969/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5272 - acc: 0.8473 - val_loss: 0.6950 - val_acc: 0.8121\n",
      "Epoch 1970/2000\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 0.5276 - acc: 0.8472 - val_loss: 0.6947 - val_acc: 0.8124\n",
      "Epoch 1971/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5275 - acc: 0.8472 - val_loss: 0.6951 - val_acc: 0.8129\n",
      "Epoch 1972/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5274 - acc: 0.8475 - val_loss: 0.6948 - val_acc: 0.8125\n",
      "Epoch 1973/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5272 - acc: 0.8477 - val_loss: 0.6951 - val_acc: 0.8119\n",
      "Epoch 1974/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5274 - acc: 0.8470 - val_loss: 0.6948 - val_acc: 0.8127\n",
      "Epoch 1975/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5274 - acc: 0.8472 - val_loss: 0.6948 - val_acc: 0.8131\n",
      "Epoch 1976/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5274 - acc: 0.8474 - val_loss: 0.6949 - val_acc: 0.8128\n",
      "Epoch 1977/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5274 - acc: 0.8474 - val_loss: 0.6947 - val_acc: 0.8127\n",
      "Epoch 1978/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5273 - acc: 0.8475 - val_loss: 0.6946 - val_acc: 0.8121\n",
      "Epoch 1979/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5273 - acc: 0.8476 - val_loss: 0.6954 - val_acc: 0.8113\n",
      "Epoch 1980/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5273 - acc: 0.8472 - val_loss: 0.6947 - val_acc: 0.8127\n",
      "Epoch 1981/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5274 - acc: 0.8474 - val_loss: 0.6945 - val_acc: 0.8121\n",
      "Epoch 1982/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5272 - acc: 0.8471 - val_loss: 0.6954 - val_acc: 0.8122\n",
      "Epoch 1983/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5272 - acc: 0.8474 - val_loss: 0.6954 - val_acc: 0.8124\n",
      "Epoch 1984/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5270 - acc: 0.8483 - val_loss: 0.6952 - val_acc: 0.8127\n",
      "Epoch 1985/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5272 - acc: 0.8470 - val_loss: 0.6950 - val_acc: 0.8124\n",
      "Epoch 1986/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5270 - acc: 0.8472 - val_loss: 0.6946 - val_acc: 0.8121\n",
      "Epoch 1987/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5270 - acc: 0.8474 - val_loss: 0.6949 - val_acc: 0.8121\n",
      "Epoch 1988/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5272 - acc: 0.8470 - val_loss: 0.6949 - val_acc: 0.8123\n",
      "Epoch 1989/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5272 - acc: 0.8473 - val_loss: 0.6948 - val_acc: 0.8121\n",
      "Epoch 1990/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5268 - acc: 0.8477 - val_loss: 0.6963 - val_acc: 0.8112\n",
      "Epoch 1991/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5271 - acc: 0.8467 - val_loss: 0.6947 - val_acc: 0.8118\n",
      "Epoch 1992/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5269 - acc: 0.8481 - val_loss: 0.6949 - val_acc: 0.8127\n",
      "Epoch 1993/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5269 - acc: 0.8474 - val_loss: 0.6955 - val_acc: 0.8122\n",
      "Epoch 1994/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5268 - acc: 0.8474 - val_loss: 0.6952 - val_acc: 0.8132\n",
      "Epoch 1995/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5270 - acc: 0.8475 - val_loss: 0.6954 - val_acc: 0.8121\n",
      "Epoch 1996/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5271 - acc: 0.8472 - val_loss: 0.6948 - val_acc: 0.8119\n",
      "Epoch 1997/2000\n",
      "42000/42000 [==============================] - 1s 25us/sample - loss: 0.5269 - acc: 0.8478 - val_loss: 0.6946 - val_acc: 0.8127\n",
      "Epoch 1998/2000\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 0.5270 - acc: 0.8474 - val_loss: 0.6948 - val_acc: 0.8129\n",
      "Epoch 1999/2000\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 0.5268 - acc: 0.8473 - val_loss: 0.6952 - val_acc: 0.8127\n",
      "Epoch 2000/2000\n",
      "42000/42000 [==============================] - 1s 24us/sample - loss: 0.5267 - acc: 0.8476 - val_loss: 0.6942 - val_acc: 0.8124\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6941773838996887, 0.81244445]"
      ]
     },
     "execution_count": 36,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the best hyperparameters found in the previous steps\n",
    "lr = 0.01\n",
    "Lambda = 0.0003\n",
    "iterations = 2000\n",
    "\n",
    "# Call the train and test function (with score)\n",
    "train_and_test_loop1(iterations, lr, Lambda)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "AnupriyaRamachandran_DLCP_Project1_Milestone3.1.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
